  RFC 9199        Considerations for Large Auth DNS Ops   March 2022
  --------------- --------------------------------------- ------------
  Moura, et al.   Informational                           \[Page\]

::: {#external-metadata .document-information}
:::

::: {#internal-metadata .document-information}

Stream:
:   Independent Submission

RFC:
:   [9199](https://www.rfc-editor.org/rfc/rfc9199){.eref}

Category:
:   Informational

Published:
:   March 2022

ISSN:
:   2070-1721

Authors:

:   ::: author
    ::: author-name
    G. Moura
    :::

    ::: org
    SIDN Labs/TU Delft
    :::
    :::

    ::: author
    ::: author-name
    W. Hardaker
    :::

    ::: org
    USC/Information Sciences Institute
    :::
    :::

    ::: author
    ::: author-name
    J. Heidemann
    :::

    ::: org
    USC/Information Sciences Institute
    :::
    :::

    ::: author
    ::: author-name
    M. Davids
    :::

    ::: org
    SIDN Labs
    :::
    :::
:::

# RFC 9199 {#rfcnum}

# Considerations for Large Authoritative DNS Server Operators {#title}

::: {#section-abstract .section}
## [Abstract](#abstract){.selfRef}

Recent research work has explored the deployment characteristics and
configuration of the Domain Name System (DNS). This document summarizes
the conclusions from these research efforts and offers specific,
tangible considerations or advice to authoritative DNS server operators.
Authoritative server operators may wish to follow these considerations
to improve their DNS services.[¶](#section-abstract-1){.pilcrow}

It is possible that the results presented in this document could be
applicable in a wider context than just the DNS protocol, as some of the
results may generically apply to any stateless/short-duration anycasted
service.[¶](#section-abstract-2){.pilcrow}

This document is not an IETF consensus document: it is published for
informational purposes.[¶](#section-abstract-3){.pilcrow}
:::

::: {#status-of-memo}
::: {#section-boilerplate.1 .section}
## [Status of This Memo](#name-status-of-this-memo){.section-name .selfRef} {#name-status-of-this-memo}

This document is not an Internet Standards Track specification; it is
published for informational
purposes.[¶](#section-boilerplate.1-1){.pilcrow}

This is a contribution to the RFC Series, independently of any other RFC
stream. The RFC Editor has chosen to publish this document at its
discretion and makes no statement about its value for implementation or
deployment. Documents approved for publication by the RFC Editor are not
candidates for any level of Internet Standard; see Section 2 of RFC
7841.[¶](#section-boilerplate.1-2){.pilcrow}

Information about the current status of this document, any errata, and
how to provide feedback on it may be obtained at
<https://www.rfc-editor.org/info/rfc9199>.[¶](#section-boilerplate.1-3){.pilcrow}
:::
:::

::: {#copyright}
::: {#section-boilerplate.2 .section}
## [Copyright Notice](#name-copyright-notice){.section-name .selfRef} {#name-copyright-notice}

Copyright (c) 2022 IETF Trust and the persons identified as the document
authors. All rights reserved.[¶](#section-boilerplate.2-1){.pilcrow}

This document is subject to BCP 78 and the IETF Trust\'s Legal
Provisions Relating to IETF Documents
(<https://trustee.ietf.org/license-info>) in effect on the date of
publication of this document. Please review these documents carefully,
as they describe your rights and restrictions with respect to this
document.[¶](#section-boilerplate.2-2){.pilcrow}
:::
:::

::: {#toc}
::: {#section-toc.1 .section}
[▲](#){.toplink}

## [Table of Contents](#name-table-of-contents){.section-name .selfRef} {#name-table-of-contents}

-   ::: {#section-toc.1-1.1}
    [1](#section-1){.xref}.  [Introduction](#name-introduction){.xref}
    :::

-   ::: {#section-toc.1-1.2}
    [2](#section-2){.xref}.  [Background](#name-background){.xref}
    :::

-   ::: {#section-toc.1-1.3}
    [3](#section-3){.xref}.  [Considerations](#name-considerations){.xref}

    -   ::: {#section-toc.1-1.3.2.1}
        [3.1](#section-3.1){.xref}.  [C1: Deploy Anycast in Every
        Authoritative Server to Enhance Distribution and
        Latency](#name-c1-deploy-anycast-in-every-){.xref}

        -   ::: {#section-toc.1-1.3.2.1.2.1}
            [3.1.1](#section-3.1.1){.xref}.  [Research
            Background](#name-research-background){.xref}
            :::

        -   ::: {#section-toc.1-1.3.2.1.2.2}
            [3.1.2](#section-3.1.2){.xref}.  [Resulting
            Considerations](#name-resulting-considerations){.xref}
            :::
        :::

    -   ::: {#section-toc.1-1.3.2.2}
        [3.2](#section-3.2){.xref}.  [C2: Optimizing Routing is More
        Important than Location Count and
        Diversity](#name-c2-optimizing-routing-is-mo){.xref}

        -   ::: {#section-toc.1-1.3.2.2.2.1}
            [3.2.1](#section-3.2.1){.xref}.  [Research
            Background](#name-research-background-2){.xref}
            :::

        -   ::: {#section-toc.1-1.3.2.2.2.2}
            [3.2.2](#section-3.2.2){.xref}.  [Resulting
            Considerations](#name-resulting-considerations-2){.xref}
            :::
        :::

    -   ::: {#section-toc.1-1.3.2.3}
        [3.3](#section-3.3){.xref}.  [C3: Collect Anycast Catchment Maps
        to Improve Design](#name-c3-collect-anycast-catchmen){.xref}

        -   ::: {#section-toc.1-1.3.2.3.2.1}
            [3.3.1](#section-3.3.1){.xref}.  [Research
            Background](#name-research-background-3){.xref}
            :::

        -   ::: {#section-toc.1-1.3.2.3.2.2}
            [3.3.2](#section-3.3.2){.xref}.  [Resulting
            Considerations](#name-resulting-considerations-3){.xref}
            :::
        :::

    -   ::: {#section-toc.1-1.3.2.4}
        [3.4](#section-3.4){.xref}.  [C4: Employ Two Strategies When
        under Stress](#name-c4-employ-two-strategies-wh){.xref}

        -   ::: {#section-toc.1-1.3.2.4.2.1}
            [3.4.1](#section-3.4.1){.xref}.  [Research
            Background](#name-research-background-4){.xref}
            :::

        -   ::: {#section-toc.1-1.3.2.4.2.2}
            [3.4.2](#section-3.4.2){.xref}.  [Resulting
            Considerations](#name-resulting-considerations-4){.xref}
            :::
        :::

    -   ::: {#section-toc.1-1.3.2.5}
        [3.5](#section-3.5){.xref}.  [C5: Consider Longer Time-to-Live
        Values Whenever
        Possible](#name-c5-consider-longer-time-to-){.xref}

        -   ::: {#section-toc.1-1.3.2.5.2.1}
            [3.5.1](#section-3.5.1){.xref}.  [Research
            Background](#name-research-background-5){.xref}
            :::

        -   ::: {#section-toc.1-1.3.2.5.2.2}
            [3.5.2](#section-3.5.2){.xref}.  [Resulting
            Considerations](#name-resulting-considerations-5){.xref}
            :::
        :::

    -   ::: {#section-toc.1-1.3.2.6}
        [3.6](#section-3.6){.xref}.  [C6: Consider the Difference in
        Parent and Children\'s TTL
        Values](#name-c6-consider-the-difference-){.xref}

        -   ::: {#section-toc.1-1.3.2.6.2.1}
            [3.6.1](#section-3.6.1){.xref}.  [Research
            Background](#name-research-background-6){.xref}
            :::

        -   ::: {#section-toc.1-1.3.2.6.2.2}
            [3.6.2](#section-3.6.2){.xref}.  [Resulting
            Considerations](#name-resulting-considerations-6){.xref}
            :::
        :::
    :::

-   ::: {#section-toc.1-1.4}
    [4](#section-4){.xref}.  [Security
    Considerations](#name-security-considerations){.xref}
    :::

-   ::: {#section-toc.1-1.5}
    [5](#section-5){.xref}.  [Privacy
    Considerations](#name-privacy-considerations){.xref}
    :::

-   ::: {#section-toc.1-1.6}
    [6](#section-6){.xref}.  [IANA
    Considerations](#name-iana-considerations){.xref}
    :::

-   ::: {#section-toc.1-1.7}
    [7](#section-7){.xref}.  [References](#name-references){.xref}

    -   ::: {#section-toc.1-1.7.2.1}
        [7.1](#section-7.1){.xref}.  [Normative
        References](#name-normative-references){.xref}
        :::

    -   ::: {#section-toc.1-1.7.2.2}
        [7.2](#section-7.2){.xref}.  [Informative
        References](#name-informative-references){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.8}
    [](#appendix-A){.xref}[Acknowledgements](#name-acknowledgements){.xref}
    :::

-   ::: {#section-toc.1-1.9}
    [](#appendix-B){.xref}[Contributors](#name-contributors){.xref}
    :::

-   ::: {#section-toc.1-1.10}
    [](#appendix-C){.xref}[Authors\'
    Addresses](#name-authors-addresses){.xref}
    :::
:::
:::

::: {#intro}
::: {#section-1 .section}
## [1.](#section-1){.section-number .selfRef} [Introduction](#name-introduction){.section-name .selfRef} {#name-introduction}

This document summarizes recent research that explored the deployed DNS
configurations and offers derived, specific, tangible advice to DNS
authoritative server operators (referred to as \"DNS operators\"
hereafter). The considerations ([C1-C6](#considerations){.xref})
presented in this document are backed by peer-reviewed research, which
used wide-scale Internet measurements to draw their conclusions. This
document summarizes the research results and describes the resulting key
engineering options. In each section, readers are pointed to the
pertinent publications where additional details are
presented.[¶](#section-1-1){.pilcrow}

These considerations are designed for operators of \"large\"
authoritative DNS servers, which, in this context, are servers with a
significant global user population, like top-level domain (TLD)
operators, run by either a single operator or multiple operators.
Typically, these networks are deployed on wide anycast networks
\[[RFC1546](#RFC1546){.xref}\] \[[AnyBest](#AnyBest){.xref}\]. These
considerations may not be appropriate for smaller domains, such as those
used by an organization with users in one unicast network or in a single
city or region, where operational goals such as uniform, global low
latency are less required.[¶](#section-1-2){.pilcrow}

It is possible that the results presented in this document could be
applicable in a wider context than just the DNS protocol, as some of the
results may generically apply to any stateless/short-duration anycasted
service. Because the conclusions of the reviewed studies don\'t measure
smaller networks, the wording in this document concentrates solely on
discussing large-scale DNS authoritative
services.[¶](#section-1-3){.pilcrow}

This document is not an IETF consensus document: it is published for
informational purposes.[¶](#section-1-4){.pilcrow}
:::
:::

::: {#background}
::: {#section-2 .section}
## [2.](#section-2){.section-number .selfRef} [Background](#name-background){.section-name .selfRef} {#name-background}

The DNS has two main types of DNS servers: authoritative servers and
recursive resolvers, shown by a representational deployment model in
[Figure 1](#recuath){.xref}. An authoritative server (shown as AT1-AT4
in [Figure 1](#recuath){.xref}) knows the content of a DNS zone and is
responsible for answering queries about that zone. It runs using local
(possibly automatically updated) copies of the zone and does not need to
query other servers \[[RFC2181](#RFC2181){.xref}\] in order to answer
requests. A recursive resolver (Re1-Re3) is a server that iteratively
queries authoritative and other servers to answer queries received from
client requests \[[RFC1034](#RFC1034){.xref}\]. A client typically
employs a software library called a \"stub resolver\" (\"stub\" in
[Figure 1](#recuath){.xref}) to issue its query to the upstream
recursive resolvers
\[[RFC1034](#RFC1034){.xref}\].[¶](#section-2-1){.pilcrow}

[]{#name-relationship-between-recurs}

::: {#recuath}
::: {#section-2-2.1 .alignLeft .art-text .artwork}
            +-----+  +-----+  +-----+  +-----+
            | AT1 |  | AT2 |  | AT3 |  | AT4 |
            +-----+  +-----+  +-----+  +-----+
              ^         ^        ^        ^
              |         |        |        |
              |      +-----+     |        |
              +------| Re1 |----+|        |
              |      +-----+              |
              |         ^                 |
              |         |                 |
              |      +----+   +----+      |
              +------|Re2 |   |Re3 |------+
                     +----+   +----+
                       ^          ^
                       |          |
                       | +------+ |
                       +-| stub |-+
                         +------+
:::

[Figure 1](#figure-1){.selfRef}: [Relationship between Recursive
Resolvers (Re) and Authoritative Name Servers
(ATn)](#name-relationship-between-recurs){.selfRef}
:::

DNS queries issued by a client contribute to a user\'s perceived latency
and affect the user experience \[[Singla2014](#Singla2014){.xref}\]
depending on how long it takes for responses to be returned. The DNS
system has been subject to repeated Denial-of-Service (DoS) attacks (for
example, in November 2015 \[[Moura16b](#Moura16b){.xref}\]) in order to
specifically degrade the user experience.[¶](#section-2-3){.pilcrow}

To reduce latency and improve resiliency against DoS attacks, the DNS
uses several types of service replication. Replication at the
authoritative server level can be achieved with the
following:[¶](#section-2-4){.pilcrow}

i.  [the deployment of multiple servers for the same zone
    \[[RFC1035](#RFC1035){.xref}\] (AT1-AT4 in [Figure
    1](#recuath){.xref});[¶](#section-2-5.1){.pilcrow}]{#section-2-5.1}
ii. [the use of IP anycast \[[RFC1546](#RFC1546){.xref}\]
    \[[RFC4786](#RFC4786){.xref}\] \[[RFC7094](#RFC7094){.xref}\] that
    allows the same IP address to be announced from multiple locations
    (each of referred to as an \"anycast instance\"
    \[[RFC8499](#RFC8499){.xref}\]);
    and[¶](#section-2-5.2){.pilcrow}]{#section-2-5.2}
iii. [the use of load balancers to support multiple servers inside a
     single (potentially anycasted) instance. As a consequence, there
     are many possible ways an authoritative DNS provider can engineer
     its production authoritative server network with multiple viable
     choices, and there is not necessarily a single optimal
     design.[¶](#section-2-5.3){.pilcrow}]{#section-2-5.3}
:::
:::

::: {#considerations}
::: {#section-3 .section}
## [3.](#section-3){.section-number .selfRef} [Considerations](#name-considerations){.section-name .selfRef} {#name-considerations}

In the next sections, we cover the specific considerations
([C1-C6](#considerations){.xref}) for conclusions drawn within academic
papers about large authoritative DNS server operators. These
considerations are conclusions reached from academic work that
authoritative server operators may wish to consider in order to improve
their DNS service. Each consideration offers different improvements that
may impact service latency, routing, anycast deployment, and defensive
strategies, for example.[¶](#section-3-1){.pilcrow}

::: {#c1}
::: {#section-3.1 .section}
### [3.1.](#section-3.1){.section-number .selfRef} [C1: Deploy Anycast in Every Authoritative Server to Enhance Distribution and Latency](#name-c1-deploy-anycast-in-every-){.section-name .selfRef} {#name-c1-deploy-anycast-in-every-}

::: {#research-background}
::: {#section-3.1.1 .section}
#### [3.1.1.](#section-3.1.1){.section-number .selfRef} [Research Background](#name-research-background){.section-name .selfRef} {#name-research-background}

Authoritative DNS server operators announce their service using NS
records \[[RFC1034](#RFC1034){.xref}\]. Different authoritative servers
for a given zone should return the same content; typically, they stay
synchronized using DNS zone transfers (authoritative transfer (AXFR)
\[[RFC5936](#RFC5936){.xref}\] and incremental zone transfer (IXFR)
\[[RFC1995](#RFC1995){.xref}\]), coordinating the zone data they all
return to their clients.[¶](#section-3.1.1-1){.pilcrow}

As discussed above, the DNS heavily relies upon replication to support
high reliability, ensure capacity, and reduce latency
\[[Moura16b](#Moura16b){.xref}\]. The DNS has two complementary
mechanisms for service replication: name server replication (multiple NS
records) and anycast (multiple physical locations). Name server
replication is strongly recommended for all zones (multiple NS records),
and IP anycast is used by many larger zones such as the DNS root
\[[AnyFRoot](#AnyFRoot){.xref}\], most top-level domains
\[[Moura16b](#Moura16b){.xref}\], and many large commercial enterprises,
governments, and other organizations.[¶](#section-3.1.1-2){.pilcrow}

Most DNS operators strive to reduce service latency for users, which is
greatly affected by both of these replication techniques. However,
because operators only have control over their authoritative servers and
not over the client\'s recursive resolvers, it is difficult to ensure
that recursives will be served by the closest authoritative server.
Server selection is ultimately up to the recursive resolver\'s software
implementation, and different vendors and even different releases employ
different criteria to choose the authoritative servers with which to
communicate.[¶](#section-3.1.1-3){.pilcrow}

Understanding how recursive resolvers choose authoritative servers is a
key step in improving the effectiveness of authoritative server
deployments. To measure and evaluate server deployments,
\[[Mueller17b](#Mueller17b){.xref}\] describes the deployment of seven
unicast authoritative name servers in different global locations and
then queried them from more than 9000 Reseaux IP Europeens (RIPE)
authoritative server operators and their respective recursive
resolvers.[¶](#section-3.1.1-4){.pilcrow}

It was found in \[[Mueller17b](#Mueller17b){.xref}\] that recursive
resolvers in the wild query all available authoritative servers,
regardless of the observed latency. But the distribution of queries
tends to be skewed towards authoritatives with lower latency: the lower
the latency between a recursive resolver and an authoritative server,
the more often the recursive will send queries to that server. These
results were obtained by aggregating results from all of the vantage
points, and they were not specific to any vendor or
version.[¶](#section-3.1.1-5){.pilcrow}

The authors believe this behavior is a consequence of combining the two
main criteria employed by resolvers when selecting authoritative
servers: resolvers regularly check all listed authoritative servers in
an NS set to determine which is closer (the least latent), and when one
isn\'t available, it selects one of the
alternatives.[¶](#section-3.1.1-6){.pilcrow}
:::
:::

::: {#resulting-considerations}
::: {#section-3.1.2 .section}
#### [3.1.2.](#section-3.1.2){.section-number .selfRef} [Resulting Considerations](#name-resulting-considerations){.section-name .selfRef} {#name-resulting-considerations}

For an authoritative DNS operator, this result means that the latency of
all authoritative servers (NS records) matter, so they all must be
similarly capable \-- all available authoritatives will be queried by
most recursive resolvers. Unicasted services, unfortunately, cannot
deliver good latency worldwide (a unicast authoritative server in Europe
will always have high latency to resolvers in California and Australia,
for example, given its geographical
distance).[¶](#section-3.1.2-1){.pilcrow}

\[[Mueller17b](#Mueller17b){.xref}\] recommends that DNS operators
deploy equally strong IP anycast instances for every authoritative
server (i.e., for each NS record). Each large authoritative DNS server
provider should phase out its usage of unicast and deploy a number of
well-engineered anycast instances with good peering strategies so they
can provide good latency to their global
clients.[¶](#section-3.1.2-2){.pilcrow}

As a case study, the \".nl\" TLD zone was originally served on seven
authoritative servers with a mixed unicast/anycast setup. In early 2018,
.nl moved to a setup with 4 anycast authoritative
servers.[¶](#section-3.1.2-3){.pilcrow}

The contribution of \[[Mueller17b](#Mueller17b){.xref}\] to DNS service
engineering shows that because unicast cannot deliver good latency
worldwide, anycast needs to be used to provide a low-latency service
worldwide.[¶](#section-3.1.2-4){.pilcrow}
:::
:::
:::
:::

::: {#c2}
::: {#section-3.2 .section}
### [3.2.](#section-3.2){.section-number .selfRef} [C2: Optimizing Routing is More Important than Location Count and Diversity](#name-c2-optimizing-routing-is-mo){.section-name .selfRef} {#name-c2-optimizing-routing-is-mo}

::: {#research-background-1}
::: {#section-3.2.1 .section}
#### [3.2.1.](#section-3.2.1){.section-number .selfRef} [Research Background](#name-research-background-2){.section-name .selfRef} {#name-research-background-2}

When selecting an anycast DNS provider or setting up an anycast service,
choosing the best number of anycast instances
\[[RFC4786](#RFC4786){.xref}\] \[[RFC7094](#RFC7094){.xref}\] to deploy
is a challenging problem. Selecting the right quantity and set of global
locations that should send BGP announcements is tricky. Intuitively, one
could naively think that more instances are better and that simply
\"more\" will always lead to shorter response
times.[¶](#section-3.2.1-1){.pilcrow}

This is not necessarily true, however. In fact, proper route engineering
can matter more than the total number of locations, as found in
\[[Schmidt17a](#Schmidt17a){.xref}\]. To study the relationship between
the number of anycast instances and the associated service performance,
the authors measured the round-trip time (RTT) latency of four DNS root
servers. The root DNS servers are implemented by 12 separate
organizations serving the DNS root zone at 13 different IPv4/IPv6
address pairs.[¶](#section-3.2.1-2){.pilcrow}

The results documented in \[[Schmidt17a](#Schmidt17a){.xref}\] measured
the performance of the {c,f,k,l}.root-servers.net (referred to as \"C\",
\"F\", \"K\", and \"L\" hereafter) servers from more than 7,900 RIPE
Atlas probes. RIPE Atlas is an Internet measurement platform with more
than 12,000 global vantage points called \"Atlas probes\", and it is
used regularly by both researchers and operators
\[[RipeAtlas15a](#RipeAtlas15a){.xref}\]
\[[RipeAtlas19a](#RipeAtlas19a){.xref}\].[¶](#section-3.2.1-3){.pilcrow}

In \[[Schmidt17a](#Schmidt17a){.xref}\], the authors found that the C
server, a smaller anycast deployment consisting of only 8 instances,
provided very similar overall performance in comparison to the much
larger deployments of K and L, with 33 and 144 instances, respectively.
The median RTTs for the C, K, and L root servers were all between 30-32
ms.[¶](#section-3.2.1-4){.pilcrow}

Because RIPE Atlas is known to have better coverage in Europe than other
regions, the authors specifically analyzed the results per region and
per country (Figure 5 in \[[Schmidt17a](#Schmidt17a){.xref}\]) and show
that known Atlas bias toward Europe does not change the conclusion that
properly selected anycast locations are more important to latency than
the number of sites.[¶](#section-3.2.1-5){.pilcrow}
:::
:::

::: {#resulting-considerations-1}
::: {#section-3.2.2 .section}
#### [3.2.2.](#section-3.2.2){.section-number .selfRef} [Resulting Considerations](#name-resulting-considerations-2){.section-name .selfRef} {#name-resulting-considerations-2}

The important conclusion from \[[Schmidt17a](#Schmidt17a){.xref}\] is
that when engineering anycast services for performance, factors other
than just the number of instances (such as local routing connectivity)
must be considered. Specifically, optimizing routing policies is more
important than simply adding new instances. The authors showed that 12
instances can provide reasonable latency, assuming they are globally
distributed and have good local interconnectivity. However, additional
instances can still be useful for other reasons, such as when handling
DoS attacks
\[[Moura16b](#Moura16b){.xref}\].[¶](#section-3.2.2-1){.pilcrow}
:::
:::
:::
:::

::: {#c3}
::: {#section-3.3 .section}
### [3.3.](#section-3.3){.section-number .selfRef} [C3: Collect Anycast Catchment Maps to Improve Design](#name-c3-collect-anycast-catchmen){.section-name .selfRef} {#name-c3-collect-anycast-catchmen}

::: {#research-background-2}
::: {#section-3.3.1 .section}
#### [3.3.1.](#section-3.3.1){.section-number .selfRef} [Research Background](#name-research-background-3){.section-name .selfRef} {#name-research-background-3}

An anycast DNS service may be deployed from anywhere and from several
locations to hundreds of locations (for example, l.root-servers.net has
over 150 anycast instances at the time this was written). Anycast
leverages Internet routing to distribute incoming queries to a
service\'s nearest distributed anycast locations measured by the number
of routing hops. However, queries are usually not evenly distributed
across all anycast locations, as found in the case of L-Root when
analyzed using Hedgehog
\[[IcannHedgehog](#IcannHedgehog){.xref}\].[¶](#section-3.3.1-1){.pilcrow}

Adding locations to or removing locations from a deployed anycast
network changes the load distribution across all of its locations. When
a new location is announced by BGP, locations may receive more or less
traffic than it was engineered for, leading to suboptimal service
performance or even stressing some locations while leaving others
underutilized. Operators constantly face this scenario when expanding an
anycast service. Operators cannot easily directly estimate future query
distributions based on proposed anycast network engineering
decisions.[¶](#section-3.3.1-2){.pilcrow}

To address this need and estimate the query loads of an anycast service
undergoing changes (in particular expanding),
\[[Vries17b](#Vries17b){.xref}\] describes the development of a new
technique enabling operators to carry out active measurements using an
open-source tool called Verfploeter (available at
\[[VerfSrc](#VerfSrc){.xref}\]). The results allow the creation of
detailed anycast maps and catchment estimates. By running Verfploeter
combined with a published IPv4 \"hit list\", the DNS can precisely
calculate which remote prefixes will be matched to each anycast instance
in a network. At the time of this writing, Verfploeter still does not
support IPv6 as the IPv4 hit lists used are generated via frequent
large-scale ICMP echo scans, which is not possible using
IPv6.[¶](#section-3.3.1-3){.pilcrow}

As proof of concept, \[[Vries17b](#Vries17b){.xref}\] documents how
Verfploeter was used to predict both the catchment and query load
distribution for a new anycast instance deployed for b.root-servers.net.
Using two anycast test instances in Miami (MIA) and Los Angeles (LAX),
an ICMP echo query was sent from an IP anycast address to each IPv4 /24
network routing block on the Internet.[¶](#section-3.3.1-4){.pilcrow}

The ICMP echo responses were recorded at both sites and analyzed and
overlaid onto a graphical world map, resulting in an Internet-scale
catchment map. To calculate expected load once the production network
was enabled, the quantity of traffic received by b.root-servers.net\'s
single site at LAX was recorded based on a single day\'s traffic
(2017-04-12, \"day in the life\" (DITL) datasets
\[[Ditl17](#Ditl17){.xref}\]). In \[[Vries17b](#Vries17b){.xref}\], it
was predicted that 81.6% of the traffic load would remain at the LAX
site. This Verfploeter estimate turned out to be very accurate; the
actual measured traffic volume when production service at MIA was
enabled was 81.4%.[¶](#section-3.3.1-5){.pilcrow}

Verfploeter can also be used to estimate traffic shifts based on other
BGP route engineering techniques (for example, Autonomous System (AS)
path prepending or BGP community use) in advance of operational
deployment. This was studied in \[[Vries17b](#Vries17b){.xref}\] using
prepending with 1-3 hops at each instance, and the results were compared
against real operational changes to validate the accuracy of the
techniques.[¶](#section-3.3.1-6){.pilcrow}
:::
:::

::: {#resulting-considerations-2}
::: {#section-3.3.2 .section}
#### [3.3.2.](#section-3.3.2){.section-number .selfRef} [Resulting Considerations](#name-resulting-considerations-3){.section-name .selfRef} {#name-resulting-considerations-3}

An important operational takeaway \[[Vries17b](#Vries17b){.xref}\]
provides is how DNS operators can make informed engineering choices when
changing DNS anycast network deployments by using Verfploeter in
advance. Operators can identify suboptimal routing situations in advance
with significantly better coverage rather than using other active
measurement platforms such as RIPE Atlas. To date, Verfploeter has been
deployed on an operational testbed (anycast testbed)
\[[AnyTest](#AnyTest){.xref}\] on a large unnamed operator and is run
daily at b.root-servers.net
\[[Vries17b](#Vries17b){.xref}\].[¶](#section-3.3.2-1){.pilcrow}

Operators should use active measurement techniques like Verfploeter in
advance of potential anycast network changes to accurately measure the
benefits and potential issues ahead of
time.[¶](#section-3.3.2-2){.pilcrow}
:::
:::
:::
:::

::: {#c4}
::: {#section-3.4 .section}
### [3.4.](#section-3.4){.section-number .selfRef} [C4: Employ Two Strategies When under Stress](#name-c4-employ-two-strategies-wh){.section-name .selfRef} {#name-c4-employ-two-strategies-wh}

::: {#research-background-3}
::: {#section-3.4.1 .section}
#### [3.4.1.](#section-3.4.1){.section-number .selfRef} [Research Background](#name-research-background-4){.section-name .selfRef} {#name-research-background-4}

DDoS attacks are becoming bigger, cheaper, and more frequent
\[[Moura16b](#Moura16b){.xref}\]. The most powerful recorded DDoS attack
against DNS servers to date reached 1.2 Tbps by using Internet of Things
(IoT) devices \[[Perlroth16](#Perlroth16){.xref}\]. How should a DNS
operator engineer its anycast authoritative DNS server to react to such
a DDoS attack? \[[Moura16b](#Moura16b){.xref}\] investigates this
question using empirical observations grounded with theoretical option
evaluations.[¶](#section-3.4.1-1){.pilcrow}

An authoritative DNS server deployed using anycast will have many server
instances distributed over many networks. Ultimately, the relationship
between the DNS provider\'s network and a client\'s ISP will determine
which anycast instance will answer queries for a given client, given
that the BGP protocol maps clients to specific anycast instances using
routing information. As a consequence, when an anycast authoritative
server is under attack, the load that each anycast instance receives is
likely to be unevenly distributed (a function of the source of the
attacks); thus, some instances may be more overloaded than others, which
is what was observed when analyzing the root DNS events of November 2015
\[[Moura16b](#Moura16b){.xref}\]. Given the fact that different
instances may have different capacities (bandwidth, CPU, etc.), making a
decision about how to react to stress becomes even more
difficult.[¶](#section-3.4.1-2){.pilcrow}

In practice, when an anycast instance is overloaded with incoming
traffic, operators have two options:[¶](#section-3.4.1-3){.pilcrow}

-   [They can withdraw its routes, pre-prepend its AS route to some or
    all of its neighbors, perform other traffic-shifting tricks (such as
    reducing route announcement propagation using BGP communities
    \[[RFC1997](#RFC1997){.xref}\]), or communicate with its upstream
    network providers to apply filtering (potentially using FlowSpec
    \[[RFC8955](#RFC8955){.xref}\] or the DDoS Open Threat Signaling
    (DOTS) protocol \[[RFC8811](#RFC8811){.xref}\]
    \[[RFC9132](#RFC9132){.xref}\] \[[RFC8783](#RFC8783){.xref}\]).
    These techniques shift both legitimate and attack traffic to other
    anycast instances (with hopefully greater capacity) or block traffic
    entirely.[¶](#section-3.4.1-4.1){.pilcrow}]{#section-3.4.1-4.1}
-   [Alternatively, operators can become degraded absorbers by
    continuing to operate, knowing dropping incoming legitimate requests
    due to queue overflow. However, this approach will also absorb
    attack traffic directed toward its catchment, hopefully protecting
    the other anycast
    instances.[¶](#section-3.4.1-4.2){.pilcrow}]{#section-3.4.1-4.2}

\[[Moura16b](#Moura16b){.xref}\] describes seeing both of these
behaviors deployed in practice when studying instance reachability and
RTTs in the DNS root events. When withdraw strategies were deployed, the
stress of increased query loads were displaced from one instance to
multiple other sites. In other observed events, one site was left to
absorb the brunt of an attack, leaving the other sites to remain
relatively less affected.[¶](#section-3.4.1-5){.pilcrow}
:::
:::

::: {#resulting-considerations-3}
::: {#section-3.4.2 .section}
#### [3.4.2.](#section-3.4.2){.section-number .selfRef} [Resulting Considerations](#name-resulting-considerations-4){.section-name .selfRef} {#name-resulting-considerations-4}

Operators should consider having both an anycast site withdraw strategy
and an absorption strategy ready to be used before a network overload
occurs. Operators should be able to deploy one or both of these
strategies rapidly. Ideally, these should be encoded into operating
playbooks with defined site measurement guidelines for which strategy to
employ based on measured data from past
events.[¶](#section-3.4.2-1){.pilcrow}

\[[Moura16b](#Moura16b){.xref}\] speculates that careful, explicit, and
automated management policies may provide stronger defenses to overload
events. DNS operators should be ready to employ both common filtering
approaches and other routing load-balancing techniques (such as
withdrawing routes, prepending Autonomous Systems (ASes), adding
communities, or isolating instances), where the best choice depends on
the specifics of the attack.[¶](#section-3.4.2-2){.pilcrow}

Note that this consideration refers to the operation of just one anycast
service point, i.e., just one anycasted IP address block covering one NS
record. However, DNS zones with multiple authoritative anycast servers
may also expect loads to shift from one anycasted server to another, as
resolvers switch from one authoritative service point to another when
attempting to resolve a name
\[[Mueller17b](#Mueller17b){.xref}\].[¶](#section-3.4.2-3){.pilcrow}
:::
:::
:::
:::

::: {#c5}
::: {#section-3.5 .section}
### [3.5.](#section-3.5){.section-number .selfRef} [C5: Consider Longer Time-to-Live Values Whenever Possible](#name-c5-consider-longer-time-to-){.section-name .selfRef} {#name-c5-consider-longer-time-to-}

::: {#research-background-4}
::: {#section-3.5.1 .section}
#### [3.5.1.](#section-3.5.1){.section-number .selfRef} [Research Background](#name-research-background-5){.section-name .selfRef} {#name-research-background-5}

Caching is the cornerstone of good DNS performance and reliability. A 50
ms response to a new DNS query may be considered fast, but a response of
less than 1 ms to a cached entry is far faster. In
\[[Moura18b](#Moura18b){.xref}\], it was shown that caching also
protects users from short outages and even significant DDoS
attacks.[¶](#section-3.5.1-1){.pilcrow}

Time-to-live (TTL) values \[[RFC1034](#RFC1034){.xref}\]
\[[RFC1035](#RFC1035){.xref}\] for DNS records directly control cache
durations and affect latency, resilience, and the role of DNS in Content
Delivery Network (CDN) server selection. Some early work modeled caches
as a function of their TTLs \[[Jung03a](#Jung03a){.xref}\], and recent
work has examined cache interactions with DNS
\[[Moura18b](#Moura18b){.xref}\], but until
\[[Moura19b](#Moura19b){.xref}\], no research had provided
considerations about the benefits of various TTL value choices. To study
this, Moura et al. \[[Moura19b](#Moura19b){.xref}\] carried out a
measurement study investigating TTL choices and their impact on user
experiences in the wild. They performed this study independent of
specific resolvers (and their caching architectures), vendors, or
setups.[¶](#section-3.5.1-2){.pilcrow}

First, they identified several reasons why operators and zone owners may
want to choose longer or shorter TTLs:[¶](#section-3.5.1-3){.pilcrow}

-   [Longer TTLs, as discussed, lead to a longer cache life, resulting
    in faster responses. In \[[Moura19b](#Moura19b){.xref}\], this was
    measured this in the wild, and it showed that by increasing the TTL
    for the .uy TLD from 5 minutes (300 s) to 1 day (86,400 s), the
    latency measured from 15,000 Atlas vantage points changed
    significantly: the median RTT decreased from 28.7 ms to 8 ms, and
    the 75th percentile decreased from 183 ms to 21
    ms.[¶](#section-3.5.1-4.1){.pilcrow}]{#section-3.5.1-4.1}
-   [Longer caching times also result in lower DNS traffic:
    authoritative servers will experience less traffic with extended
    TTLs, as repeated queries are answered by resolver
    caches.[¶](#section-3.5.1-4.2){.pilcrow}]{#section-3.5.1-4.2}
-   [Longer caching consequently results in a lower overall cost if the
    DNS is metered: some providers that offer DNS as a Service charge a
    per-query (metered) cost (often in addition to a fixed monthly
    cost).[¶](#section-3.5.1-4.3){.pilcrow}]{#section-3.5.1-4.3}
-   [Longer caching is more robust to DDoS attacks on DNS
    infrastructure. DNS caching was also measured in
    \[[Moura18b](#Moura18b){.xref}\], and it showed that the effects of
    a DDoS on DNS can be greatly reduced, provided that the caches last
    longer than the
    attack.[¶](#section-3.5.1-4.4){.pilcrow}]{#section-3.5.1-4.4}
-   [Shorter caching, however, supports deployments that may require
    rapid operational changes: an easy way to transition from an old
    server to a new one is to simply change the DNS records. Since there
    is no method to remotely remove cached DNS records, the TTL duration
    represents a necessary transition delay to fully shift from one
    server to another. Thus, low TTLs allow for more rapid transitions.
    However, when deployments are planned in advance (that is, longer
    than the TTL), it is possible to lower the TTLs just before a major
    operational change and raise them again
    afterward.[¶](#section-3.5.1-4.5){.pilcrow}]{#section-3.5.1-4.5}
-   [Shorter caching can also help with a DNS-based response to DDoS
    attacks. Specifically, some DDoS-scrubbing services use the DNS to
    redirect traffic during an attack. Since DDoS attacks arrive
    unannounced, DNS-based traffic redirection requires that the TTL be
    kept quite low at all times to allow operators to suddenly have
    their zone served by a DDoS-scrubbing
    service.[¶](#section-3.5.1-4.6){.pilcrow}]{#section-3.5.1-4.6}
-   [Shorter caching helps DNS-based load balancing. Many large services
    are known to rotate traffic among their servers using DNS-based load
    balancing. Each arriving DNS request provides an opportunity to
    adjust the service load by rotating IP address records (A and AAAA)
    to the lowest unused server. Shorter TTLs may be desired in these
    architectures to react more quickly to traffic dynamics. Many
    recursive resolvers, however, have minimum caching times of tens of
    seconds, placing a limit on this form of
    agility.[¶](#section-3.5.1-4.7){.pilcrow}]{#section-3.5.1-4.7}
:::
:::

::: {#resulting-considerations-4}
::: {#section-3.5.2 .section}
#### [3.5.2.](#section-3.5.2){.section-number .selfRef} [Resulting Considerations](#name-resulting-considerations-5){.section-name .selfRef} {#name-resulting-considerations-5}

Given these considerations, the proper choice for a TTL depends in part
on multiple external factors \-- no single recommendation is appropriate
for all scenarios. Organizations must weigh these trade-offs and find a
good balance for their situation. Still, some guidelines can be reached
when choosing TTLs:[¶](#section-3.5.2-1){.pilcrow}

-   [For general DNS zone owners, \[[Moura19b](#Moura19b){.xref}\]
    recommends a longer TTL of at least one hour and ideally 4, 8, or 24
    hours. Assuming planned maintenance can be scheduled at least a day
    in advance, long TTLs have little cost and may even literally
    provide cost
    savings.[¶](#section-3.5.2-2.1){.pilcrow}]{#section-3.5.2-2.1}
-   [For TLD and other public registration operators (for example, most
    ccTLDs and .com, .net, and .org) that host many delegations (NS
    records, DS records, and \"glue\" records),
    \[[Moura19b](#Moura19b){.xref}\] demonstrates that most resolvers
    will use the TTL values provided by the child delegations while some
    others will choose the TTL provided by the parent\'s copy of the
    record. As such, \[[Moura19b](#Moura19b){.xref}\] recommends longer
    TTLs (at least an hour or more) for registry operators as well for
    child NS and other
    records.[¶](#section-3.5.2-2.2){.pilcrow}]{#section-3.5.2-2.2}
-   [Users of DNS-based load balancing or DDoS-prevention services may
    require shorter TTLs: TTLs may even need to be as short as 5
    minutes, although 15 minutes may provide sufficient agility for many
    operators. There is always a tussle between using shorter TTLs that
    provide more agility and using longer TTLs that include all the
    benefits listed
    above.[¶](#section-3.5.2-2.3){.pilcrow}]{#section-3.5.2-2.3}
-   [Regarding the use of A/AAAA and NS records, the TTLs for A/AAAA
    records should be shorter than or equal to the TTL for the
    corresponding NS records for in-bailiwick authoritative DNS servers,
    since \[[Moura19b](#Moura19b){.xref}\] finds that once an NS record
    expires, their associated A/AAAA will also be requeried when glue is
    required to be sent by the parents. For out-of-bailiwick servers, A,
    AAAA, and NS records are usually all cached independently, so
    different TTLs can be used effectively if desired. In either case,
    short A and AAAA records may still be desired if DDoS mitigation
    services are
    required.[¶](#section-3.5.2-2.4){.pilcrow}]{#section-3.5.2-2.4}
:::
:::
:::
:::

::: {#c6}
::: {#section-3.6 .section}
### [3.6.](#section-3.6){.section-number .selfRef} [C6: Consider the Difference in Parent and Children\'s TTL Values](#name-c6-consider-the-difference-){.section-name .selfRef} {#name-c6-consider-the-difference-}

::: {#research-background-5}
::: {#section-3.6.1 .section}
#### [3.6.1.](#section-3.6.1){.section-number .selfRef} [Research Background](#name-research-background-6){.section-name .selfRef} {#name-research-background-6}

Multiple record types exist or are related between the parent of a zone
and the child. At a minimum, NS records are supposed to be identical in
the parent (but often are not), as are corresponding IP addresses in
\"glue\" A/AAAA records that must exist for in-bailiwick authoritative
servers. Additionally, if DNSSEC \[[RFC4033](#RFC4033){.xref}\]
\[[RFC4034](#RFC4034){.xref}\] \[[RFC4035](#RFC4035){.xref}\]
\[[RFC4509](#RFC4509){.xref}\] is deployed for a zone, the parent\'s DS
record must cryptographically refer to a child\'s DNSKEY
record.[¶](#section-3.6.1-1){.pilcrow}

Because some information exists in both the parent and a child, it is
possible for the TTL values to differ between the parent\'s copy and the
child\'s. \[[Moura19b](#Moura19b){.xref}\] examines resolver behaviors
when these values differed in the wild, as they frequently do \-- often,
parent zones have de facto TTL values that a child has no control over.
For example, NS records for TLDs in the root zone are all set to 2 days
(48 hours), but some TLDs have lower values within their published
records (the TTLs for .cl\'s NS records from their authoritative servers
is 1 hour). \[[Moura19b](#Moura19b){.xref}\] also examines the
differences in the TTLs between the NS records and the corresponding
A/AAAA records for the addresses of a name server. RIPE Atlas nodes are
used to determine what resolvers in the wild do with different
information and whether the parent\'s TTL is used for cache lifetimes
(\"parent-centric\") or the child\'s
(\"child-centric\").[¶](#section-3.6.1-2){.pilcrow}

\[[Moura19b](#Moura19b){.xref}\] found that roughly 90% of resolvers
follow the child\'s view of the TTL, while 10% appear parent-centric.
Additionally, it found that resolvers behave differently for cache
lifetimes for in-bailiwick vs. out-of-bailiwick NS/A/AAAA TTL
combinations. Specifically, when NS TTLs are shorter than the
corresponding address records, most resolvers will requery for A/AAAA
records for the in-bailiwick resolvers and switch to new address records
even if the cache indicates the original A/AAAA records could be kept
longer. On the other hand, the inverse is true for out-of-bailiwick
resolvers: if the NS record expires first, resolvers will honor the
original cache time of the name server\'s
address.[¶](#section-3.6.1-3){.pilcrow}
:::
:::

::: {#resulting-considerations-5}
::: {#section-3.6.2 .section}
#### [3.6.2.](#section-3.6.2){.section-number .selfRef} [Resulting Considerations](#name-resulting-considerations-6){.section-name .selfRef} {#name-resulting-considerations-6}

The important conclusion from this study is that operators cannot depend
on their published TTL values alone \-- the parent\'s values are also
used for timing cache entries in the wild. Operators that are planning
on infrastructure changes should assume that an older infrastructure
must be left on and operational for at least the maximum of both the
parent and child\'s TTLs.[¶](#section-3.6.2-1){.pilcrow}
:::
:::
:::
:::
:::
:::

::: {#security-considerations}
::: {#section-4 .section}
## [4.](#section-4){.section-number .selfRef} [Security Considerations](#name-security-considerations){.section-name .selfRef} {#name-security-considerations}

This document discusses applying measured research results to
operational deployments. Most of the considerations affect mostly
operational practice, though a few do have security-related
impacts.[¶](#section-4-1){.pilcrow}

Specifically, [C4](#c4){.xref} discusses a couple of strategies to
employ when a service is under stress from DDoS attacks and offers
operators additional guidance when handling excess
traffic.[¶](#section-4-2){.pilcrow}

Similarly, [C5](#c5){.xref} identifies the trade-offs with respect to
the operational and security benefits of using longer TTL
values.[¶](#section-4-3){.pilcrow}
:::
:::

::: {#privacy-considerations}
::: {#section-5 .section}
## [5.](#section-5){.section-number .selfRef} [Privacy Considerations](#name-privacy-considerations){.section-name .selfRef} {#name-privacy-considerations}

This document does not add any new, practical privacy issues, aside from
possible benefits in deploying longer TTLs as suggested in
[C5](#c5){.xref}. Longer TTLs may help preserve a user\'s privacy by
reducing the number of requests that get transmitted in both
client-to-resolver and resolver-to-authoritative
cases.[¶](#section-5-1){.pilcrow}
:::
:::

::: {#iana-considerations}
::: {#section-6 .section}
## [6.](#section-6){.section-number .selfRef} [IANA Considerations](#name-iana-considerations){.section-name .selfRef} {#name-iana-considerations}

This document has no IANA actions.[¶](#section-6-1){.pilcrow}
:::
:::

::: {#section-7 .section}
## [7.](#section-7){.section-number .selfRef} [References](#name-references){.section-name .selfRef} {#name-references}

::: {#section-7.1 .section}
### [7.1.](#section-7.1){.section-number .selfRef} [Normative References](#name-normative-references){.section-name .selfRef} {#name-normative-references}

\[RFC1034\]
:   [Mockapetris, P.]{.refAuthor}, [\"Domain names - concepts and
    facilities\"]{.refTitle}, [STD 13]{.seriesInfo}, [RFC
    1034]{.seriesInfo}, [DOI 10.17487/RFC1034]{.seriesInfo}, November
    1987, \<<https://www.rfc-editor.org/info/rfc1034>\>.
:   

\[RFC1035\]
:   [Mockapetris, P.]{.refAuthor}, [\"Domain names - implementation and
    specification\"]{.refTitle}, [STD 13]{.seriesInfo}, [RFC
    1035]{.seriesInfo}, [DOI 10.17487/RFC1035]{.seriesInfo}, November
    1987, \<<https://www.rfc-editor.org/info/rfc1035>\>.
:   

\[RFC1546\]
:   [Partridge, C.]{.refAuthor}, [Mendez, T.]{.refAuthor}, and [W.
    Milliken]{.refAuthor}, [\"Host Anycasting Service\"]{.refTitle},
    [RFC 1546]{.seriesInfo}, [DOI 10.17487/RFC1546]{.seriesInfo},
    November 1993, \<<https://www.rfc-editor.org/info/rfc1546>\>.
:   

\[RFC1995\]
:   [Ohta, M.]{.refAuthor}, [\"Incremental Zone Transfer in
    DNS\"]{.refTitle}, [RFC 1995]{.seriesInfo}, [DOI
    10.17487/RFC1995]{.seriesInfo}, August 1996,
    \<<https://www.rfc-editor.org/info/rfc1995>\>.
:   

\[RFC1997\]
:   [Chandra, R.]{.refAuthor}, [Traina, P.]{.refAuthor}, and [T.
    Li]{.refAuthor}, [\"BGP Communities Attribute\"]{.refTitle}, [RFC
    1997]{.seriesInfo}, [DOI 10.17487/RFC1997]{.seriesInfo}, August
    1996, \<<https://www.rfc-editor.org/info/rfc1997>\>.
:   

\[RFC2181\]
:   [Elz, R.]{.refAuthor} and [R. Bush]{.refAuthor}, [\"Clarifications
    to the DNS Specification\"]{.refTitle}, [RFC 2181]{.seriesInfo},
    [DOI 10.17487/RFC2181]{.seriesInfo}, July 1997,
    \<<https://www.rfc-editor.org/info/rfc2181>\>.
:   

\[RFC4786\]
:   [Abley, J.]{.refAuthor} and [K. Lindqvist]{.refAuthor}, [\"Operation
    of Anycast Services\"]{.refTitle}, [BCP 126]{.seriesInfo}, [RFC
    4786]{.seriesInfo}, [DOI 10.17487/RFC4786]{.seriesInfo}, December
    2006, \<<https://www.rfc-editor.org/info/rfc4786>\>.
:   

\[RFC5936\]
:   [Lewis, E.]{.refAuthor} and [A. Hoenes, Ed.]{.refAuthor}, [\"DNS
    Zone Transfer Protocol (AXFR)\"]{.refTitle}, [RFC
    5936]{.seriesInfo}, [DOI 10.17487/RFC5936]{.seriesInfo}, June 2010,
    \<<https://www.rfc-editor.org/info/rfc5936>\>.
:   

\[RFC7094\]
:   [McPherson, D.]{.refAuthor}, [Oran, D.]{.refAuthor},
    [Thaler, D.]{.refAuthor}, and [E. Osterweil]{.refAuthor},
    [\"Architectural Considerations of IP Anycast\"]{.refTitle}, [RFC
    7094]{.seriesInfo}, [DOI 10.17487/RFC7094]{.seriesInfo}, January
    2014, \<<https://www.rfc-editor.org/info/rfc7094>\>.
:   

\[RFC8499\]
:   [Hoffman, P.]{.refAuthor}, [Sullivan, A.]{.refAuthor}, and [K.
    Fujiwara]{.refAuthor}, [\"DNS Terminology\"]{.refTitle}, [BCP
    219]{.seriesInfo}, [RFC 8499]{.seriesInfo}, [DOI
    10.17487/RFC8499]{.seriesInfo}, January 2019,
    \<<https://www.rfc-editor.org/info/rfc8499>\>.
:   

\[RFC8783\]
:   [Boucadair, M., Ed.]{.refAuthor} and [T. Reddy.K, Ed.]{.refAuthor},
    [\"Distributed Denial-of-Service Open Threat Signaling (DOTS) Data
    Channel Specification\"]{.refTitle}, [RFC 8783]{.seriesInfo}, [DOI
    10.17487/RFC8783]{.seriesInfo}, May 2020,
    \<<https://www.rfc-editor.org/info/rfc8783>\>.
:   

\[RFC8955\]
:   [Loibl, C.]{.refAuthor}, [Hares, S.]{.refAuthor},
    [Raszuk, R.]{.refAuthor}, [McPherson, D.]{.refAuthor}, and [M.
    Bacher]{.refAuthor}, [\"Dissemination of Flow Specification
    Rules\"]{.refTitle}, [RFC 8955]{.seriesInfo}, [DOI
    10.17487/RFC8955]{.seriesInfo}, December 2020,
    \<<https://www.rfc-editor.org/info/rfc8955>\>.
:   

\[RFC9132\]
:   [Boucadair, M., Ed.]{.refAuthor}, [Shallow, J.]{.refAuthor}, and [T.
    Reddy.K]{.refAuthor}, [\"Distributed Denial-of-Service Open Threat
    Signaling (DOTS) Signal Channel Specification\"]{.refTitle}, [RFC
    9132]{.seriesInfo}, [DOI 10.17487/RFC9132]{.seriesInfo}, September
    2021, \<<https://www.rfc-editor.org/info/rfc9132>\>.
:   
:::

::: {#section-7.2 .section}
### [7.2.](#section-7.2){.section-number .selfRef} [Informative References](#name-informative-references){.section-name .selfRef} {#name-informative-references}

\[AnyBest\]
:   [Woodcock, B.]{.refAuthor}, [\"Best Practices in DNS
    Service-Provision Architecture\"]{.refTitle}, [Version
    1.2]{.seriesInfo}, March 2016,
    \<<https://meetings.icann.org/en/marrakech55/schedule/mon-tech/presentation-dns-service-provision-07mar16-en.pdf>\>.
:   

\[AnyFRoot\]
:   [Woolf, S.]{.refAuthor}, [\"Anycasting
    f.root-servers.net\"]{.refTitle}, January 2003,
    \<<https://archive.nanog.org/meetings/nanog27/presentations/suzanne.pdf>\>.
:   

\[AnyTest\]
:   [Tangled]{.refAuthor}, [\"Tangled Anycast Testbed\"]{.refTitle},
    \<<http://www.anycast-testbed.com/>\>.
:   

\[Ditl17\]
:   [DNS-OARC]{.refAuthor}, [\"2017 DITL Data\"]{.refTitle}, April 2017,
    \<<https://www.dns-oarc.net/oarc/data/ditl/2017>\>.
:   

\[IcannHedgehog\]
:   [\"hedgehog\"]{.refTitle}, [commit b136eb0]{.refContent}, May 2021,
    \<<https://github.com/dns-stats/hedgehog>\>.
:   

\[Jung03a\]
:   [Jung, J.]{.refAuthor}, [Berger, A.]{.refAuthor}, and [H.
    Balakrishnan]{.refAuthor}, [\"Modeling TTL-based Internet
    Caches\"]{.refTitle}, [ACM 2003 IEEE INFOCOM]{.refContent}, [DOI
    10.1109/INFCOM.2003.1208693]{.seriesInfo}, July 2003,
    \<<http://www.ieee-infocom.org/2003/papers/11_01.PDF>\>.
:   

\[Moura16b\]
:   [Moura, G.C.M.]{.refAuthor}, [Schmidt, R. de O.]{.refAuthor},
    [Heidemann, J.]{.refAuthor}, [de Vries, W.]{.refAuthor},
    [Müller, M.]{.refAuthor}, [Wei, L.]{.refAuthor}, and [C.
    Hesselman]{.refAuthor}, [\"Anycast vs. DDoS: Evaluating the November
    2015 Root DNS Event\"]{.refTitle}, [ACM 2016 Internet Measurement
    Conference]{.refContent}, [DOI
    10.1145/2987443.2987446]{.seriesInfo}, November 2016,
    \<<https://www.isi.edu/~johnh/PAPERS/Moura16b.pdf>\>.
:   

\[Moura18b\]
:   [Moura, G.C.M.]{.refAuthor}, [Heidemann, J.]{.refAuthor},
    [Müller, M.]{.refAuthor}, [Schmidt, R. de O.]{.refAuthor}, and [M.
    Davids]{.refAuthor}, [\"When the Dike Breaks: Dissecting DNS
    Defenses During DDoS\"]{.refTitle}, [ACM 2018 Internet Measurement
    Conference]{.refContent}, [DOI
    10.1145/3278532.3278534]{.seriesInfo}, October 2018,
    \<<https://www.isi.edu/~johnh/PAPERS/Moura18b.pdf>\>.
:   

\[Moura19b\]
:   [Moura, G.C.M.]{.refAuthor}, [Hardaker, W.]{.refAuthor},
    [Heidemann, J.]{.refAuthor}, and [R. de O. Schmidt]{.refAuthor},
    [\"Cache Me If You Can: Effects of DNS Time-to-Live\"]{.refTitle},
    [ACM 2019 Internet Measurement Conference]{.refContent}, [DOI
    10.1145/3355369.3355568]{.seriesInfo}, October 2019,
    \<<https://www.isi.edu/~hardaker/papers/2019-10-cache-me-ttls.pdf>\>.
:   

\[Mueller17b\]
:   [Müller, M.]{.refAuthor}, [Moura, G.C.M.]{.refAuthor}, [Schmidt, R.
    de O.]{.refAuthor}, and [J. Heidemann]{.refAuthor}, [\"Recursives in
    the Wild: Engineering Authoritative DNS Servers\"]{.refTitle}, [ACM
    2017 Internet Measurement Conference]{.refContent}, [DOI
    10.1145/3131365.3131366]{.seriesInfo}, November 2017,
    \<<https://www.isi.edu/%7ejohnh/PAPERS/Mueller17b.pdf>\>.
:   

\[Perlroth16\]
:   [Perlroth, N.]{.refAuthor}, [\"Hackers Used New Weapons to Disrupt
    Major Websites Across U.S.\"]{.refTitle}, October 2016,
    \<<https://www.nytimes.com/2016/10/22/business/internet-problems-attack.html>\>.
:   

\[RFC4033\]
:   [Arends, R.]{.refAuthor}, [Austein, R.]{.refAuthor},
    [Larson, M.]{.refAuthor}, [Massey, D.]{.refAuthor}, and [S.
    Rose]{.refAuthor}, [\"DNS Security Introduction and
    Requirements\"]{.refTitle}, [RFC 4033]{.seriesInfo}, [DOI
    10.17487/RFC4033]{.seriesInfo}, March 2005,
    \<<https://www.rfc-editor.org/info/rfc4033>\>.
:   

\[RFC4034\]
:   [Arends, R.]{.refAuthor}, [Austein, R.]{.refAuthor},
    [Larson, M.]{.refAuthor}, [Massey, D.]{.refAuthor}, and [S.
    Rose]{.refAuthor}, [\"Resource Records for the DNS Security
    Extensions\"]{.refTitle}, [RFC 4034]{.seriesInfo}, [DOI
    10.17487/RFC4034]{.seriesInfo}, March 2005,
    \<<https://www.rfc-editor.org/info/rfc4034>\>.
:   

\[RFC4035\]
:   [Arends, R.]{.refAuthor}, [Austein, R.]{.refAuthor},
    [Larson, M.]{.refAuthor}, [Massey, D.]{.refAuthor}, and [S.
    Rose]{.refAuthor}, [\"Protocol Modifications for the DNS Security
    Extensions\"]{.refTitle}, [RFC 4035]{.seriesInfo}, [DOI
    10.17487/RFC4035]{.seriesInfo}, March 2005,
    \<<https://www.rfc-editor.org/info/rfc4035>\>.
:   

\[RFC4509\]
:   [Hardaker, W.]{.refAuthor}, [\"Use of SHA-256 in DNSSEC Delegation
    Signer (DS) Resource Records (RRs)\"]{.refTitle}, [RFC
    4509]{.seriesInfo}, [DOI 10.17487/RFC4509]{.seriesInfo}, May 2006,
    \<<https://www.rfc-editor.org/info/rfc4509>\>.
:   

\[RFC8811\]
:   [Mortensen, A., Ed.]{.refAuthor}, [Reddy.K, T., Ed.]{.refAuthor},
    [Andreasen, F.]{.refAuthor}, [Teague, N.]{.refAuthor}, and [R.
    Compton]{.refAuthor}, [\"DDoS Open Threat Signaling (DOTS)
    Architecture\"]{.refTitle}, [RFC 8811]{.seriesInfo}, [DOI
    10.17487/RFC8811]{.seriesInfo}, August 2020,
    \<<https://www.rfc-editor.org/info/rfc8811>\>.
:   

\[RipeAtlas15a\]
:   [RIPE Network Coordination Centre (RIPE NCC)]{.refAuthor}, [\"RIPE
    Atlas: A Global Internet Measurement Network\"]{.refTitle}, October
    2015,
    \<<http://ipj.dreamhosters.com/wp-content/uploads/issues/2015/ipj18-3.pdf>\>.
:   

\[RipeAtlas19a\]
:   [RIPE Network Coordination Centre (RIPE NCC)]{.refAuthor}, [\"RIPE
    Atlas\"]{.refTitle}, \<<https://atlas.ripe.net>\>.
:   

\[Schmidt17a\]
:   [Schmidt, R. de O.]{.refAuthor}, [Heidemann, J.]{.refAuthor}, and
    [J. Kuipers]{.refAuthor}, [\"Anycast Latency: How Many Sites Are
    Enough?\"]{.refTitle}, [PAM 2017 Passive and Active Measurement
    Conference]{.refContent}, [DOI
    10.1007/978-3-319-54328-4_14]{.seriesInfo}, March 2017,
    \<<https://www.isi.edu/%7ejohnh/PAPERS/Schmidt17a.pdf>\>.
:   

\[Singla2014\]
:   [Singla, A.]{.refAuthor}, [Chandrasekaran, B.]{.refAuthor},
    [Godfrey, P.]{.refAuthor}, and [B. Maggs]{.refAuthor}, [\"The
    Internet at the Speed of Light\"]{.refTitle}, [13th ACM Workshop on
    Hot Topics in Networks]{.refContent}, [DOI
    10.1145/2670518.2673876]{.seriesInfo}, October 2014,
    \<<http://speedierweb.web.engr.illinois.edu/cspeed/papers/hotnets14.pdf>\>.
:   

\[VerfSrc\]
:   [\"Verfploeter Source Code\"]{.refTitle}, [commit
    f4792dc]{.refContent}, May 2019,
    \<<https://github.com/Woutifier/verfploeter>\>.
:   

\[Vries17b\]
:   [de Vries, W.]{.refAuthor}, [Schmidt, R. de O.]{.refAuthor},
    [Hardaker, W.]{.refAuthor}, [Heidemann, J.]{.refAuthor}, [de Boer,
    P-T.]{.refAuthor}, and [A. Pras]{.refAuthor}, [\"Broad and
    Load-Aware Anycast Mapping with Verfploeter\"]{.refTitle}, [ACM 2017
    Internet Measurement Conference]{.refContent}, [DOI
    10.1145/3131365.3131371]{.seriesInfo}, November 2017,
    \<<https://www.isi.edu/%7ejohnh/PAPERS/Vries17b.pdf>\>.
:   
:::
:::

::: {#acknowledgements}
::: {#appendix-A .section}
## [Acknowledgements](#name-acknowledgements){.section-name .selfRef} {#name-acknowledgements}

We would like to thank the reviewers of this document who offered
valuable suggestions as well as comments at the IETF DNSOP session (IETF
104): [Duane Wessels]{.contact-name}, [Joe Abley]{.contact-name}, [Toema
Gavrichenkov]{.contact-name}, [John Levine]{.contact-name}, [Michael
StJohns]{.contact-name}, [Kristof Tuyteleers]{.contact-name}, [Stefan
Ubbink]{.contact-name}, [Klaus Darilion]{.contact-name}, and [Samir
Jafferali]{.contact-name}.[¶](#appendix-A-1){.pilcrow}

Additionally, we would like thank those acknowledged in the papers this
document summarizes for helping produce the results: RIPE NCC and DNS
OARC for their tools and datasets used in this research, as well as the
funding agencies sponsoring the individual
research.[¶](#appendix-A-2){.pilcrow}
:::
:::

::: {#contributors}
::: {#appendix-B .section}
## [Contributors](#name-contributors){.section-name .selfRef} {#name-contributors}

This document is a summary of the main considerations of six research
papers written by the authors and the following people who contributed
substantially to the content and should be considered coauthors; this
document would not have been possible without their hard
work:[¶](#appendix-B-1){.pilcrow}

-   ::: {#appendix-B-2.1}
    [Ricardo de O.
    Schmidt]{.contact-name}[¶](#appendix-B-2.1.1){.pilcrow}
    :::

-   ::: {#appendix-B-2.2}
    [Wouter B. de Vries]{.contact-name}[¶](#appendix-B-2.2.1){.pilcrow}
    :::

-   ::: {#appendix-B-2.3}
    [Moritz Mueller]{.contact-name}[¶](#appendix-B-2.3.1){.pilcrow}
    :::

-   ::: {#appendix-B-2.4}
    [Lan Wei]{.contact-name}[¶](#appendix-B-2.4.1){.pilcrow}
    :::

-   ::: {#appendix-B-2.5}
    [Cristian Hesselman]{.contact-name}[¶](#appendix-B-2.5.1){.pilcrow}
    :::

-   ::: {#appendix-B-2.6}
    [Jan Harm Kuipers]{.contact-name}[¶](#appendix-B-2.6.1){.pilcrow}
    :::

-   ::: {#appendix-B-2.7}
    [Pieter-Tjerk de
    Boer]{.contact-name}[¶](#appendix-B-2.7.1){.pilcrow}
    :::

-   ::: {#appendix-B-2.8}
    [Aiko Pras]{.contact-name}[¶](#appendix-B-2.8.1){.pilcrow}
    :::
:::
:::

::: {#authors-addresses}
::: {#appendix-C .section}
## [Authors\' Addresses](#name-authors-addresses){.section-name .selfRef} {#name-authors-addresses}

::: {.left dir="auto"}
[Giovane C. M. Moura]{.fn .nameRole}
:::

::: {.left dir="auto"}
[SIDN Labs/TU Delft]{.org}
:::

::: {.left dir="auto"}
[Meander 501]{.street-address}
:::

::: {.left dir="auto"}
[6825 MD]{.postal-code} [Arnhem]{.locality}
:::

::: {.left dir="auto"}
[Netherlands]{.country-name}
:::

::: tel
Phone: [+31 26 352 5500](tel:+31%2026%20352%205500){.tel}
:::

::: email
Email: <giovane.moura@sidn.nl>
:::

::: {.left dir="auto"}
[Wes Hardaker]{.fn .nameRole}
:::

::: {.left dir="auto"}
[USC/Information Sciences Institute]{.org}
:::

::: {.left dir="auto"}
[PO Box 382]{.street-address}
:::

::: {.left dir="auto"}
[Davis]{.locality}, [CA]{.region} [95617-0382]{.postal-code}
:::

::: {.left dir="auto"}
[United States of America]{.country-name}
:::

::: tel
Phone: [+1 (530) 404-0099](tel:+1%20(530)%20404-0099){.tel}
:::

::: email
Email: <ietf@hardakers.net>
:::

::: {.left dir="auto"}
[John Heidemann]{.fn .nameRole}
:::

::: {.left dir="auto"}
[USC/Information Sciences Institute]{.org}
:::

::: {.left dir="auto"}
[4676 Admiralty Way]{.street-address}
:::

::: {.left dir="auto"}
[Marina Del Rey]{.locality}, [CA]{.region} [90292-6695]{.postal-code}
:::

::: {.left dir="auto"}
[United States of America]{.country-name}
:::

::: tel
Phone: [+1 (310) 448-8708](tel:+1%20(310)%20448-8708){.tel}
:::

::: email
Email: <johnh@isi.edu>
:::

::: {.left dir="auto"}
[Marco Davids]{.fn .nameRole}
:::

::: {.left dir="auto"}
[SIDN Labs]{.org}
:::

::: {.left dir="auto"}
[Meander 501]{.street-address}
:::

::: {.left dir="auto"}
[6825 MD]{.postal-code} [Arnhem]{.locality}
:::

::: {.left dir="auto"}
[Netherlands]{.country-name}
:::

::: tel
Phone: [+31 26 352 5500](tel:+31%2026%20352%205500){.tel}
:::

::: email
Email: <marco.davids@sidn.nl>
:::
:::
:::
