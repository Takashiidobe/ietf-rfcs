  RFC 9040        TCP Control Block Interdependence   July 2021
  --------------- ----------------------------------- -----------
  Touch, et al.   Informational                       \[Page\]

::: {#external-metadata .document-information}
:::

::: {#internal-metadata .document-information}

Stream:
:   Internet Engineering Task Force (IETF)

RFC:
:   [9040](https://www.rfc-editor.org/rfc/rfc9040){.eref}

Obsoletes:
:   [2140](https://www.rfc-editor.org/rfc/rfc2140){.eref}

Category:
:   Informational

Published:
:   July 2021

ISSN:
:   2070-1721

Authors:

:   ::: author
    ::: author-name
    J. Touch
    :::

    ::: org
    Independent
    :::
    :::

    ::: author
    ::: author-name
    M. Welzl
    :::

    ::: org
    University of Oslo
    :::
    :::

    ::: author
    ::: author-name
    S. Islam
    :::

    ::: org
    University of Oslo
    :::
    :::
:::

# RFC 9040 {#rfcnum}

# TCP Control Block Interdependence {#title}

::: {#section-abstract .section}
## [Abstract](#abstract){.selfRef}

This memo provides guidance to TCP implementers that is intended to help
improve connection convergence to steady-state operation without
affecting interoperability. It updates and replaces RFC 2140\'s
description of sharing TCP state, as typically represented in TCP
Control Blocks, among similar concurrent or consecutive
connections.[¶](#section-abstract-1){.pilcrow}
:::

::: {#status-of-memo}
::: {#section-boilerplate.1 .section}
## [Status of This Memo](#name-status-of-this-memo){.section-name .selfRef} {#name-status-of-this-memo}

This document is not an Internet Standards Track specification; it is
published for informational
purposes.[¶](#section-boilerplate.1-1){.pilcrow}

This document is a product of the Internet Engineering Task Force
(IETF). It represents the consensus of the IETF community. It has
received public review and has been approved for publication by the
Internet Engineering Steering Group (IESG). Not all documents approved
by the IESG are candidates for any level of Internet Standard; see
Section 2 of RFC 7841.[¶](#section-boilerplate.1-2){.pilcrow}

Information about the current status of this document, any errata, and
how to provide feedback on it may be obtained at
<https://www.rfc-editor.org/info/rfc9040>.[¶](#section-boilerplate.1-3){.pilcrow}
:::
:::

::: {#copyright}
::: {#section-boilerplate.2 .section}
## [Copyright Notice](#name-copyright-notice){.section-name .selfRef} {#name-copyright-notice}

Copyright (c) 2021 IETF Trust and the persons identified as the document
authors. All rights reserved.[¶](#section-boilerplate.2-1){.pilcrow}

This document is subject to BCP 78 and the IETF Trust\'s Legal
Provisions Relating to IETF Documents
(<https://trustee.ietf.org/license-info>) in effect on the date of
publication of this document. Please review these documents carefully,
as they describe your rights and restrictions with respect to this
document. Code Components extracted from this document must include
Simplified BSD License text as described in Section 4.e of the Trust
Legal Provisions and are provided without warranty as described in the
Simplified BSD License.[¶](#section-boilerplate.2-2){.pilcrow}
:::
:::

::: {#toc}
::: {#section-toc.1 .section}
[▲](#){.toplink}

## [Table of Contents](#name-table-of-contents){.section-name .selfRef} {#name-table-of-contents}

-   ::: {#section-toc.1-1.1}
    [1](#section-1){.xref}.  [Introduction](#name-introduction){.xref}
    :::

-   ::: {#section-toc.1-1.2}
    [2](#section-2){.xref}.  [Conventions Used in This
    Document](#name-conventions-used-in-this-do){.xref}
    :::

-   ::: {#section-toc.1-1.3}
    [3](#section-3){.xref}.  [Terminology](#name-terminology){.xref}
    :::

-   ::: {#section-toc.1-1.4}
    [4](#section-4){.xref}.  [The TCP Control Block
    (TCB)](#name-the-tcp-control-block-tcb){.xref}
    :::

-   ::: {#section-toc.1-1.5}
    [5](#section-5){.xref}.  [TCB
    Interdependence](#name-tcb-interdependence){.xref}
    :::

-   ::: {#section-toc.1-1.6}
    [6](#section-6){.xref}.  [Temporal
    Sharing](#name-temporal-sharing){.xref}

    -   ::: {#section-toc.1-1.6.2.1}
        [6.1](#section-6.1){.xref}.  [Initialization of a New
        TCB](#name-initialization-of-a-new-tcb){.xref}
        :::

    -   ::: {#section-toc.1-1.6.2.2}
        [6.2](#section-6.2){.xref}.  [Updates to the TCB
        Cache](#name-updates-to-the-tcb-cache){.xref}
        :::

    -   ::: {#section-toc.1-1.6.2.3}
        [6.3](#section-6.3){.xref}.  [Discussion](#name-discussion){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.7}
    [7](#section-7){.xref}.  [Ensemble
    Sharing](#name-ensemble-sharing){.xref}

    -   ::: {#section-toc.1-1.7.2.1}
        [7.1](#section-7.1){.xref}.  [Initialization of a New
        TCB](#name-initialization-of-a-new-tcb-2){.xref}
        :::

    -   ::: {#section-toc.1-1.7.2.2}
        [7.2](#section-7.2){.xref}.  [Updates to the TCB
        Cache](#name-updates-to-the-tcb-cache-2){.xref}
        :::

    -   ::: {#section-toc.1-1.7.2.3}
        [7.3](#section-7.3){.xref}.  [Discussion](#name-discussion-2){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.8}
    [8](#section-8){.xref}.  [Issues with TCB Information
    Sharing](#name-issues-with-tcb-information){.xref}

    -   ::: {#section-toc.1-1.8.2.1}
        [8.1](#section-8.1){.xref}.  [Traversing the Same Network
        Path](#name-traversing-the-same-network){.xref}
        :::

    -   ::: {#section-toc.1-1.8.2.2}
        [8.2](#section-8.2){.xref}.  [State
        Dependence](#name-state-dependence){.xref}
        :::

    -   ::: {#section-toc.1-1.8.2.3}
        [8.3](#section-8.3){.xref}.  [Problems with Sharing Based on IP
        Address](#name-problems-with-sharing-based){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.9}
    [9](#section-9){.xref}.  [Implications](#name-implications){.xref}

    -   ::: {#section-toc.1-1.9.2.1}
        [9.1](#section-9.1){.xref}.  [Layering](#name-layering){.xref}
        :::

    -   ::: {#section-toc.1-1.9.2.2}
        [9.2](#section-9.2){.xref}.  [Other
        Possibilities](#name-other-possibilities){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.10}
    [10](#section-10){.xref}. [Implementation
    Observations](#name-implementation-observations){.xref}
    :::

-   ::: {#section-toc.1-1.11}
    [11](#section-11){.xref}. [Changes Compared to RFC
    2140](#name-changes-compared-to-rfc-214){.xref}
    :::

-   ::: {#section-toc.1-1.12}
    [12](#section-12){.xref}. [Security
    Considerations](#name-security-considerations){.xref}
    :::

-   ::: {#section-toc.1-1.13}
    [13](#section-13){.xref}. [IANA
    Considerations](#name-iana-considerations){.xref}
    :::

-   ::: {#section-toc.1-1.14}
    [14](#section-14){.xref}. [References](#name-references){.xref}

    -   ::: {#section-toc.1-1.14.2.1}
        [14.1](#section-14.1){.xref}.  [Normative
        References](#name-normative-references){.xref}
        :::

    -   ::: {#section-toc.1-1.14.2.2}
        [14.2](#section-14.2){.xref}.  [Informative
        References](#name-informative-references){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.15}
    [Appendix A](#appendix-A){.xref}.  [TCB Sharing
    History](#name-tcb-sharing-history){.xref}
    :::

-   ::: {#section-toc.1-1.16}
    [Appendix B](#appendix-B){.xref}.  [TCP Option Sharing and
    Caching](#name-tcp-option-sharing-and-cach){.xref}
    :::

-   ::: {#section-toc.1-1.17}
    [Appendix C](#appendix-C){.xref}.  [Automating the Initial Window in
    TCP over Long Timescales](#name-automating-the-initial-wind){.xref}

    -   ::: {#section-toc.1-1.17.2.1}
        [C.1](#appendix-C.1){.xref}.  [Introduction](#name-introduction-2){.xref}
        :::

    -   ::: {#section-toc.1-1.17.2.2}
        [C.2](#appendix-C.2){.xref}.  [Design
        Considerations](#name-design-considerations){.xref}
        :::

    -   ::: {#section-toc.1-1.17.2.3}
        [C.3](#appendix-C.3){.xref}.  [Proposed IW
        Algorithm](#name-proposed-iw-algorithm){.xref}
        :::

    -   ::: {#section-toc.1-1.17.2.4}
        [C.4](#appendix-C.4){.xref}.  [Discussion](#name-discussion-3){.xref}
        :::

    -   ::: {#section-toc.1-1.17.2.5}
        [C.5](#appendix-C.5){.xref}.  [Observations](#name-observations){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.18}
    [](#appendix-D){.xref}[Acknowledgments](#name-acknowledgments){.xref}
    :::

-   ::: {#section-toc.1-1.19}
    [](#appendix-E){.xref}[Authors\'
    Addresses](#name-authors-addresses){.xref}
    :::
:::
:::

::: {#sect-1}
::: {#section-1 .section}
## [1.](#section-1){.section-number .selfRef} [Introduction](#name-introduction){.section-name .selfRef} {#name-introduction}

TCP is a connection-oriented reliable transport protocol layered over IP
\[[RFC0793](#RFC0793){.xref}\]. Each TCP connection maintains state,
usually in a data structure called the \"TCP Control Block (TCB)\". The
TCB contains information about the connection state, its associated
local process, and feedback parameters about the connection\'s
transmission properties. As originally specified and usually
implemented, most TCB information is maintained on a per-connection
basis. Some implementations share certain TCB information across
connections to the same host \[[RFC2140](#RFC2140){.xref}\]. Such
sharing is intended to lead to better overall transient performance,
especially for numerous short-lived and simultaneous connections, as can
be used in the World Wide Web and other applications
\[[Be94](#Be94){.xref}\] \[[Br02](#Br02){.xref}\]. This sharing of state
is intended to help TCP connections converge to long-term behavior
(assuming stable application load, i.e., so-called \"steady-state\")
more quickly without affecting TCP
interoperability.[¶](#section-1-1){.pilcrow}

This document updates RFC 2140\'s discussion of TCB state sharing and
provides a complete replacement for that document. This state sharing
affects only TCB initialization \[[RFC2140](#RFC2140){.xref}\] and thus
has no effect on the long-term behavior of TCP after a connection has
been established or on interoperability. Path information shared across
SYN destination port numbers assumes that TCP segments having the same
host-pair experience the same path properties, i.e., that traffic is not
routed differently based on port numbers or other connection parameters
(also addressed further in [Section 8.1](#sect-8.1){.xref}). The
observations about TCB sharing in this document apply similarly to any
protocol with congestion state, including the Stream Control
Transmission Protocol (SCTP) \[[RFC4960](#RFC4960){.xref}\] and the
Datagram Congestion Control Protocol (DCCP)
\[[RFC4340](#RFC4340){.xref}\], as well as to individual subflows in
Multipath TCP \[[RFC8684](#RFC8684){.xref}\].[¶](#section-1-2){.pilcrow}
:::
:::

::: {#sect-2}
::: {#section-2 .section}
## [2.](#section-2){.section-number .selfRef} [Conventions Used in This Document](#name-conventions-used-in-this-do){.section-name .selfRef} {#name-conventions-used-in-this-do}

The key words \"[MUST]{.bcp14}\", \"[MUST NOT]{.bcp14}\",
\"[REQUIRED]{.bcp14}\", \"[SHALL]{.bcp14}\", \"[SHALL NOT]{.bcp14}\",
\"[SHOULD]{.bcp14}\", \"[SHOULD NOT]{.bcp14}\",
\"[RECOMMENDED]{.bcp14}\", \"[NOT RECOMMENDED]{.bcp14}\",
\"[MAY]{.bcp14}\", and \"[OPTIONAL]{.bcp14}\" in this document are to be
interpreted as described in BCP 14 \[[RFC2119](#RFC2119){.xref}\]
\[[RFC8174](#RFC8174){.xref}\] when, and only when, they appear in all
capitals, as shown here.[¶](#section-2-1){.pilcrow}

The core of this document describes behavior that is already permitted
by TCP standards. As a result, this document provides informative
guidance but does not use normative language except when quoting other
documents. Normative language is used in [Appendix C](#sect-c){.xref} as
examples of requirements for future
consideration.[¶](#section-2-2){.pilcrow}
:::
:::

::: {#sect-3}
::: {#section-3 .section}
## [3.](#section-3){.section-number .selfRef} [Terminology](#name-terminology){.section-name .selfRef} {#name-terminology}

The following terminology is used frequently in this document. Items
preceded with a \"+\" may be part of the state maintained as TCP
connection state in the TCB of associated connections and are the focus
of sharing as described in this document. Note that terms are used as
originally introduced where possible; in some cases, direction is
indicated with a suffix (\_S for send, \_R for receive) and in other
cases spelled out (sendcwnd).[¶](#section-3-1){.pilcrow}

[]{.break}

+cwnd:
:   TCP congestion window size
    \[[RFC5681](#RFC5681){.xref}\][¶](#section-3-2.2){.pilcrow}
:   

host:
:   a source or sink of TCP segments associated with a single IP
    address[¶](#section-3-2.4){.pilcrow}
:   

host-pair:
:   a pair of hosts and their corresponding IP
    addresses[¶](#section-3-2.6){.pilcrow}
:   

ISN:
:   Initial Sequence Number[¶](#section-3-2.8){.pilcrow}
:   

+MMS_R:
:   maximum message size that can be received, the largest received
    transport payload of an IP datagram
    \[[RFC1122](#RFC1122){.xref}\][¶](#section-3-2.10){.pilcrow}
:   

+MMS_S:
:   maximum message size that can be sent, the largest transmitted
    transport payload of an IP datagram
    \[[RFC1122](#RFC1122){.xref}\][¶](#section-3-2.12){.pilcrow}
:   

path:
:   an Internet path between the IP addresses of two
    hosts[¶](#section-3-2.14){.pilcrow}
:   

PCB:
:   protocol control block, the data associated with a protocol as
    maintained by an endpoint; a TCP PCB is called a
    \"TCB\"[¶](#section-3-2.16){.pilcrow}
:   

PLPMTUD:
:   packetization-layer path MTU discovery, a mechanism that uses
    transport packets to discover the Path Maximum Transmission Unit
    (PMTU) \[[RFC4821](#RFC4821){.xref}\][¶](#section-3-2.18){.pilcrow}
:   

+PMTU:
:   largest IP datagram that can traverse a path
    \[[RFC1191](#RFC1191){.xref}\]
    \[[RFC8201](#RFC8201){.xref}\][¶](#section-3-2.20){.pilcrow}
:   

PMTUD:
:   path-layer MTU discovery, a mechanism that relies on ICMP error
    messages to discover the PMTU \[[RFC1191](#RFC1191){.xref}\]
    \[[RFC8201](#RFC8201){.xref}\][¶](#section-3-2.22){.pilcrow}
:   

+RTT:
:   round-trip time of a TCP packet exchange
    \[[RFC0793](#RFC0793){.xref}\][¶](#section-3-2.24){.pilcrow}
:   

+RTTVAR:
:   variation of round-trip times of a TCP packet exchange
    \[[RFC6298](#RFC6298){.xref}\][¶](#section-3-2.26){.pilcrow}
:   

+rwnd:
:   TCP receive window size
    \[[RFC5681](#RFC5681){.xref}\][¶](#section-3-2.28){.pilcrow}
:   

+sendcwnd:
:   TCP send-side congestion window (cwnd) size
    \[[RFC5681](#RFC5681){.xref}\][¶](#section-3-2.30){.pilcrow}
:   

+sendMSS:
:   TCP maximum segment size, a value transmitted in a TCP option that
    represents the largest TCP user data payload that can be received
    \[[RFC6691](#RFC6691){.xref}\][¶](#section-3-2.32){.pilcrow}
:   

+ssthresh:
:   TCP slow-start threshold
    \[[RFC5681](#RFC5681){.xref}\][¶](#section-3-2.34){.pilcrow}
:   

TCB:
:   TCP Control Block, the data associated with a TCP connection as
    maintained by an endpoint[¶](#section-3-2.36){.pilcrow}
:   

TCP-AO:
:   TCP Authentication Option
    \[[RFC5925](#RFC5925){.xref}\][¶](#section-3-2.38){.pilcrow}
:   

TFO:
:   TCP Fast Open option
    \[[RFC7413](#RFC7413){.xref}\][¶](#section-3-2.40){.pilcrow}
:   

+TFO_cookie:
:   TCP Fast Open cookie, state that is used as part of the TFO
    mechanism, when TFO is supported
    \[[RFC7413](#RFC7413){.xref}\][¶](#section-3-2.42){.pilcrow}
:   

+TFO_failure:
:   an indication of when TFO option negotiation failed, when TFO is
    supported[¶](#section-3-2.44){.pilcrow}
:   

+TFOinfo:
:   information cached when a TFO connection is established, which
    includes the TFO_cookie
    \[[RFC7413](#RFC7413){.xref}\][¶](#section-3-2.46){.pilcrow}
:   
:::
:::

::: {#sect-4}
::: {#section-4 .section}
## [4.](#section-4){.section-number .selfRef} [The TCP Control Block (TCB)](#name-the-tcp-control-block-tcb){.section-name .selfRef} {#name-the-tcp-control-block-tcb}

A TCB describes the data associated with each connection, i.e., with
each association of a pair of applications across the network. The TCB
contains at least the following information
\[[RFC0793](#RFC0793){.xref}\]:[¶](#section-4-1){.pilcrow}

-   ::: {#section-4-2.1}
    Local process state[¶](#section-4-2.1.1){.pilcrow}

    -   [pointers to send and receive
        buffers[¶](#section-4-2.1.2.1){.pilcrow}]{#section-4-2.1.2.1}
    -   [pointers to retransmission queue and current
        segment[¶](#section-4-2.1.2.2){.pilcrow}]{#section-4-2.1.2.2}
    -   [pointers to Internet Protocol (IP)
        PCB[¶](#section-4-2.1.2.3){.pilcrow}]{#section-4-2.1.2.3}
    :::

-   ::: {#section-4-2.2}
    Per-connection shared state[¶](#section-4-2.2.1){.pilcrow}

    -   ::: {#section-4-2.2.2.1}
        macro-state[¶](#section-4-2.2.2.1.1){.pilcrow}

        -   [connection
            state[¶](#section-4-2.2.2.1.2.1){.pilcrow}]{#section-4-2.2.2.1.2.1}
        -   [timers[¶](#section-4-2.2.2.1.2.2){.pilcrow}]{#section-4-2.2.2.1.2.2}
        -   [flags[¶](#section-4-2.2.2.1.2.3){.pilcrow}]{#section-4-2.2.2.1.2.3}
        -   [local and remote host numbers and
            ports[¶](#section-4-2.2.2.1.2.4){.pilcrow}]{#section-4-2.2.2.1.2.4}
        -   [TCP option
            state[¶](#section-4-2.2.2.1.2.5){.pilcrow}]{#section-4-2.2.2.1.2.5}
        :::

    -   ::: {#section-4-2.2.2.2}
        micro-state[¶](#section-4-2.2.2.2.1){.pilcrow}

        -   [send and receive window state (size\*, current
            number)[¶](#section-4-2.2.2.2.2.1){.pilcrow}]{#section-4-2.2.2.2.2.1}
        -   [congestion window size
            (sendcwnd)\*[¶](#section-4-2.2.2.2.2.2){.pilcrow}]{#section-4-2.2.2.2.2.2}
        -   [congestion window size threshold
            (ssthresh)\*[¶](#section-4-2.2.2.2.2.3){.pilcrow}]{#section-4-2.2.2.2.2.3}
        -   [max window size
            seen\*[¶](#section-4-2.2.2.2.2.4){.pilcrow}]{#section-4-2.2.2.2.2.4}
        -   [sendMSS#[¶](#section-4-2.2.2.2.2.5){.pilcrow}]{#section-4-2.2.2.2.2.5}
        -   [MMS_S\#[¶](#section-4-2.2.2.2.2.6){.pilcrow}]{#section-4-2.2.2.2.2.6}
        -   [MMS_R\#[¶](#section-4-2.2.2.2.2.7){.pilcrow}]{#section-4-2.2.2.2.2.7}
        -   [PMTU#[¶](#section-4-2.2.2.2.2.8){.pilcrow}]{#section-4-2.2.2.2.2.8}
        -   [round-trip time and its
            variation#[¶](#section-4-2.2.2.2.2.9){.pilcrow}]{#section-4-2.2.2.2.2.9}
        :::
    :::

The per-connection information is shown as split into macro-state and
micro-state, terminology borrowed from \[[Co91](#Co91){.xref}\].
Macro-state describes the protocol for establishing the initial shared
state about the connection; we include the endpoint numbers and
components (timers, flags) required upon commencement that are later
used to help maintain that state. Micro-state describes the protocol
after a connection has been established, to maintain the reliability and
congestion control of the data transferred in the
connection.[¶](#section-4-3){.pilcrow}

We distinguish two other classes of shared micro-state that are
associated more with host-pairs than with application pairs. One class
is clearly host-pair dependent (shown above as \"#\", e.g., sendMSS,
MMS_R, MMS_S, PMTU, RTT), because these parameters are defined by the
endpoint or endpoint pair (of the given example: sendMSS, MMS_R, MMS_S,
RTT) or are already cached and shared on that basis (of the given
example: PMTU \[[RFC1191](#RFC1191){.xref}\]
\[[RFC4821](#RFC4821){.xref}\]). The other is host-pair dependent in its
aggregate (shown above as \"\*\", e.g., congestion window information,
current window sizes, etc.) because they depend on the total capacity
between the two endpoints.[¶](#section-4-4){.pilcrow}

Not all of the TCB state is necessarily shareable. In particular, some
TCP options are negotiated only upon request by the application layer,
so their use may not be correlated across connections. Other options
negotiate connection-specific parameters, which are similarly not
shareable. These are discussed further in [Appendix
B](#sect-b){.xref}.[¶](#section-4-5){.pilcrow}

Finally, we exclude rwnd from further discussion because its value
should depend on the send window size, so it is already addressed by
send window sharing and is not independently affected by
sharing.[¶](#section-4-6){.pilcrow}
:::
:::

::: {#sect-5}
::: {#section-5 .section}
## [5.](#section-5){.section-number .selfRef} [TCB Interdependence](#name-tcb-interdependence){.section-name .selfRef} {#name-tcb-interdependence}

There are two cases of TCB interdependence. Temporal sharing occurs when
the TCB of an earlier (now CLOSED) connection to a host is used to
initialize some parameters of a new connection to that same host, i.e.,
in sequence. Ensemble sharing occurs when a currently active connection
to a host is used to initialize another (concurrent) connection to that
host.[¶](#section-5-1){.pilcrow}
:::
:::

::: {#sect-6}
::: {#section-6 .section}
## [6.](#section-6){.section-number .selfRef} [Temporal Sharing](#name-temporal-sharing){.section-name .selfRef} {#name-temporal-sharing}

The TCB data cache is accessed in two ways: it is read to initialize new
TCBs and written when more current per-host state is
available.[¶](#section-6-1){.pilcrow}

::: {#sect-6.1}
::: {#section-6.1 .section}
### [6.1.](#section-6.1){.section-number .selfRef} [Initialization of a New TCB](#name-initialization-of-a-new-tcb){.section-name .selfRef} {#name-initialization-of-a-new-tcb}

TCBs for new connections can be initialized using cached context from
past connections as follows:[¶](#section-6.1-1){.pilcrow}

[]{#name-temporal-sharing-tcb-initia}

::: {#TCB_initialization}
  Cached TCB     New TCB
  -------------- -----------------------------
  old_MMS_S      old_MMS_S or not cached (2)
  old_MMS_R      old_MMS_R or not cached (2)
  old_sendMSS    old_sendMSS
  old_PMTU       old_PMTU (1)
  old_RTT        old_RTT
  old_RTTVAR     old_RTTVAR
  old_option     (option specific)
  old_ssthresh   old_ssthresh
  old_sendcwnd   old_sendcwnd

  : [Table 1](#table-1){.selfRef}: [Temporal Sharing - TCB
  Initialization](#name-temporal-sharing-tcb-initia){.selfRef}
:::

[]{.break}

\(1\)
:   Note that PMTU is cached at the IP layer
    \[[RFC1191](#RFC1191){.xref}\]
    \[[RFC4821](#RFC4821){.xref}\].[¶](#section-6.1-3.2){.pilcrow}
:   

\(2\)
:   Note that some values are not cached when they are computed locally
    (MMS_R) or indicated in the connection itself (MMS_S in the
    SYN).[¶](#section-6.1-3.4){.pilcrow}
:   

[Table 2](#Option_Info_Initialization){.xref} gives an overview of
option-specific information that can be shared. Additional information
on some specific TCP options and sharing is provided in [Appendix
B](#sect-b){.xref}.[¶](#section-6.1-4){.pilcrow}

[]{#name-temporal-sharing-option-inf}

::: {#Option_Info_Initialization}
  Cached            New
  ----------------- -----------------
  old_TFO_cookie    old_TFO_cookie
  old_TFO_failure   old_TFO_failure

  : [Table 2](#table-2){.selfRef}: [Temporal Sharing - Option Info
  Initialization](#name-temporal-sharing-option-inf){.selfRef}
:::
:::
:::

::: {#sect-6.2}
::: {#section-6.2 .section}
### [6.2.](#section-6.2){.section-number .selfRef} [Updates to the TCB Cache](#name-updates-to-the-tcb-cache){.section-name .selfRef} {#name-updates-to-the-tcb-cache}

During a connection, the TCB cache can be updated based on events of
current connections and their TCBs as they progress over time, as shown
in [Table 3](#Cache_Updates){.xref}.[¶](#section-6.2-1){.pilcrow}

[]{#name-temporal-sharing-cache-upda}

::: {#Cache_Updates}
  Cached TCB     Current TCB     When?                     New Cached TCB
  -------------- --------------- ------------------------- ---------------------
  old_MMS_S      curr_MMS_S      OPEN                      curr_MMS_S
  old_MMS_R      curr_MMS_R      OPEN                      curr_MMS_R
  old_sendMSS    curr_sendMSS    MSSopt                    curr_sendMSS
  old_PMTU       curr_PMTU       PMTUD (1) / PLPMTUD (1)   curr_PMTU
  old_RTT        curr_RTT        CLOSE                     merge(curr,old)
  old_RTTVAR     curr_RTTVAR     CLOSE                     merge(curr,old)
  old_option     curr_option     ESTAB                     (depends on option)
  old_ssthresh   curr_ssthresh   CLOSE                     merge(curr,old)
  old_sendcwnd   curr_sendcwnd   CLOSE                     merge(curr,old)

  : [Table 3](#table-3){.selfRef}: [Temporal Sharing - Cache
  Updates](#name-temporal-sharing-cache-upda){.selfRef}
:::

[]{.break}

\(1\)
:   Note that PMTU is cached at the IP layer
    \[[RFC1191](#RFC1191){.xref}\]
    \[[RFC4821](#RFC4821){.xref}\].[¶](#section-6.2-3.2){.pilcrow}
:   

Merge() is the function that combines the current and previous (old)
values and may vary for each parameter of the TCB cache. The particular
function is not specified in this document; examples include windowed
averages (mean of the past N values, for some N) and exponential decay
(new = (1-alpha)\*old + alpha \*new, where alpha is in the range
\[0..1\]).[¶](#section-6.2-4){.pilcrow}

[Table 4](#Option_Info_Updates){.xref} gives an overview of
option-specific information that can be similarly shared. The TFO cookie
is maintained until the client explicitly requests it be updated as a
separate event.[¶](#section-6.2-5){.pilcrow}

[]{#name-temporal-sharing-option-info}

::: {#Option_Info_Updates}
  Cached            Current           When?   New Cached
  ----------------- ----------------- ------- -----------------
  old_TFO_cookie    old_TFO_cookie    ESTAB   old_TFO_cookie
  old_TFO_failure   old_TFO_failure   ESTAB   old_TFO_failure

  : [Table 4](#table-4){.selfRef}: [Temporal Sharing - Option Info
  Updates](#name-temporal-sharing-option-info){.selfRef}
:::
:::
:::

::: {#sect-6.3}
::: {#section-6.3 .section}
### [6.3.](#section-6.3){.section-number .selfRef} [Discussion](#name-discussion){.section-name .selfRef} {#name-discussion}

As noted, there is no particular benefit to caching MMS_S and MMS_R as
these are reported by the local IP stack. Caching sendMSS and PMTU is
trivial; reported values are cached (PMTU at the IP layer), and the most
recent values are used. The cache is updated when the MSS option is
received in a SYN or after PMTUD (i.e., when an ICMPv4 Fragmentation
Needed \[[RFC1191](#RFC1191){.xref}\] or ICMPv6 Packet Too Big message
is received \[[RFC8201](#RFC8201){.xref}\] or the equivalent is
inferred, e.g., as from PLPMTUD \[[RFC4821](#RFC4821){.xref}\]),
respectively, so the cache always has the most recent values from any
connection. For sendMSS, the cache is consulted only at connection
establishment and not otherwise updated, which means that MSS options do
not affect current connections. The default sendMSS is never saved; only
reported MSS values update the cache, so an explicit override is
required to reduce the sendMSS. Cached sendMSS affects only data sent in
the SYN segment, i.e., during client connection initiation or during
simultaneous open; the MSS of all other segments are constrained by the
value updated as included in the SYN.[¶](#section-6.3-1){.pilcrow}

RTT values are updated by formulae that merge the old and new values, as
noted in [Section 6.2](#sect-6.2){.xref}. Dynamic RTT estimation
requires a sequence of RTT measurements. As a result, the cached RTT
(and its variation) is an average of its previous value with the
contents of the currently active TCB for that host, when a TCB is
closed. RTT values are updated only when a connection is closed. The
method for merging old and current values needs to attempt to reduce the
transient effects of the new connections.[¶](#section-6.3-2){.pilcrow}

The updates for RTT, RTTVAR, and ssthresh rely on existing information,
i.e., old values. Should no such values exist, the current values are
cached instead.[¶](#section-6.3-3){.pilcrow}

TCP options are copied or merged depending on the details of each
option. For example, TFO state is updated when a connection is
established and read before establishing a new
connection.[¶](#section-6.3-4){.pilcrow}

Sections [8](#sect-8){.xref} and [9](#sect-9){.xref} discuss
compatibility issues and implications of sharing the specific
information listed above. [Section 10](#sect-10){.xref} gives an
overview of known implementations.[¶](#section-6.3-5){.pilcrow}

Most cached TCB values are updated when a connection closes. The
exceptions are MMS_R and MMS_S, which are reported by IP
\[[RFC1122](#RFC1122){.xref}\]; PMTU, which is updated after Path MTU
Discovery and also reported by IP \[[RFC1191](#RFC1191){.xref}\]
\[[RFC4821](#RFC4821){.xref}\] \[[RFC8201](#RFC8201){.xref}\]; and
sendMSS, which is updated if the MSS option is received in the TCP SYN
header.[¶](#section-6.3-6){.pilcrow}

Sharing sendMSS information affects only data in the SYN of the next
connection, because sendMSS information is typically included in most
TCP SYN segments. Caching PMTU can accelerate the efficiency of PMTUD
but can also result in black-holing until corrected if in error. Caching
MMS_R and MMS_S may be of little direct value as they are reported by
the local IP stack anyway.[¶](#section-6.3-7){.pilcrow}

The way in which state related to other TCP options can be shared
depends on the details of that option. For example, TFO state includes
the TCP Fast Open cookie \[[RFC7413](#RFC7413){.xref}\] or, in case TFO
fails, a negative TCP Fast Open response. RFC 7413
states,[¶](#section-6.3-8){.pilcrow}

> The client [MUST]{.bcp14} cache negative responses from the server in
> order to avoid potential connection failures. Negative responses
> include the server not acknowledging the data in the SYN, ICMP error
> messages, and (most importantly) no response (SYN-ACK) from the server
> at all, i.e., connection timeout.[¶](#section-6.3-9){.pilcrow}

TFOinfo is cached when a connection is
established.[¶](#section-6.3-10){.pilcrow}

State related to other TCP options might not be as readily cached. For
example, TCP-AO \[[RFC5925](#RFC5925){.xref}\] success or failure
between a host-pair for a single SYN destination port might be usefully
cached. TCP-AO success or failure to other SYN destination ports on that
host-pair is never useful to cache because TCP-AO security parameters
can vary per service.[¶](#section-6.3-11){.pilcrow}
:::
:::
:::
:::

::: {#sect-7}
::: {#section-7 .section}
## [7.](#section-7){.section-number .selfRef} [Ensemble Sharing](#name-ensemble-sharing){.section-name .selfRef} {#name-ensemble-sharing}

Sharing cached TCB data across concurrent connections requires attention
to the aggregate nature of some of the shared state. For example,
although MSS and RTT values can be shared by copying, it may not be
appropriate to simply copy congestion window or ssthresh information;
instead, the new values can be a function (f) of the cumulative values
and the number of connections (N).[¶](#section-7-1){.pilcrow}

::: {#sect-7.1}
::: {#section-7.1 .section}
### [7.1.](#section-7.1){.section-number .selfRef} [Initialization of a New TCB](#name-initialization-of-a-new-tcb-2){.section-name .selfRef} {#name-initialization-of-a-new-tcb-2}

TCBs for new connections can be initialized using cached context from
concurrent connections as follows:[¶](#section-7.1-1){.pilcrow}

[]{#name-ensemble-sharing-tcb-initia}

::: {#TCB_Initialization}
  Cached TCB          New TCB
  ------------------- -------------------------
  old_MMS_S           old_MMS_S
  old_MMS_R           old_MMS_R
  old_sendMSS         old_sendMSS
  old_PMTU            old_PMTU (1)
  old_RTT             old_RTT
  old_RTTVAR          old_RTTVAR
  sum(old_ssthresh)   f(sum(old_ssthresh), N)
  sum(old_sendcwnd)   f(sum(old_sendcwnd), N)
  old_option          (option specific)

  : [Table 5](#table-5){.selfRef}: [Ensemble Sharing - TCB
  Initialization](#name-ensemble-sharing-tcb-initia){.selfRef}
:::

[]{.break}

\(1\)
:   Note that PMTU is cached at the IP layer
    \[[RFC1191](#RFC1191){.xref}\]
    \[[RFC4821](#RFC4821){.xref}\].[¶](#section-7.1-3.2){.pilcrow}
:   

In [Table 5](#TCB_Initialization){.xref}, the cached sum() is a total
across all active connections because these parameters act in aggregate;
similarly, f() is a function that updates that sum based on the new
connection\'s values, represented as \"N\".[¶](#section-7.1-4){.pilcrow}

[Table 6](#Ensemble_Option_Info_Initialization){.xref} gives an overview
of option-specific information that can be similarly shared. Again, the
TFO_cookie is updated upon explicit client request, which is a separate
event.[¶](#section-7.1-5){.pilcrow}

[]{#name-ensemble-sharing-option-inf}

::: {#Ensemble_Option_Info_Initialization}
  Cached            New
  ----------------- -----------------
  old_TFO_cookie    old_TFO_cookie
  old_TFO_failure   old_TFO_failure

  : [Table 6](#table-6){.selfRef}: [Ensemble Sharing - Option Info
  Initialization](#name-ensemble-sharing-option-inf){.selfRef}
:::
:::
:::

::: {#sect-7.2}
::: {#section-7.2 .section}
### [7.2.](#section-7.2){.section-number .selfRef} [Updates to the TCB Cache](#name-updates-to-the-tcb-cache-2){.section-name .selfRef} {#name-updates-to-the-tcb-cache-2}

During a connection, the TCB cache can be updated based on changes to
concurrent connections and their TCBs, as shown
below:[¶](#section-7.2-1){.pilcrow}

[]{#name-ensemble-sharing-cache-upda}

::: {#Ensemble_Cache_Updates}
  Cached TCB     Current TCB     When?               New Cached TCB
  -------------- --------------- ------------------- ---------------------------
  old_MMS_S      curr_MMS_S      OPEN                curr_MMS_S
  old_MMS_R      curr_MMS_R      OPEN                curr_MMS_R
  old_sendMSS    curr_sendMSS    MSSopt              curr_sendMSS
  old_PMTU       curr_PMTU       PMTUD+ / PLPMTUD+   curr_PMTU
  old_RTT        curr_RTT        update              rtt_update(old, curr)
  old_RTTVAR     curr_RTTVAR     update              rtt_update(old, curr)
  old_ssthresh   curr_ssthresh   update              adjust sum as appropriate
  old_sendcwnd   curr_sendcwnd   update              adjust sum as appropriate
  old_option     curr_option     (depends)           (option specific)

  : [Table 7](#table-7){.selfRef}: [Ensemble Sharing - Cache
  Updates](#name-ensemble-sharing-cache-upda){.selfRef}
:::

[]{.break}

\+
:   Note that the PMTU is cached at the IP layer
    \[[RFC1191](#RFC1191){.xref}\]
    \[[RFC4821](#RFC4821){.xref}\].[¶](#section-7.2-3.2){.pilcrow}
:   

In [Table 7](#Ensemble_Cache_Updates){.xref}, rtt_update() is the
function used to combine old and current values, e.g., as a windowed
average or exponentially decayed average.[¶](#section-7.2-4){.pilcrow}

[Table 8](#Ensemble_Option_Info_Updates){.xref} gives an overview of
option-specific information that can be similarly
shared.[¶](#section-7.2-5){.pilcrow}

[]{#name-ensemble-sharing-option-info}

::: {#Ensemble_Option_Info_Updates}
  Cached            Current           When?   New Cached
  ----------------- ----------------- ------- -----------------
  old_TFO_cookie    old_TFO_cookie    ESTAB   old_TFO_cookie
  old_TFO_failure   old_TFO_failure   ESTAB   old_TFO_failure

  : [Table 8](#table-8){.selfRef}: [Ensemble Sharing - Option Info
  Updates](#name-ensemble-sharing-option-info){.selfRef}
:::
:::
:::

::: {#sect-7.3}
::: {#section-7.3 .section}
### [7.3.](#section-7.3){.section-number .selfRef} [Discussion](#name-discussion-2){.section-name .selfRef} {#name-discussion-2}

For ensemble sharing, TCB information should be cached as early as
possible, sometimes before a connection is closed. Otherwise, opening
multiple concurrent connections may not result in TCB data sharing if no
connection closes before others open. The amount of work involved in
updating the aggregate average should be minimized, but the resulting
value should be equivalent to having all values measured within a single
connection. The function \"rtt_update\" in [Table
7](#Ensemble_Cache_Updates){.xref} indicates this operation, which
occurs whenever the RTT would have been updated in the individual TCP
connection. As a result, the cache contains the shared RTT variables,
which no longer need to reside in the TCB.[¶](#section-7.3-1){.pilcrow}

Congestion window size and ssthresh aggregation are more complicated in
the concurrent case. When there is an ensemble of connections, we need
to decide how that ensemble would have shared these variables, in order
to derive initial values for new TCBs.[¶](#section-7.3-2){.pilcrow}

Sections [8](#sect-8){.xref} and [9](#sect-9){.xref} discuss
compatibility issues and implications of sharing the specific
information listed above.[¶](#section-7.3-3){.pilcrow}

There are several ways to initialize the congestion window in a new TCB
among an ensemble of current connections to a host. Current TCP
implementations initialize it to 4 segments as standard
\[[RFC3390](#RFC3390){.xref}\] and 10 segments experimentally
\[[RFC6928](#RFC6928){.xref}\]. These approaches assume that new
connections should behave as conservatively as possible. The algorithm
described in \[[Ba12](#Ba12){.xref}\] adjusts the initial cwnd depending
on the cwnd values of ongoing connections. It is also possible to use
sharing mechanisms over long timescales to adapt TCP\'s initial window
automatically, as described further in [Appendix
C](#sect-c){.xref}.[¶](#section-7.3-4){.pilcrow}
:::
:::
:::
:::

::: {#sect-8}
::: {#section-8 .section}
## [8.](#section-8){.section-number .selfRef} [Issues with TCB Information Sharing](#name-issues-with-tcb-information){.section-name .selfRef} {#name-issues-with-tcb-information}

Here, we discuss various types of problems that may arise with TCB
information sharing.[¶](#section-8-1){.pilcrow}

For the congestion and current window information, the initial values
computed by TCB interdependence may not be consistent with the long-term
aggregate behavior of a set of concurrent connections between the same
endpoints. Under conventional TCP congestion control, if the congestion
window of a single existing connection has converged to 40 segments, two
newly joining concurrent connections will assume initial windows of 10
segments \[[RFC6928](#RFC6928){.xref}\] and the existing connection\'s
window will not decrease to accommodate this additional load. As a
consequence, the three connections can mutually interfere. One example
of this is seen on low-bandwidth, high-delay links, where concurrent
connections supporting Web traffic can collide because their initial
windows were too large, even when set at 1
segment.[¶](#section-8-2){.pilcrow}

The authors of \[[Hu12](#Hu12){.xref}\] recommend caching ssthresh for
temporal sharing only when flows are long. Some studies suggest that
sharing ssthresh between short flows can deteriorate the performance of
individual connections \[[Hu12](#Hu12){.xref}\]
\[[Du16](#Du16){.xref}\], although this may benefit aggregate network
performance.[¶](#section-8-3){.pilcrow}

::: {#sect-8.1}
::: {#section-8.1 .section}
### [8.1.](#section-8.1){.section-number .selfRef} [Traversing the Same Network Path](#name-traversing-the-same-network){.section-name .selfRef} {#name-traversing-the-same-network}

TCP is sometimes used in situations where packets of the same host-pair
do not always take the same path, such as when connection-specific
parameters are used for routing (e.g., for load balancing). Multipath
routing that relies on examining transport headers, such as ECMP and
Link Aggregation Group (LAG) \[[RFC7424](#RFC7424){.xref}\], may not
result in repeatable path selection when TCP segments are encapsulated,
encrypted, or altered \-- for example, in some Virtual Private Network
(VPN) tunnels that rely on proprietary encapsulation. Similarly, such
approaches cannot operate deterministically when the TCP header is
encrypted, e.g., when using IPsec Encapsulating Security Payload (ESP)
(although TCB interdependence among the entire set sharing the same
endpoint IP addresses should work without problems when the TCP header
is encrypted). Measures to increase the probability that connections use
the same path could be applied; for example, the connections could be
given the same IPv6 flow label \[[RFC6437](#RFC6437){.xref}\]. TCB
interdependence can also be extended to sets of host IP address pairs
that share the same network path conditions, such as when a group of
addresses is on the same LAN (see [Section
9](#sect-9){.xref}).[¶](#section-8.1-1){.pilcrow}

Traversing the same path is not important for host-specific information
(e.g., rwnd), TCP option state (e.g., TFOinfo), or for information that
is already cached per-host (e.g., path MTU). When TCB information is
shared across different SYN destination ports, path-related information
can be incorrect; however, the impact of this error is potentially
diminished if (as discussed here) TCB sharing affects only the transient
event of a connection start or if TCB information is shared only within
connections to the same SYN destination
port.[¶](#section-8.1-2){.pilcrow}

In the case of temporal sharing, TCB information could also become
invalid over time, i.e., indicating that although the path remains the
same, path properties have changed. Because this is similar to the case
when a connection becomes idle, mechanisms that address idle TCP
connections (e.g., \[[RFC7661](#RFC7661){.xref}\]) could also be applied
to TCB cache management, especially when TCP Fast Open is used
\[[RFC7413](#RFC7413){.xref}\].[¶](#section-8.1-3){.pilcrow}
:::
:::

::: {#sect-8.2}
::: {#section-8.2 .section}
### [8.2.](#section-8.2){.section-number .selfRef} [State Dependence](#name-state-dependence){.section-name .selfRef} {#name-state-dependence}

There may be additional considerations to the way in which TCB
interdependence rebalances congestion feedback among the current
connections. For example, it may be appropriate to consider the impact
of a connection being in Fast Recovery \[[RFC5681](#RFC5681){.xref}\] or
some other similar unusual feedback state that could inhibit or affect
the calculations described herein.[¶](#section-8.2-1){.pilcrow}
:::
:::

::: {#sect-8.3}
::: {#section-8.3 .section}
### [8.3.](#section-8.3){.section-number .selfRef} [Problems with Sharing Based on IP Address](#name-problems-with-sharing-based){.section-name .selfRef} {#name-problems-with-sharing-based}

It can be wrong to share TCB information between TCP connections on the
same host as identified by the IP address if an IP address is assigned
to a new host (e.g., IP address spinning, as is used by ISPs to inhibit
running servers). It can be wrong if Network Address Translation (NAT)
\[[RFC2663](#RFC2663){.xref}\], Network Address and Port Translation
(NAPT) \[[RFC2663](#RFC2663){.xref}\], or any other IP sharing mechanism
is used. Such mechanisms are less likely to be used with IPv6. Other
methods to identify a host could also be considered to make correct TCB
sharing more likely. Moreover, some TCB information is about dominant
path properties rather than the specific host. IP addresses may differ,
yet the relevant part of the path may be the
same.[¶](#section-8.3-1){.pilcrow}
:::
:::
:::
:::

::: {#sect-9}
::: {#section-9 .section}
## [9.](#section-9){.section-number .selfRef} [Implications](#name-implications){.section-name .selfRef} {#name-implications}

There are several implications to incorporating TCB interdependence in
TCP implementations. First, it may reduce the need for application-layer
multiplexing for performance enhancement \[[RFC7231](#RFC7231){.xref}\].
Protocols like HTTP/2 \[[RFC7540](#RFC7540){.xref}\] avoid connection
re-establishment costs by serializing or multiplexing a set of per-host
connections across a single TCP connection. This avoids TCP\'s
per-connection OPEN handshake and also avoids recomputing the MSS, RTT,
and congestion window values. By avoiding the so-called \"slow-start
restart\", performance can be optimized
\[[Hu01](#I-D.hughes-restart){.xref}\]. TCB interdependence can provide
the \"slow-start restart avoidance\" of multiplexing, without requiring
a multiplexing mechanism at the application
layer.[¶](#section-9-1){.pilcrow}

Like the initial version of this document
\[[RFC2140](#RFC2140){.xref}\], this update\'s approach to TCB
interdependence focuses on sharing a set of TCBs by updating the TCB
state to reduce the impact of transients when connections begin, end, or
otherwise significantly change state. Other mechanisms have since been
proposed to continuously share information between all ongoing
communication (including connectionless protocols) and update the
congestion state during any congestion-related event (e.g., timeout,
loss confirmation, etc.) \[[RFC3124](#RFC3124){.xref}\]. By dealing
exclusively with transients, the approach in this document is more
likely to exhibit the \"steady-state\" behavior as unmodified,
independent TCP connections.[¶](#section-9-2){.pilcrow}

::: {#sect-9.1}
::: {#section-9.1 .section}
### [9.1.](#section-9.1){.section-number .selfRef} [Layering](#name-layering){.section-name .selfRef} {#name-layering}

TCB interdependence pushes some of the TCP implementation from its
typical placement solely within the transport layer (in the ISO model)
to the network layer. This acknowledges that some components of state
are, in fact, per-host-pair or can be per-path as indicated solely by
that host-pair. Transport protocols typically manage
per-application-pair associations (per stream), and network protocols
manage per-host-pair and path associations (routing). Round-trip time,
MSS, and congestion information could be more appropriately handled at
the network layer, aggregated among concurrent connections, and shared
across connection instances
\[[RFC3124](#RFC3124){.xref}\].[¶](#section-9.1-1){.pilcrow}

An earlier version of RTT sharing suggested implementing RTT state at
the IP layer rather than at the TCP layer. Our observations describe
sharing state among TCP connections, which avoids some of the
difficulties in an IP-layer solution. One such problem of an IP-layer
solution is determining the correspondence between packet exchanges
using IP header information alone, where such correspondence is needed
to compute RTT. Because TCB sharing computes RTTs inside the TCP layer
using TCP header information, it can be implemented more directly and
simply than at the IP layer. This is a case where information should be
computed at the transport layer but could be shared at the network
layer.[¶](#section-9.1-2){.pilcrow}
:::
:::

::: {#sect-9.2}
::: {#section-9.2 .section}
### [9.2.](#section-9.2){.section-number .selfRef} [Other Possibilities](#name-other-possibilities){.section-name .selfRef} {#name-other-possibilities}

Per-host-pair associations are not the limit of these techniques. It is
possible that TCBs could be similarly shared between hosts on a subnet
or within a cluster, because the predominant path can be subnet-subnet
rather than host-host. Additionally, TCB interdependence can be applied
to any protocol with congestion state, including SCTP
\[[RFC4960](#RFC4960){.xref}\] and DCCP \[[RFC4340](#RFC4340){.xref}\],
as well as to individual subflows in Multipath TCP
\[[RFC8684](#RFC8684){.xref}\].[¶](#section-9.2-1){.pilcrow}

There may be other information that can be shared between concurrent
connections. For example, knowing that another connection has just tried
to expand its window size and failed, a connection may not attempt to do
the same for some period. The idea is that existing TCP implementations
infer the behavior of all competing connections, including those within
the same host or subnet. One possible optimization is to make that
implicit feedback explicit, via extended information associated with the
endpoint IP address and its TCP implementation, rather than
per-connection state in the TCB.[¶](#section-9.2-2){.pilcrow}

This document focuses on sharing TCB information at connection
initialization. Subsequent to RFC 2140, there have been numerous
approaches that attempt to coordinate ongoing state across concurrent
connections, both within TCP and other congestion-reactive protocols,
which are summarized in \[[Is18](#Is18){.xref}\]. These approaches are
more complex to implement, and their comparison to steady-state TCP
equivalence can be more difficult to establish, sometimes intentionally
(i.e., they sometimes intend to provide a different kind of \"fairness\"
than emerges from TCP operation).[¶](#section-9.2-3){.pilcrow}
:::
:::
:::
:::

::: {#sect-10}
::: {#section-10 .section}
## [10.](#section-10){.section-number .selfRef} [Implementation Observations](#name-implementation-observations){.section-name .selfRef} {#name-implementation-observations}

The observation that some TCB state is host-pair specific rather than
application-pair dependent is not new and is a common engineering
decision in layered protocol implementations. Although now deprecated,
T/TCP \[[RFC1644](#RFC1644){.xref}\] was the first to propose using
caches in order to maintain TCB states (see [Appendix
A](#sect-a){.xref}).[¶](#section-10-1){.pilcrow}

[Table 9](#Known_Implementation_Status){.xref} describes the current
implementation status for TCB temporal sharing in Windows as of December
2020, Apple variants (macOS, iOS, iPadOS, tvOS, and watchOS) as of
January 2021, Linux kernel version 5.10.3, and FreeBSD 12. Ensemble
sharing is not yet implemented.[¶](#section-10-2){.pilcrow}

[]{#name-known-implementation-status}

::: {#Known_Implementation_Status}
  TCB data       Status
  -------------- -----------------------------------------------------
  old_MMS_S      Not shared
  old_MMS_R      Not shared
  old_sendMSS    Cached and shared in Apple, Linux (MSS)
  old_PMTU       Cached and shared in Apple, FreeBSD, Windows (PMTU)
  old_RTT        Cached and shared in Apple, FreeBSD, Linux, Windows
  old_RTTVAR     Cached and shared in Apple, FreeBSD, Windows
  old_TFOinfo    Cached and shared in Apple, Linux, Windows
  old_sendcwnd   Not shared
  old_ssthresh   Cached and shared in Apple, FreeBSD\*, Linux\*
  TFO failure    Cached and shared in Apple

  : [Table 9](#table-9){.selfRef}: [KNOWN IMPLEMENTATION
  STATUS](#name-known-implementation-status){.selfRef}
:::

[]{.break}

\*
:   Note: In FreeBSD, new ssthresh is the mean of curr_ssthresh and its
    previous value if a previous value exists; in Linux, the calculation
    depends on state and is max(curr_cwnd/2, old_ssthresh) in most
    cases.[¶](#section-10-4.2){.pilcrow}
:   

In [Table 9](#Known_Implementation_Status){.xref}, \"Apple\" refers to
all Apple OSes, i.e., macOS (desktop/laptop), iOS (phone), iPadOS
(tablet), tvOS (video player), and watchOS (smart watch), which all
share the same Internet protocol stack.[¶](#section-10-5){.pilcrow}
:::
:::

::: {#sect-11}
::: {#section-11 .section}
## [11.](#section-11){.section-number .selfRef} [Changes Compared to RFC 2140](#name-changes-compared-to-rfc-214){.section-name .selfRef} {#name-changes-compared-to-rfc-214}

This document updates the description of TCB sharing in RFC 2140 and its
associated impact on existing and new connection state, providing a
complete replacement for that document \[[RFC2140](#RFC2140){.xref}\].
It clarifies the previous description and terminology and extends the
mechanism to its impact on new protocols and mechanisms, including
multipath TCP, Fast Open, PLPMTUD, NAT, and the TCP Authentication
Option.[¶](#section-11-1){.pilcrow}

The detailed impact on TCB state addresses TCB parameters with greater
specificity. It separates the way MSS is used in both send and receive
directions, it separates the way both of these MSS values differ from
sendMSS, it adds both path MTU and ssthresh, and it addresses the impact
on state associated with TCP options.[¶](#section-11-2){.pilcrow}

New sections have been added to address compatibility issues and
implementation observations. The relation of this work to T/TCP has been
moved to [Appendix A](#sect-a){.xref} (which describes the history to
TCB sharing) partly to reflect the deprecation of that
protocol.[¶](#section-11-3){.pilcrow}

[Appendix C](#sect-c){.xref} has been added to discuss the potential to
use temporal sharing over long timescales to adapt TCP\'s initial window
automatically, avoiding the need to periodically revise a single global
constant value.[¶](#section-11-4){.pilcrow}

Finally, this document updates and significantly expands the referenced
literature.[¶](#section-11-5){.pilcrow}
:::
:::

::: {#sect-12}
::: {#section-12 .section}
## [12.](#section-12){.section-number .selfRef} [Security Considerations](#name-security-considerations){.section-name .selfRef} {#name-security-considerations}

These presented implementation methods do not have additional
ramifications for direct (connection-aborting or information-injecting)
attacks on individual connections. Individual connections, whether using
sharing or not, also may be susceptible to denial-of-service attacks
that reduce performance or completely deny connections and transfers if
not otherwise secured.[¶](#section-12-1){.pilcrow}

TCB sharing may create additional denial-of-service attacks that affect
the performance of other connections by polluting the cached
information. This can occur across any set of connections in which the
TCB is shared, between connections in a single host, or between hosts if
TCB sharing is implemented within a subnet (see
[\"Implications\"](#sect-9){.xref} ([Section 9](#sect-9){.xref})). Some
shared TCB parameters are used only to create new TCBs; others are
shared among the TCBs of ongoing connections. New connections can join
the ongoing set, e.g., to optimize send window size among a set of
connections to the same host. PMTU is defined as shared at the IP layer
and is already susceptible in this way.[¶](#section-12-2){.pilcrow}

Options in client SYNs can be easier to forge than complete, two-way
connections. As a result, their values may not be safely incorporated in
shared values until after the three-way handshake
completes.[¶](#section-12-3){.pilcrow}

Attacks on parameters used only for initialization affect only the
transient performance of a TCP connection. For short connections, the
performance ramification can approach that of a denial-of-service
attack. For example, if an application changes its TCB to have a false
and small window size, subsequent connections will experience
performance degradation until their window grows
appropriately.[¶](#section-12-4){.pilcrow}

TCB sharing reuses and mixes information from past and current
connections. Although reusing information could create a potential for
fingerprinting to identify hosts, the mixing reduces that potential.
There has been no evidence of fingerprinting based on this technique,
and it is currently considered safe in that regard. Further, information
about the performance of a TCP connection has not been considered as
private.[¶](#section-12-5){.pilcrow}
:::
:::

::: {#sect-13}
::: {#section-13 .section}
## [13.](#section-13){.section-number .selfRef} [IANA Considerations](#name-iana-considerations){.section-name .selfRef} {#name-iana-considerations}

This document has no IANA actions.[¶](#section-13-1){.pilcrow}
:::
:::

::: {#section-14 .section}
## [14.](#section-14){.section-number .selfRef} [References](#name-references){.section-name .selfRef} {#name-references}

::: {#section-14.1 .section}
### [14.1.](#section-14.1){.section-number .selfRef} [Normative References](#name-normative-references){.section-name .selfRef} {#name-normative-references}

\[RFC0793\]
:   [Postel, J.]{.refAuthor}, [\"Transmission Control
    Protocol\"]{.refTitle}, [STD 7]{.seriesInfo}, [RFC
    793]{.seriesInfo}, [DOI 10.17487/RFC0793]{.seriesInfo}, September
    1981, \<<https://www.rfc-editor.org/info/rfc793>\>.
:   

\[RFC1122\]
:   [Braden, R., Ed.]{.refAuthor}, [\"Requirements for Internet Hosts -
    Communication Layers\"]{.refTitle}, [STD 3]{.seriesInfo}, [RFC
    1122]{.seriesInfo}, [DOI 10.17487/RFC1122]{.seriesInfo}, October
    1989, \<<https://www.rfc-editor.org/info/rfc1122>\>.
:   

\[RFC1191\]
:   [Mogul, J.]{.refAuthor} and [S. Deering]{.refAuthor}, [\"Path MTU
    discovery\"]{.refTitle}, [RFC 1191]{.seriesInfo}, [DOI
    10.17487/RFC1191]{.seriesInfo}, November 1990,
    \<<https://www.rfc-editor.org/info/rfc1191>\>.
:   

\[RFC2119\]
:   [Bradner, S.]{.refAuthor}, [\"Key words for use in RFCs to Indicate
    Requirement Levels\"]{.refTitle}, [BCP 14]{.seriesInfo}, [RFC
    2119]{.seriesInfo}, [DOI 10.17487/RFC2119]{.seriesInfo}, March 1997,
    \<<https://www.rfc-editor.org/info/rfc2119>\>.
:   

\[RFC4821\]
:   [Mathis, M.]{.refAuthor} and [J. Heffner]{.refAuthor},
    [\"Packetization Layer Path MTU Discovery\"]{.refTitle}, [RFC
    4821]{.seriesInfo}, [DOI 10.17487/RFC4821]{.seriesInfo}, March 2007,
    \<<https://www.rfc-editor.org/info/rfc4821>\>.
:   

\[RFC5681\]
:   [Allman, M.]{.refAuthor}, [Paxson, V.]{.refAuthor}, and [E.
    Blanton]{.refAuthor}, [\"TCP Congestion Control\"]{.refTitle}, [RFC
    5681]{.seriesInfo}, [DOI 10.17487/RFC5681]{.seriesInfo}, September
    2009, \<<https://www.rfc-editor.org/info/rfc5681>\>.
:   

\[RFC6298\]
:   [Paxson, V.]{.refAuthor}, [Allman, M.]{.refAuthor},
    [Chu, J.]{.refAuthor}, and [M. Sargent]{.refAuthor}, [\"Computing
    TCP\'s Retransmission Timer\"]{.refTitle}, [RFC 6298]{.seriesInfo},
    [DOI 10.17487/RFC6298]{.seriesInfo}, June 2011,
    \<<https://www.rfc-editor.org/info/rfc6298>\>.
:   

\[RFC7413\]
:   [Cheng, Y.]{.refAuthor}, [Chu, J.]{.refAuthor},
    [Radhakrishnan, S.]{.refAuthor}, and [A. Jain]{.refAuthor}, [\"TCP
    Fast Open\"]{.refTitle}, [RFC 7413]{.seriesInfo}, [DOI
    10.17487/RFC7413]{.seriesInfo}, December 2014,
    \<<https://www.rfc-editor.org/info/rfc7413>\>.
:   

\[RFC8174\]
:   [Leiba, B.]{.refAuthor}, [\"Ambiguity of Uppercase vs Lowercase in
    RFC 2119 Key Words\"]{.refTitle}, [BCP 14]{.seriesInfo}, [RFC
    8174]{.seriesInfo}, [DOI 10.17487/RFC8174]{.seriesInfo}, May 2017,
    \<<https://www.rfc-editor.org/info/rfc8174>\>.
:   

\[RFC8201\]
:   [McCann, J.]{.refAuthor}, [Deering, S.]{.refAuthor},
    [Mogul, J.]{.refAuthor}, and [R. Hinden, Ed.]{.refAuthor}, [\"Path
    MTU Discovery for IP version 6\"]{.refTitle}, [STD 87]{.seriesInfo},
    [RFC 8201]{.seriesInfo}, [DOI 10.17487/RFC8201]{.seriesInfo}, July
    2017, \<<https://www.rfc-editor.org/info/rfc8201>\>.
:   
:::

::: {#section-14.2 .section}
### [14.2.](#section-14.2){.section-number .selfRef} [Informative References](#name-informative-references){.section-name .selfRef} {#name-informative-references}

\[Al10\]
:   [Allman, M.]{.refAuthor}, [\"Initial Congestion Window
    Specification\"]{.refTitle}, [Work in Progress]{.refContent},
    [Internet-Draft, draft-allman-tcpm-bump-initcwnd-00]{.seriesInfo},
    15 November 2010,
    \<<https://datatracker.ietf.org/doc/html/draft-allman-tcpm-bump-initcwnd-00>\>.
:   

\[Ba12\]
:   [Barik, R.]{.refAuthor}, [Welzl, M.]{.refAuthor},
    [Ferlin, S.]{.refAuthor}, and [O. Alay]{.refAuthor}, [\"LISA: A
    linked slow-start algorithm for MPTCP\"]{.refTitle}, [IEEE ICC
    ]{.refContent}, [DOI 10.1109/ICC.2016.7510786]{.seriesInfo}, May
    2016, \<<https://doi.org/10.1109/ICC.2016.7510786>\>.
:   

\[Ba20\]
:   [Bagnulo, M.]{.refAuthor} and [B. Briscoe]{.refAuthor}, [\"ECN++:
    Adding Explicit Congestion Notification (ECN) to TCP Control
    Packets\"]{.refTitle}, [Work in Progress]{.refContent},
    [Internet-Draft, draft-ietf-tcpm-generalized-ecn-07]{.seriesInfo},
    16 February 2021,
    \<<https://datatracker.ietf.org/doc/html/draft-ietf-tcpm-generalized-ecn-07>\>.
:   

\[Be94\]
:   [Berners-Lee, T.]{.refAuthor}, [Cailliau, C.]{.refAuthor},
    [Luotonen, A.]{.refAuthor}, [Nielsen, H.]{.refAuthor}, and [A.
    Secret]{.refAuthor}, [\"The World-Wide Web\"]{.refTitle},
    [Communications of the ACM V37, pp. 76-82]{.refContent}, [DOI
    10.1145/179606.179671]{.seriesInfo}, August 1994,
    \<<https://doi.org/10.1145/179606.179671>\>.
:   

\[Br02\]
:   [Brownlee, N.]{.refAuthor} and [KC. Claffy]{.refAuthor},
    [\"Understanding Internet traffic streams: dragonflies and
    tortoises\"]{.refTitle}, [IEEE Communications Magazine, pp.
    110-117]{.refContent}, [DOI 10.1109/MCOM.2002.1039865]{.seriesInfo},
    2002, \<<https://doi.org/10.1109/MCOM.2002.1039865>\>.
:   

\[Br94\]
:   [Braden, B.]{.refAuthor}, [\"T/TCP \-- Transaction TCP: Source
    Changes for Sun OS 4.1.3\"]{.refTitle}, [USC/ISI Release
    1.0]{.refContent}, September 1994.
:   

\[Co91\]
:   [Comer, D.]{.refAuthor} and [D. Stevens]{.refAuthor},
    [\"Internetworking with TCP/IP\"]{.refTitle}, [ISBN 10:
    0134685059]{.seriesInfo}, [ISBN 13:
    9780134685052]{.seriesInfo}, 1991.
:   

\[Du16\]
:   [Dukkipati, N.]{.refAuthor}, [Cheng, Y.]{.refAuthor}, and [A.
    Vahdat]{.refAuthor}, [\"Research Impacting the Practice of
    Congestion Control\"]{.refTitle}, [Computer Communication
    Review]{.refContent}, [The ACM SIGCOMM newsletter]{.refContent},
    July 2016.
:   

\[FreeBSD\]
:   [FreeBSD]{.refAuthor}, [\"The FreeBSD Project\"]{.refTitle},
    \<<https://www.freebsd.org/>\>.
:   

\[Hu01\]
:   [Hughes, A.]{.refAuthor}, [Touch, J.]{.refAuthor}, and [J.
    Heidemann]{.refAuthor}, [\"Issues in TCP Slow-Start Restart After
    Idle\"]{.refTitle}, [Work in Progress]{.refContent},
    [Internet-Draft, draft-hughes-restart-00]{.seriesInfo}, December
    2001,
    \<<https://datatracker.ietf.org/doc/html/draft-hughes-restart-00>\>.
:   

\[Hu12\]
:   [Hurtig, P.]{.refAuthor} and [A. Brunstrom]{.refAuthor}, [\"Enhanced
    metric caching for short TCP flows\"]{.refTitle}, [IEEE
    International Conference on Communications]{.refContent}, [DOI
    10.1109/ICC.2012.6364516]{.seriesInfo}, 2012,
    \<<https://doi.org/10.1109/ICC.2012.6364516>\>.
:   

\[IANA\]
:   [IANA]{.refAuthor}, [\"Transmission Control Protocol (TCP)
    Parameters\"]{.refTitle},
    \<<https://www.iana.org/assignments/tcp-parameters>\>.
:   

\[Is18\]
:   [Islam, S.]{.refAuthor}, [Welzl, M.]{.refAuthor},
    [Hiorth, K.]{.refAuthor}, [Hayes, D.]{.refAuthor},
    [Armitage, G.]{.refAuthor}, and [S. Gjessing]{.refAuthor},
    [\"ctrlTCP: Reducing latency through coupled, heterogeneous
    multi-flow TCP congestion control\"]{.refTitle}, [IEEE INFOCOM
    2018 - IEEE Conference on Computer Communications Workshops (INFOCOM
    WKSHPS)]{.refContent}, [DOI
    10.1109/INFCOMW.2018.8406887]{.seriesInfo}, April 2018,
    \<<https://doi.org/10.1109/INFCOMW.2018.8406887>\>.
:   

\[Ja88\]
:   [Jacobson, V.]{.refAuthor} and [M. Karels]{.refAuthor},
    [\"Congestion Avoidance and Control\"]{.refTitle}, [SIGCOMM
    Symposium proceedings on Communications architectures and protocols
    ]{.refContent}, November 1988.
:   

\[RFC1379\]
:   [Braden, R.]{.refAuthor}, [\"Extending TCP for Transactions \--
    Concepts\"]{.refTitle}, [RFC 1379]{.seriesInfo}, [DOI
    10.17487/RFC1379]{.seriesInfo}, November 1992,
    \<<https://www.rfc-editor.org/info/rfc1379>\>.
:   

\[RFC1644\]
:   [Braden, R.]{.refAuthor}, [\"T/TCP \-- TCP Extensions for
    Transactions Functional Specification\"]{.refTitle}, [RFC
    1644]{.seriesInfo}, [DOI 10.17487/RFC1644]{.seriesInfo}, July 1994,
    \<<https://www.rfc-editor.org/info/rfc1644>\>.
:   

\[RFC2001\]
:   [Stevens, W.]{.refAuthor}, [\"TCP Slow Start, Congestion Avoidance,
    Fast Retransmit, and Fast Recovery Algorithms\"]{.refTitle}, [RFC
    2001]{.seriesInfo}, [DOI 10.17487/RFC2001]{.seriesInfo}, January
    1997, \<<https://www.rfc-editor.org/info/rfc2001>\>.
:   

\[RFC2140\]
:   [Touch, J.]{.refAuthor}, [\"TCP Control Block
    Interdependence\"]{.refTitle}, [RFC 2140]{.seriesInfo}, [DOI
    10.17487/RFC2140]{.seriesInfo}, April 1997,
    \<<https://www.rfc-editor.org/info/rfc2140>\>.
:   

\[RFC2414\]
:   [Allman, M.]{.refAuthor}, [Floyd, S.]{.refAuthor}, and [C.
    Partridge]{.refAuthor}, [\"Increasing TCP\'s Initial
    Window\"]{.refTitle}, [RFC 2414]{.seriesInfo}, [DOI
    10.17487/RFC2414]{.seriesInfo}, September 1998,
    \<<https://www.rfc-editor.org/info/rfc2414>\>.
:   

\[RFC2663\]
:   [Srisuresh, P.]{.refAuthor} and [M. Holdrege]{.refAuthor}, [\"IP
    Network Address Translator (NAT) Terminology and
    Considerations\"]{.refTitle}, [RFC 2663]{.seriesInfo}, [DOI
    10.17487/RFC2663]{.seriesInfo}, August 1999,
    \<<https://www.rfc-editor.org/info/rfc2663>\>.
:   

\[RFC3124\]
:   [Balakrishnan, H.]{.refAuthor} and [S. Seshan]{.refAuthor}, [\"The
    Congestion Manager\"]{.refTitle}, [RFC 3124]{.seriesInfo}, [DOI
    10.17487/RFC3124]{.seriesInfo}, June 2001,
    \<<https://www.rfc-editor.org/info/rfc3124>\>.
:   

\[RFC3390\]
:   [Allman, M.]{.refAuthor}, [Floyd, S.]{.refAuthor}, and [C.
    Partridge]{.refAuthor}, [\"Increasing TCP\'s Initial
    Window\"]{.refTitle}, [RFC 3390]{.seriesInfo}, [DOI
    10.17487/RFC3390]{.seriesInfo}, October 2002,
    \<<https://www.rfc-editor.org/info/rfc3390>\>.
:   

\[RFC4340\]
:   [Kohler, E.]{.refAuthor}, [Handley, M.]{.refAuthor}, and [S.
    Floyd]{.refAuthor}, [\"Datagram Congestion Control Protocol
    (DCCP)\"]{.refTitle}, [RFC 4340]{.seriesInfo}, [DOI
    10.17487/RFC4340]{.seriesInfo}, March 2006,
    \<<https://www.rfc-editor.org/info/rfc4340>\>.
:   

\[RFC4960\]
:   [Stewart, R., Ed.]{.refAuthor}, [\"Stream Control Transmission
    Protocol\"]{.refTitle}, [RFC 4960]{.seriesInfo}, [DOI
    10.17487/RFC4960]{.seriesInfo}, September 2007,
    \<<https://www.rfc-editor.org/info/rfc4960>\>.
:   

\[RFC5925\]
:   [Touch, J.]{.refAuthor}, [Mankin, A.]{.refAuthor}, and [R.
    Bonica]{.refAuthor}, [\"The TCP Authentication Option\"]{.refTitle},
    [RFC 5925]{.seriesInfo}, [DOI 10.17487/RFC5925]{.seriesInfo}, June
    2010, \<<https://www.rfc-editor.org/info/rfc5925>\>.
:   

\[RFC6437\]
:   [Amante, S.]{.refAuthor}, [Carpenter, B.]{.refAuthor},
    [Jiang, S.]{.refAuthor}, and [J. Rajahalme]{.refAuthor}, [\"IPv6
    Flow Label Specification\"]{.refTitle}, [RFC 6437]{.seriesInfo},
    [DOI 10.17487/RFC6437]{.seriesInfo}, November 2011,
    \<<https://www.rfc-editor.org/info/rfc6437>\>.
:   

\[RFC6691\]
:   [Borman, D.]{.refAuthor}, [\"TCP Options and Maximum Segment Size
    (MSS)\"]{.refTitle}, [RFC 6691]{.seriesInfo}, [DOI
    10.17487/RFC6691]{.seriesInfo}, July 2012,
    \<<https://www.rfc-editor.org/info/rfc6691>\>.
:   

\[RFC6928\]
:   [Chu, J.]{.refAuthor}, [Dukkipati, N.]{.refAuthor},
    [Cheng, Y.]{.refAuthor}, and [M. Mathis]{.refAuthor}, [\"Increasing
    TCP\'s Initial Window\"]{.refTitle}, [RFC 6928]{.seriesInfo}, [DOI
    10.17487/RFC6928]{.seriesInfo}, April 2013,
    \<<https://www.rfc-editor.org/info/rfc6928>\>.
:   

\[RFC7231\]
:   [Fielding, R., Ed.]{.refAuthor} and [J. Reschke, Ed.]{.refAuthor},
    [\"Hypertext Transfer Protocol (HTTP/1.1): Semantics and
    Content\"]{.refTitle}, [RFC 7231]{.seriesInfo}, [DOI
    10.17487/RFC7231]{.seriesInfo}, June 2014,
    \<<https://www.rfc-editor.org/info/rfc7231>\>.
:   

\[RFC7323\]
:   [Borman, D.]{.refAuthor}, [Braden, B.]{.refAuthor},
    [Jacobson, V.]{.refAuthor}, and [R. Scheffenegger, Ed.]{.refAuthor},
    [\"TCP Extensions for High Performance\"]{.refTitle}, [RFC
    7323]{.seriesInfo}, [DOI 10.17487/RFC7323]{.seriesInfo}, September
    2014, \<<https://www.rfc-editor.org/info/rfc7323>\>.
:   

\[RFC7424\]
:   [Krishnan, R.]{.refAuthor}, [Yong, L.]{.refAuthor},
    [Ghanwani, A.]{.refAuthor}, [So, N.]{.refAuthor}, and [B.
    Khasnabish]{.refAuthor}, [\"Mechanisms for Optimizing Link
    Aggregation Group (LAG) and Equal-Cost Multipath (ECMP) Component
    Link Utilization in Networks\"]{.refTitle}, [RFC 7424]{.seriesInfo},
    [DOI 10.17487/RFC7424]{.seriesInfo}, January 2015,
    \<<https://www.rfc-editor.org/info/rfc7424>\>.
:   

\[RFC7540\]
:   [Belshe, M.]{.refAuthor}, [Peon, R.]{.refAuthor}, and [M. Thomson,
    Ed.]{.refAuthor}, [\"Hypertext Transfer Protocol Version 2
    (HTTP/2)\"]{.refTitle}, [RFC 7540]{.seriesInfo}, [DOI
    10.17487/RFC7540]{.seriesInfo}, May 2015,
    \<<https://www.rfc-editor.org/info/rfc7540>\>.
:   

\[RFC7661\]
:   [Fairhurst, G.]{.refAuthor}, [Sathiaseelan, A.]{.refAuthor}, and [R.
    Secchi]{.refAuthor}, [\"Updating TCP to Support Rate-Limited
    Traffic\"]{.refTitle}, [RFC 7661]{.seriesInfo}, [DOI
    10.17487/RFC7661]{.seriesInfo}, October 2015,
    \<<https://www.rfc-editor.org/info/rfc7661>\>.
:   

\[RFC8684\]
:   [Ford, A.]{.refAuthor}, [Raiciu, C.]{.refAuthor},
    [Handley, M.]{.refAuthor}, [Bonaventure, O.]{.refAuthor}, and [C.
    Paasch]{.refAuthor}, [\"TCP Extensions for Multipath Operation with
    Multiple Addresses\"]{.refTitle}, [RFC 8684]{.seriesInfo}, [DOI
    10.17487/RFC8684]{.seriesInfo}, March 2020,
    \<<https://www.rfc-editor.org/info/rfc8684>\>.
:   
:::
:::

::: {#sect-a}
::: {#appendix-A .section}
## [Appendix A.](#appendix-A){.section-number .selfRef} [TCB Sharing History](#name-tcb-sharing-history){.section-name .selfRef} {#name-tcb-sharing-history}

T/TCP proposed using caches to maintain TCB information across instances
(temporal sharing), e.g., smoothed RTT, RTT variation,
congestion-avoidance threshold, and MSS \[[RFC1644](#RFC1644){.xref}\].
These values were in addition to connection counts used by T/TCP to
accelerate data delivery prior to the full three-way handshake during an
OPEN. The goal was to aggregate TCB components where they reflect one
association \-- that of the host-pair rather than artificially
separating those components by connection.[¶](#appendix-A-1){.pilcrow}

At least one T/TCP implementation saved the MSS and aggregated the RTT
parameters across multiple connections but omitted caching the
congestion window information \[[Br94](#Br94){.xref}\], as originally
specified in \[[RFC1379](#RFC1379){.xref}\]. Some T/TCP implementations
immediately updated MSS when the TCP MSS header option was received
\[[Br94](#Br94){.xref}\], although this was not addressed specifically
in the concepts or functional specification
\[[RFC1379](#RFC1379){.xref}\] \[[RFC1644](#RFC1644){.xref}\]. In later
T/TCP implementations, RTT values were updated only after a CLOSE, which
does not benefit concurrent sessions.[¶](#appendix-A-2){.pilcrow}

Temporal sharing of cached TCB data was originally implemented in the
Sun OS 4.1.3 T/TCP extensions \[[Br94](#Br94){.xref}\] and the FreeBSD
port of same \[[FreeBSD](#FreeBSD){.xref}\]. As mentioned before, only
the MSS and RTT parameters were cached, as originally specified in
\[[RFC1379](#RFC1379){.xref}\]. Later discussion of T/TCP suggested
including congestion control parameters in this cache; for example,
[Section
3.1](https://www.rfc-editor.org/rfc/rfc1644#section-3.1){.relref} of
\[[RFC1644](#RFC1644){.xref}\] hints at initializing the congestion
window to the old window size.[¶](#appendix-A-3){.pilcrow}
:::
:::

::: {#sect-b}
::: {#appendix-B .section}
## [Appendix B.](#appendix-B){.section-number .selfRef} [TCP Option Sharing and Caching](#name-tcp-option-sharing-and-cach){.section-name .selfRef} {#name-tcp-option-sharing-and-cach}

In addition to the options that can be cached and shared, this memo also
lists known TCP options \[[IANA](#IANA){.xref}\] for which state is
unsafe to be kept. This list is not intended to be authoritative or
exhaustive.[¶](#appendix-B-1){.pilcrow}

Obsolete (unsafe to keep state):[¶](#appendix-B-2){.pilcrow}

-   [Echo[¶](#appendix-B-3.1){.pilcrow}]{#appendix-B-3.1}
-   [Echo Reply[¶](#appendix-B-3.2){.pilcrow}]{#appendix-B-3.2}
-   [Partial Order Connection
    Permitted[¶](#appendix-B-3.3){.pilcrow}]{#appendix-B-3.3}
-   [Partial Order Service
    Profile[¶](#appendix-B-3.4){.pilcrow}]{#appendix-B-3.4}
-   [CC[¶](#appendix-B-3.5){.pilcrow}]{#appendix-B-3.5}
-   [CC.NEW[¶](#appendix-B-3.6){.pilcrow}]{#appendix-B-3.6}
-   [CC.ECHO[¶](#appendix-B-3.7){.pilcrow}]{#appendix-B-3.7}
-   [TCP Alternate Checksum
    Request[¶](#appendix-B-3.8){.pilcrow}]{#appendix-B-3.8}
-   [TCP Alternate Checksum
    Data[¶](#appendix-B-3.9){.pilcrow}]{#appendix-B-3.9}

No state to keep:[¶](#appendix-B-4){.pilcrow}

-   [End of Option List
    (EOL)[¶](#appendix-B-5.1){.pilcrow}]{#appendix-B-5.1}
-   [No-Operation (NOP)[¶](#appendix-B-5.2){.pilcrow}]{#appendix-B-5.2}
-   [Window Scale (WS)[¶](#appendix-B-5.3){.pilcrow}]{#appendix-B-5.3}
-   [SACK[¶](#appendix-B-5.4){.pilcrow}]{#appendix-B-5.4}
-   [Timestamps (TS)[¶](#appendix-B-5.5){.pilcrow}]{#appendix-B-5.5}
-   [MD5 Signature
    Option[¶](#appendix-B-5.6){.pilcrow}]{#appendix-B-5.6}
-   [TCP Authentication Option
    (TCP-AO)[¶](#appendix-B-5.7){.pilcrow}]{#appendix-B-5.7}
-   [RFC3692-style Experiment
    1[¶](#appendix-B-5.8){.pilcrow}]{#appendix-B-5.8}
-   [RFC3692-style Experiment
    2[¶](#appendix-B-5.9){.pilcrow}]{#appendix-B-5.9}

Unsafe to keep state:[¶](#appendix-B-6){.pilcrow}

-   [Skeeter (DH exchange, known to be
    vulnerable)[¶](#appendix-B-7.1){.pilcrow}]{#appendix-B-7.1}
-   [Bubba (DH exchange, known to be
    vulnerable)[¶](#appendix-B-7.2){.pilcrow}]{#appendix-B-7.2}
-   [Trailer Checksum
    Option[¶](#appendix-B-7.3){.pilcrow}]{#appendix-B-7.3}
-   [SCPS capabilities[¶](#appendix-B-7.4){.pilcrow}]{#appendix-B-7.4}
-   [Selective Negative Acknowledgements
    (S-NACK)[¶](#appendix-B-7.5){.pilcrow}]{#appendix-B-7.5}
-   [Records Boundaries[¶](#appendix-B-7.6){.pilcrow}]{#appendix-B-7.6}
-   [Corruption
    experienced[¶](#appendix-B-7.7){.pilcrow}]{#appendix-B-7.7}
-   [SNAP[¶](#appendix-B-7.8){.pilcrow}]{#appendix-B-7.8}
-   [TCP Compression
    Filter[¶](#appendix-B-7.9){.pilcrow}]{#appendix-B-7.9}
-   [Quick-Start
    Response[¶](#appendix-B-7.10){.pilcrow}]{#appendix-B-7.10}
-   [User Timeout Option
    (UTO)[¶](#appendix-B-7.11){.pilcrow}]{#appendix-B-7.11}
-   [Multipath TCP (MPTCP) negotiation success (see below for
    negotiation
    failure)[¶](#appendix-B-7.12){.pilcrow}]{#appendix-B-7.12}
-   [TCP Fast Open (TFO) negotiation success (see below for negotiation
    failure)[¶](#appendix-B-7.13){.pilcrow}]{#appendix-B-7.13}

Safe but optional to keep state:[¶](#appendix-B-8){.pilcrow}

-   [Multipath TCP (MPTCP) negotiation failure (to avoid negotiation
    retries)[¶](#appendix-B-9.1){.pilcrow}]{#appendix-B-9.1}
-   [Maximum Segment Size
    (MSS)[¶](#appendix-B-9.2){.pilcrow}]{#appendix-B-9.2}
-   [TCP Fast Open (TFO) negotiation failure (to avoid negotiation
    retries)[¶](#appendix-B-9.3){.pilcrow}]{#appendix-B-9.3}

Safe and necessary to keep state:[¶](#appendix-B-10){.pilcrow}

-   [TCP Fast Open (TFO) Cookie (if TFO succeeded in the
    past)[¶](#appendix-B-11.1){.pilcrow}]{#appendix-B-11.1}
:::
:::

::: {#sect-c}
::: {#appendix-C .section}
## [Appendix C.](#appendix-C){.section-number .selfRef} [Automating the Initial Window in TCP over Long Timescales](#name-automating-the-initial-wind){.section-name .selfRef} {#name-automating-the-initial-wind}

::: {#sect-c.1}
::: {#appendix-C.1 .section}
### [C.1.](#appendix-C.1){.section-number .selfRef} [Introduction](#name-introduction-2){.section-name .selfRef} {#name-introduction-2}

Temporal sharing, as described earlier in this document, builds on the
assumption that multiple consecutive connections between the same
host-pair are somewhat likely to be exposed to similar environment
characteristics. The stored information can become less accurate over
time and suitable precautions should take this aging into consideration
(this is discussed further in [Section 8.1](#sect-8.1){.xref}). However,
there are also cases where it can make sense to track these values over
longer periods, observing properties of TCP connections to gradually
influence evolving trends in TCP parameters. This appendix describes an
example of such a case.[¶](#appendix-C.1-1){.pilcrow}

TCP\'s congestion control algorithm uses an initial window value (IW)
both as a starting point for new connections and as an upper limit for
restarting after an idle period \[[RFC5681](#RFC5681){.xref}\]
\[[RFC7661](#RFC7661){.xref}\]. This value has evolved over time; it was
originally 1 maximum segment size (MSS) and increased to the lesser of 4
MSSs or 4,380 bytes \[[RFC3390](#RFC3390){.xref}\]
\[[RFC5681](#RFC5681){.xref}\]. For a typical Internet connection with a
maximum transmission unit (MTU) of 1500 bytes, this permits 3 segments
of 1,460 bytes each.[¶](#appendix-C.1-2){.pilcrow}

The IW value was originally implied in the original TCP congestion
control description and documented as a standard in 1997
\[[RFC2001](#RFC2001){.xref}\] \[[Ja88](#Ja88){.xref}\]. The value was
updated in 1998 experimentally and moved to the Standards Track in 2002
\[[RFC2414](#RFC2414){.xref}\] \[[RFC3390](#RFC3390){.xref}\]. In 2013,
it was experimentally increased to 10
\[[RFC6928](#RFC6928){.xref}\].[¶](#appendix-C.1-3){.pilcrow}

This appendix discusses how TCP can objectively measure when an IW is
too large and that such feedback should be used over long timescales to
adjust the IW automatically. The result should be safer to deploy and
might avoid the need to repeatedly revisit IW over
time.[¶](#appendix-C.1-4){.pilcrow}

Note that this mechanism attempts to make the IW more adaptive over
time. It can increase the IW beyond that which is currently recommended
for wide-scale deployment, so its use should be carefully
monitored.[¶](#appendix-C.1-5){.pilcrow}
:::
:::

::: {#sect-c.2}
::: {#appendix-C.2 .section}
### [C.2.](#appendix-C.2){.section-number .selfRef} [Design Considerations](#name-design-considerations){.section-name .selfRef} {#name-design-considerations}

TCP\'s IW value has existed statically for over two decades, so any
solution to adjusting the IW dynamically should have similarly stable,
non-invasive effects on the performance and complexity of TCP. In order
to be fair, the IW should be similar for most machines on the public
Internet. Finally, a desirable goal is to develop a self-correcting
algorithm so that IW values that cause network problems can be avoided.
To that end, we propose the following design
goals:[¶](#appendix-C.2-1){.pilcrow}

-   [Impart little to no impact to TCP in the absence of loss, i.e., it
    should not increase the complexity of default packet processing in
    the normal case.[¶](#appendix-C.2-2.1){.pilcrow}]{#appendix-C.2-2.1}
-   [Adapt to network feedback over long timescales, avoiding values
    that persistently cause network
    problems.[¶](#appendix-C.2-2.2){.pilcrow}]{#appendix-C.2-2.2}
-   [Decrease the IW in the presence of sustained loss of IW segments,
    as determined over a number of different
    connections.[¶](#appendix-C.2-2.3){.pilcrow}]{#appendix-C.2-2.3}
-   [Increase the IW in the absence of sustained loss of IW segments, as
    determined over a number of different
    connections.[¶](#appendix-C.2-2.4){.pilcrow}]{#appendix-C.2-2.4}
-   [Operate conservatively, i.e., tend towards leaving the IW the same
    in the absence of sufficient information, and give greater
    consideration to IW segment loss than IW segment
    success.[¶](#appendix-C.2-2.5){.pilcrow}]{#appendix-C.2-2.5}

We expect that, without other context, a good IW algorithm will converge
to a single value, but this is not required. An endpoint with additional
context or information, or deployed in a constrained environment, can
always use a different value. In particular, information from previous
connections, or sets of connections with a similar path, can already be
used as context for such decisions (as noted in the core of this
document).[¶](#appendix-C.2-3){.pilcrow}

However, if a given IW value persistently causes packet loss during the
initial burst of packets, it is clearly inappropriate and could be
inducing unnecessary loss in other competing connections. This might
happen for sites behind very slow boxes with small buffers, which may or
may not be the first hop.[¶](#appendix-C.2-4){.pilcrow}
:::
:::

::: {#sect-c.3}
::: {#appendix-C.3 .section}
### [C.3.](#appendix-C.3){.section-number .selfRef} [Proposed IW Algorithm](#name-proposed-iw-algorithm){.section-name .selfRef} {#name-proposed-iw-algorithm}

Below is a simple description of the proposed IW algorithm. It relies on
the following parameters:[¶](#appendix-C.3-1){.pilcrow}

-   [MinIW = 3 MSS or 4,380 bytes (as per
    \[[RFC3390](#RFC3390){.xref}\])[¶](#appendix-C.3-2.1){.pilcrow}]{#appendix-C.3-2.1}
-   [MaxIW = 10 MSS (as per
    \[[RFC6928](#RFC6928){.xref}\])[¶](#appendix-C.3-2.2){.pilcrow}]{#appendix-C.3-2.2}
-   [MulDecr = 0.5[¶](#appendix-C.3-2.3){.pilcrow}]{#appendix-C.3-2.3}
-   [AddIncr = 2 MSS[¶](#appendix-C.3-2.4){.pilcrow}]{#appendix-C.3-2.4}
-   [Threshold =
    0.05[¶](#appendix-C.3-2.5){.pilcrow}]{#appendix-C.3-2.5}

We assume that the minimum IW (MinIW) should be as currently specified
as standard \[[RFC3390](#RFC3390){.xref}\]. The maximum IW (MaxIW) can
be set to a fixed value (we suggest using the experimental and now
somewhat de facto standard in \[[RFC6928](#RFC6928){.xref}\]) or set
based on a schedule if trusted time references are available
\[[Al10](#I-D.allman-tcpm-bump-initcwnd){.xref}\]; here, we prefer a
fixed value. We also propose to use an Additive Increase Multiplicative
Decrease (AIMD) algorithm, with increase and decreases as
noted.[¶](#appendix-C.3-3){.pilcrow}

Although these parameters are somewhat arbitrary, their initial values
are not important except that the algorithm is AIMD and the MaxIW should
not exceed that recommended for other systems on the Internet (here, we
selected the current de facto standard rather than the actual standard).
Current proposals, including default current operation, are degenerate
cases of the algorithm below for given parameters, notably MulDec = 1.0
and AddIncr = 0 MSS, thus disabling the automatic part of the
algorithm.[¶](#appendix-C.3-4){.pilcrow}

The proposed algorithm is as follows:[¶](#appendix-C.3-5){.pilcrow}

1.  ::: {#appendix-C.3-6.1}
    On boot:[¶](#appendix-C.3-6.1.1){.pilcrow}

    ::: {#appendix-C.3-6.1.2}
    ``` {.sourcecode .lang-pseudocode}
       IW = MaxIW; # assume this is in bytes and indicates an integer
                   # multiple of 2 MSS (an even number to support
                   # ACK compression)
    ```

    [¶](#appendix-C.3-6.1.2){.pilcrow}
    :::
    :::

2.  ::: {#appendix-C.3-6.2}
    Upon starting a new connection:[¶](#appendix-C.3-6.2.1){.pilcrow}

    ::: {#appendix-C.3-6.2.2}
    ``` {.sourcecode .lang-pseudocode}
       CWND = IW;
       conncount++;
       IWnotchecked = 1; # true
    ```

    [¶](#appendix-C.3-6.2.2){.pilcrow}
    :::
    :::

3.  ::: {#appendix-C.3-6.3}
    During a connection\'s SYN-ACK processing, if SYN-ACK includes ECN
    (as similarly addressed in Section 5 of ECN++ for TCP
    \[[Ba20](#I-D.ietf-tcpm-generalized-ecn){.xref}\]), treat as if the
    IW is too large:[¶](#appendix-C.3-6.3.1){.pilcrow}

    ::: {#appendix-C.3-6.3.2}
    ``` {.sourcecode .lang-pseudocode}
       if (IWnotchecked && (synackecn == 1)) {
          losscount++;
          IWnotchecked = 0; # never check again
       }
    ```

    [¶](#appendix-C.3-6.3.2){.pilcrow}
    :::
    :::

4.  ::: {#appendix-C.3-6.4}
    During a connection, if retransmission occurs, check the seqno of
    the outgoing packet (in bytes) to see if the re-sent segment fixes
    an IW loss:[¶](#appendix-C.3-6.4.1){.pilcrow}

    ::: {#appendix-C.3-6.4.2}
    ``` {.sourcecode .lang-pseudocode}
       if (Retransmitting && IWnotchecked && ((seqno - ISN) < IW))) {
          losscount++;
          IWnotchecked = 0; # never do this entire "if" again
       } else {
          IWnotchecked = 0; # you're beyond the IW so stop checking
       }
    ```

    [¶](#appendix-C.3-6.4.2){.pilcrow}
    :::
    :::

5.  ::: {#appendix-C.3-6.5}
    Once every 1000 connections, as a separate process (i.e., not as
    part of processing a given
    connection):[¶](#appendix-C.3-6.5.1){.pilcrow}

    ::: {#appendix-C.3-6.5.2}
    ``` {.sourcecode .lang-pseudocode}
       if (conncount > 1000) {
          if (losscount/conncount > threshold) {
             # the number of connections with errors is too high
             IW = IW * MulDecr;
          } else {
             IW = IW + AddIncr;
          }
       }
    ```

    [¶](#appendix-C.3-6.5.2){.pilcrow}
    :::
    :::

As presented, this algorithm can yield a false positive when the
sequence number wraps around, e.g., the code might increment losscount
in step 4 when no loss occurred or fail to increment losscount when a
loss did occur. This can be avoided using either Protection Against
Wrapped Sequences (PAWS) \[[RFC7323](#RFC7323){.xref}\] context or
internal extended sequence number representations (as in TCP
Authentication Option (TCP-AO) \[[RFC5925](#RFC5925){.xref}\]).
Alternately, false positives can be tolerated because they are expected
to be infrequent and thus will not significantly impact the
algorithm.[¶](#appendix-C.3-7){.pilcrow}

A number of additional constraints need to be imposed if this mechanism
is implemented to ensure that it defaults to values that comply with
current Internet standards, is conservative in how it extends those
values, and returns to those values in the absence of positive feedback
(i.e., success). To that end, we recommend the following list of example
constraints:[¶](#appendix-C.3-8){.pilcrow}

-   ::: {#appendix-C.3-9.1}
    The automatic IW algorithm [MUST]{.bcp14} initialize MaxIW a value
    no larger than the currently recommended Internet default in the
    absence of other context
    information.[¶](#appendix-C.3-9.1.1){.pilcrow}

    Thus, if there are too few connections to make a decision or if
    there is otherwise insufficient information to increase the IW, then
    the MaxIW defaults to the current recommended
    value.[¶](#appendix-C.3-9.1.2){.pilcrow}
    :::

-   ::: {#appendix-C.3-9.2}
    An implementation [MAY]{.bcp14} allow the MaxIW to grow beyond the
    currently recommended Internet default but not more than 2 segments
    per calendar year.[¶](#appendix-C.3-9.2.1){.pilcrow}

    Thus, if an endpoint has a persistent history of successfully
    transmitting IW segments without loss, then it is allowed to probe
    the Internet to determine if larger IW values have similar success.
    This probing is limited and requires a trusted time source;
    otherwise, the MaxIW remains
    constant.[¶](#appendix-C.3-9.2.2){.pilcrow}
    :::

-   ::: {#appendix-C.3-9.3}
    An implementation [MUST]{.bcp14} adjust the IW based on loss
    statistics at least once every 1000
    connections.[¶](#appendix-C.3-9.3.1){.pilcrow}

    An endpoint needs to be sufficiently reactive to IW
    loss.[¶](#appendix-C.3-9.3.2){.pilcrow}
    :::

-   ::: {#appendix-C.3-9.4}
    An implementation [MUST]{.bcp14} decrease the IW by at least 1 MSS
    when indicated during an evaluation
    interval.[¶](#appendix-C.3-9.4.1){.pilcrow}

    An endpoint that detects loss needs to decrease its IW by at least 1
    MSS; otherwise, it is not participating in an automatic reactive
    algorithm.[¶](#appendix-C.3-9.4.2){.pilcrow}
    :::

-   ::: {#appendix-C.3-9.5}
    An implementation [MUST]{.bcp14} increase by no more than 2 MSSs per
    evaluation interval.[¶](#appendix-C.3-9.5.1){.pilcrow}

    An endpoint that does not experience IW loss needs to probe the
    network incrementally.[¶](#appendix-C.3-9.5.2){.pilcrow}
    :::

-   ::: {#appendix-C.3-9.6}
    An implementation [SHOULD]{.bcp14} use an IW that is an integer
    multiple of 2 MSSs.[¶](#appendix-C.3-9.6.1){.pilcrow}

    The IW should remain a multiple of 2 MSS segments to enable
    efficient ACK compression without incurring unnecessary
    timeouts.[¶](#appendix-C.3-9.6.2){.pilcrow}
    :::

-   ::: {#appendix-C.3-9.7}
    An implementation [MUST]{.bcp14} decrease the IW if more than 95% of
    connections have IW losses.[¶](#appendix-C.3-9.7.1){.pilcrow}

    Again, this is to ensure an implementation is sufficiently
    reactive.[¶](#appendix-C.3-9.7.2){.pilcrow}
    :::

-   ::: {#appendix-C.3-9.8}
    An implementation [MAY]{.bcp14} group IW values and statistics
    within subsets of connections. Such grouping [MAY]{.bcp14} use any
    information about connections to form groups except loss
    statistics.[¶](#appendix-C.3-9.8.1){.pilcrow}
    :::

There are some TCP connections that might not be counted at all, such as
those to/from loopback addresses or those within the same subnet as that
of a local interface (for which congestion control is sometimes disabled
anyway). This may also include connections that terminate before the IW
is full, i.e., as a separate check at the time of the connection
closing.[¶](#appendix-C.3-10){.pilcrow}

The period over which the IW is updated is intended to be a long
timescale, e.g., a month or so, or 1,000 connections, whichever is
longer. An implementation might check the IW once a month and simply not
update the IW or clear the connection counts in months where the number
of connections is too small.[¶](#appendix-C.3-11){.pilcrow}
:::
:::

::: {#sect-c.4}
::: {#appendix-C.4 .section}
### [C.4.](#appendix-C.4){.section-number .selfRef} [Discussion](#name-discussion-3){.section-name .selfRef} {#name-discussion-3}

There are numerous parameters to the above algorithm that are compliant
with the given requirements; this is intended to allow variation in
configuration and implementation while ensuring that all such algorithms
are reactive and safe.[¶](#appendix-C.4-1){.pilcrow}

This algorithm continues to assume segments because that is the basis of
most TCP implementations. It might be useful to consider revising the
specifications to allow byte-based congestion given sufficient
experience.[¶](#appendix-C.4-2){.pilcrow}

The algorithm checks for IW losses only during the first IW after a
connection start; it does not check for IW losses elsewhere the IW is
used, e.g., during slow-start restarts.[¶](#appendix-C.4-3){.pilcrow}

-   ::: {#appendix-C.4-4.1}
    An implementation [MAY]{.bcp14} detect IW losses during slow-start
    restarts in addition to losses during the first IW of a connection.
    In this case, the implementation [MUST]{.bcp14} count each restart
    as a \"connection\" for the purposes of connection counts and
    periodic rechecking of the IW
    value.[¶](#appendix-C.4-4.1.1){.pilcrow}
    :::

False positives can occur during some kinds of segment reordering, e.g.,
that might trigger spurious retransmissions even without a true segment
loss. These are not expected to be sufficiently common to dominate the
algorithm and its conclusions.[¶](#appendix-C.4-5){.pilcrow}

This mechanism does require additional per-connection state, which is
currently common in some implementations and is useful for other reasons
(e.g., the ISN is used in TCP-AO \[[RFC5925](#RFC5925){.xref}\]). The
mechanism in this appendix also benefits from persistent state kept
across reboots, which would also be useful to other state sharing
mechanisms (e.g., TCP Control Block Sharing per the main body of this
document).[¶](#appendix-C.4-6){.pilcrow}

The receive window (rwnd) is not involved in this calculation. The size
of rwnd is determined by receiver resources and provides space to
accommodate segment reordering. Also, rwnd is not involved with
congestion control, which is the focus of the way this appendix manages
the IW.[¶](#appendix-C.4-7){.pilcrow}
:::
:::

::: {#sect-c.5}
::: {#appendix-C.5 .section}
### [C.5.](#appendix-C.5){.section-number .selfRef} [Observations](#name-observations){.section-name .selfRef} {#name-observations}

The IW may not converge to a single global value. It also may not
converge at all but rather may oscillate by a few MSSs as it repeatedly
probes the Internet for larger IWs and fails. Both properties are
consistent with TCP behavior during each individual
connection.[¶](#appendix-C.5-1){.pilcrow}

This mechanism assumes that losses during the IW are due to IW size.
Persistent errors that drop packets for other reasons, e.g., OS bugs,
can cause false positives. Again, this is consistent with TCP\'s basic
assumption that loss is caused by congestion and requires backoff. This
algorithm treats the IW of new connections as a long-timescale backoff
system.[¶](#appendix-C.5-2){.pilcrow}
:::
:::
:::
:::

::: {#acknowledgments}
::: {#appendix-D .section}
## [Acknowledgments](#name-acknowledgments){.section-name .selfRef} {#name-acknowledgments}

The authors would like to thank [Praveen Balasubramanian]{.contact-name}
for information regarding TCB sharing in Windows; [Christoph
Paasch]{.contact-name} for information regarding TCB sharing in Apple
OSs; [Yuchung Cheng]{.contact-name}, [Lars Eggert]{.contact-name}, [Ilpo
Jarvinen]{.contact-name}, and [Michael Scharf]{.contact-name} for
comments on earlier draft versions of this document; as well as members
of the TCPM WG. Earlier revisions of this work received funding from a
collaborative research project between the University of Oslo and Huawei
Technologies Co., Ltd. and were partly supported by USC/ISI\'s Postel
Center.[¶](#appendix-D-1){.pilcrow}
:::
:::

::: {#authors-addresses}
::: {#appendix-E .section}
## [Authors\' Addresses](#name-authors-addresses){.section-name .selfRef} {#name-authors-addresses}

::: {.left dir="auto"}
[Joe Touch]{.fn .nameRole}
:::

::: {.left dir="auto"}
[Manhattan Beach]{.locality}, [CA]{.region} [90266]{.postal-code}
:::

::: {.left dir="auto"}
[United States of America]{.country-name}
:::

::: tel
Phone: [+1 (310) 560-0334](tel:+1%20(310)%20560-0334){.tel}
:::

::: email
Email: <touch@strayalpha.com>
:::

::: {.left dir="auto"}
[Michael Welzl]{.fn .nameRole}
:::

::: {.left dir="auto"}
[University of Oslo]{.org}
:::

::: {.left dir="auto"}
[PO Box 1080 Blindern]{.street-address}
:::

::: {.left dir="auto"}
[N-0316]{.postal-code} [Oslo]{.locality}
:::

::: {.left dir="auto"}
[Norway]{.country-name}
:::

::: tel
Phone: [+47 22 85 24 20](tel:+47%2022%2085%2024%2020){.tel}
:::

::: email
Email: <michawe@ifi.uio.no>
:::

::: {.left dir="auto"}
[Safiqul Islam]{.fn .nameRole}
:::

::: {.left dir="auto"}
[University of Oslo]{.org}
:::

::: {.left dir="auto"}
[PO Box 1080 Blindern\
Oslo N-0316\
Norway]{.street-address}
:::

::: tel
Phone: [+47 22 84 08 37](tel:+47%2022%2084%2008%2037){.tel}
:::

::: email
Email: <safiquli@ifi.uio.no>
:::
:::
:::
