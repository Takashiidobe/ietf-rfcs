  RFC 9004   B2B Frame Update   May 2021
  ---------- ------------------ ----------
  Morton     Informational      \[Page\]

::: {#external-metadata .document-information}
:::

::: {#internal-metadata .document-information}

Stream:
:   Internet Engineering Task Force (IETF)

RFC:
:   [9004](https://www.rfc-editor.org/rfc/rfc9004){.eref}

Updates:
:   [2544](https://www.rfc-editor.org/rfc/rfc2544){.eref}

Category:
:   Informational

Published:
:   May 2021

ISSN:
:   2070-1721

Author:

:   ::: author
    ::: author-name
    A. Morton
    :::

    ::: org
    AT&T Labs
    :::
    :::
:::

# RFC 9004 {#rfcnum}

# Updates for the Back-to-Back Frame Benchmark in RFC 2544 {#title}

::: {#section-abstract .section}
## [Abstract](#abstract){.selfRef}

Fundamental benchmarking methodologies for network interconnect devices
of interest to the IETF are defined in RFC 2544. This memo updates the
procedures of the test to measure the Back-to-Back Frames benchmark of
RFC 2544, based on further experience.[¶](#section-abstract-1){.pilcrow}

This memo updates Section 26.4 of RFC
2544.[¶](#section-abstract-2){.pilcrow}
:::

::: {#status-of-memo}
::: {#section-boilerplate.1 .section}
## [Status of This Memo](#name-status-of-this-memo){.section-name .selfRef} {#name-status-of-this-memo}

This document is not an Internet Standards Track specification; it is
published for informational
purposes.[¶](#section-boilerplate.1-1){.pilcrow}

This document is a product of the Internet Engineering Task Force
(IETF). It represents the consensus of the IETF community. It has
received public review and has been approved for publication by the
Internet Engineering Steering Group (IESG). Not all documents approved
by the IESG are candidates for any level of Internet Standard; see
Section 2 of RFC 7841.[¶](#section-boilerplate.1-2){.pilcrow}

Information about the current status of this document, any errata, and
how to provide feedback on it may be obtained at
<https://www.rfc-editor.org/info/rfc9004>.[¶](#section-boilerplate.1-3){.pilcrow}
:::
:::

::: {#copyright}
::: {#section-boilerplate.2 .section}
## [Copyright Notice](#name-copyright-notice){.section-name .selfRef} {#name-copyright-notice}

Copyright (c) 2021 IETF Trust and the persons identified as the document
authors. All rights reserved.[¶](#section-boilerplate.2-1){.pilcrow}

This document is subject to BCP 78 and the IETF Trust\'s Legal
Provisions Relating to IETF Documents
(<https://trustee.ietf.org/license-info>) in effect on the date of
publication of this document. Please review these documents carefully,
as they describe your rights and restrictions with respect to this
document. Code Components extracted from this document must include
Simplified BSD License text as described in Section 4.e of the Trust
Legal Provisions and are provided without warranty as described in the
Simplified BSD License.[¶](#section-boilerplate.2-2){.pilcrow}
:::
:::

::: {#toc}
::: {#section-toc.1 .section}
[▲](#){.toplink}

## [Table of Contents](#name-table-of-contents){.section-name .selfRef} {#name-table-of-contents}

-   ::: {#section-toc.1-1.1}
    [1](#section-1){.xref}.  [Introduction](#name-introduction){.xref}
    :::

-   ::: {#section-toc.1-1.2}
    [2](#section-2){.xref}.  [Requirements
    Language](#name-requirements-language){.xref}
    :::

-   ::: {#section-toc.1-1.3}
    [3](#section-3){.xref}.  [Scope and
    Goals](#name-scope-and-goals){.xref}
    :::

-   ::: {#section-toc.1-1.4}
    [4](#section-4){.xref}.  [Motivation](#name-motivation){.xref}
    :::

-   ::: {#section-toc.1-1.5}
    [5](#section-5){.xref}.  [Prerequisites](#name-prerequisites){.xref}
    :::

-   ::: {#section-toc.1-1.6}
    [6](#section-6){.xref}.  [Back-to-Back
    Frames](#name-back-to-back-frames){.xref}

    -   ::: {#section-toc.1-1.6.2.1}
        [6.1](#section-6.1){.xref}.  [Preparing the List of Frame
        Sizes](#name-preparing-the-list-of-frame){.xref}
        :::

    -   ::: {#section-toc.1-1.6.2.2}
        [6.2](#section-6.2){.xref}.  [Test for a Single Frame
        Size](#name-test-for-a-single-frame-siz){.xref}
        :::

    -   ::: {#section-toc.1-1.6.2.3}
        [6.3](#section-6.3){.xref}.  [Test Repetition and
        Benchmark](#name-test-repetition-and-benchma){.xref}
        :::

    -   ::: {#section-toc.1-1.6.2.4}
        [6.4](#section-6.4){.xref}.  [Benchmark
        Calculations](#name-benchmark-calculations){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.7}
    [7](#section-7){.xref}.  [Reporting](#name-reporting){.xref}
    :::

-   ::: {#section-toc.1-1.8}
    [8](#section-8){.xref}.  [Security
    Considerations](#name-security-considerations){.xref}
    :::

-   ::: {#section-toc.1-1.9}
    [9](#section-9){.xref}.  [IANA
    Considerations](#name-iana-considerations){.xref}
    :::

-   ::: {#section-toc.1-1.10}
    [10](#section-10){.xref}. [References](#name-references){.xref}

    -   ::: {#section-toc.1-1.10.2.1}
        [10.1](#section-10.1){.xref}.  [Normative
        References](#name-normative-references){.xref}
        :::

    -   ::: {#section-toc.1-1.10.2.2}
        [10.2](#section-10.2){.xref}.  [Informative
        References](#name-informative-references){.xref}
        :::
    :::

-   ::: {#section-toc.1-1.11}
    [](#section-appendix.a){.xref}[Acknowledgments](#name-acknowledgments){.xref}
    :::

-   ::: {#section-toc.1-1.12}
    [](#section-appendix.b){.xref}[Author\'s
    Address](#name-authors-address){.xref}
    :::
:::
:::

::: {#section-1 .section}
## [1.](#section-1){.section-number .selfRef} [Introduction](#name-introduction){.section-name .selfRef} {#name-introduction}

The IETF\'s fundamental benchmarking methodologies are defined in
\[[RFC2544](#RFC2544){.xref}\], supported by the terms and definitions
in \[[RFC1242](#RFC1242){.xref}\]. \[[RFC2544](#RFC2544){.xref}\]
actually obsoletes an earlier specification,
\[[RFC1944](#RFC1944){.xref}\]. Over time, the benchmarking community
has updated \[[RFC2544](#RFC2544){.xref}\] several times, including the
Device Reset benchmark \[[RFC6201](#RFC6201){.xref}\] and the important
Applicability Statement \[[RFC6815](#RFC6815){.xref}\] concerning use
outside the Isolated Test Environment (ITE) required for accurate
benchmarking. Other specifications implicitly update
\[[RFC2544](#RFC2544){.xref}\], such as the IPv6 benchmarking
methodologies in
\[[RFC5180](#RFC5180){.xref}\].[¶](#section-1-1){.pilcrow}

Recent testing experience with the Back-to-Back Frame test and benchmark
in [Section
26.4](https://www.rfc-editor.org/rfc/rfc2544#section-26.4){.relref} of
\[[RFC2544](#RFC2544){.xref}\] indicates that an update is warranted
\[[OPNFV-2017](#OPNFV-2017){.xref}\]
\[[VSPERF-b2b](#VSPERF-b2b){.xref}\]. In particular, analysis of the
results indicates that buffer size matters when compensating for
interruptions of software-packet processing, and this finding increases
the importance of the Back-to-Back Frame characterization described
here. This memo provides additional rationale and the updated
method.[¶](#section-1-2){.pilcrow}

\[[RFC2544](#RFC2544){.xref}\] provides its own requirements language
consistent with \[[RFC2119](#RFC2119){.xref}\], since
\[[RFC1944](#RFC1944){.xref}\] (which it obsoletes) predates
\[[RFC2119](#RFC2119){.xref}\]. All three memos share common authorship.
Today, \[[RFC8174](#RFC8174){.xref}\] clarifies the usage of
requirements language, so the requirements language presented in this
memo are expressed in accordance with \[[RFC8174](#RFC8174){.xref}\].
They are intended for those performing/reporting laboratory tests to
improve clarity and repeatability, and for those designing devices that
facilitate these tests.[¶](#section-1-3){.pilcrow}
:::

::: {#section-2 .section}
## [2.](#section-2){.section-number .selfRef} [Requirements Language](#name-requirements-language){.section-name .selfRef} {#name-requirements-language}

The key words \"[MUST]{.bcp14}\", \"[MUST NOT]{.bcp14}\",
\"[REQUIRED]{.bcp14}\", \"[SHALL]{.bcp14}\", \"[SHALL NOT]{.bcp14}\",
\"[SHOULD]{.bcp14}\", \"[SHOULD NOT]{.bcp14}\",
\"[RECOMMENDED]{.bcp14}\", \"[NOT RECOMMENDED]{.bcp14}\",
\"[MAY]{.bcp14}\", and \"[OPTIONAL]{.bcp14}\" in this document are to be
interpreted as described in BCP 14 \[[RFC2119](#RFC2119){.xref}\]
\[[RFC8174](#RFC8174){.xref}\] when, and only when, they appear in all
capitals, as shown here.[¶](#section-2-1){.pilcrow}
:::

::: {#section-3 .section}
## [3.](#section-3){.section-number .selfRef} [Scope and Goals](#name-scope-and-goals){.section-name .selfRef} {#name-scope-and-goals}

The scope of this memo is to define an updated method to unambiguously
perform tests, measure the benchmark(s), and report the results for
Back-to-Back Frames (as described in [Section
26.4](https://www.rfc-editor.org/rfc/rfc2544#section-26.4){.relref} of
\[[RFC2544](#RFC2544){.xref}\]).[¶](#section-3-1){.pilcrow}

The goal is to provide more efficient test procedures where possible and
expand reporting with additional interpretation of the results. The
tests described in this memo address the cases in which the maximum
frame rate of a single ingress port cannot be transferred to an egress
port without loss (for some frame sizes of
interest).[¶](#section-3-2){.pilcrow}

Benchmarks as described in \[[RFC2544](#RFC2544){.xref}\] rely on test
conditions with constant frame sizes, with the goal of understanding
what network-device capability has been tested. Tests with the smallest
size stress the header-processing capacity, and tests with the largest
size stress the overall bit-processing capacity. Tests with sizes in
between may determine the transition between these two capacities.
However, conditions simultaneously sending a mixture of Internet (IMIX)
frame sizes, such as those described in \[[RFC6985](#RFC6985){.xref}\],
[MUST NOT]{.bcp14} be used in Back-to-Back Frame
testing.[¶](#section-3-3){.pilcrow}

[Section 3](https://www.rfc-editor.org/rfc/rfc8239#section-3){.relref}
of \[[RFC8239](#RFC8239){.xref}\] describes buffer-size testing for
physical networking devices in a data center. Those methods measure
buffer latency directly with traffic on multiple ingress ports that
overload an egress port on the Device Under Test (DUT) and are not
subject to the revised calculations presented in this memo. Likewise,
the methods of \[[RFC8239](#RFC8239){.xref}\] [SHOULD]{.bcp14} be used
for test cases where the egress-port buffer is the known point of
overload.[¶](#section-3-4){.pilcrow}
:::

::: {#motivation}
::: {#section-4 .section}
## [4.](#section-4){.section-number .selfRef} [Motivation](#name-motivation){.section-name .selfRef} {#name-motivation}

[Section
3.1](https://www.rfc-editor.org/rfc/rfc1242#section-3.1){.relref} of
\[[RFC1242](#RFC1242){.xref}\] describes the rationale for the
Back-to-Back Frames benchmark. To summarize, there are several reasons
that devices on a network produce bursts of frames at the minimum
allowed spacing; and it is, therefore, worthwhile to understand the DUT
limit on the length of such bursts in practice. The same document also
states:[¶](#section-4-1){.pilcrow}

> Tests of this parameter are intended to determine the extent of data
> buffering in the device.[¶](#section-4-2){.pilcrow}

Since this test was defined, there have been occasional discussions of
the stability and repeatability of the results, both over time and
across labs. Fortunately, the Open Platform for Network Function
Virtualization (OPNFV) project on Virtual Switch Performance (VSPERF)
Continuous Integration (CI) \[[VSPERF-CI](#VSPERF-CI){.xref}\] testing
routinely repeats Back-to-Back Frame tests to verify that test
functionality has been maintained through development of the
test-control programs. These tests were used as a basis to evaluate
stability and repeatability, even across lab setups when the test
platform was migrated to new DUT hardware at the end of
2016.[¶](#section-4-3){.pilcrow}

When the VSPERF CI results were examined
\[[VSPERF-b2b](#VSPERF-b2b){.xref}\], several aspects of the results
were considered notable:[¶](#section-4-4){.pilcrow}

1.  [Back-to-Back Frame benchmark was very consistent for some fixed
    frame sizes, and somewhat variable for other frame
    sizes.[¶](#section-4-5.1){.pilcrow}]{#section-4-5.1}
2.  [The number of Back-to-Back Frames with zero loss reported for large
    frame sizes was unexpectedly long (translating to 30 seconds of
    buffer time), and no explanation or measurement limit condition was
    indicated. It was important that the buffering time calculations
    were part of the referenced testing and analysis
    \[[VSPERF-b2b](#VSPERF-b2b){.xref}\], because the calculated buffer
    time of 30 seconds for some frame sizes was clearly wrong or highly
    suspect. On the other hand, a result expressed only as a large
    number of Back-to-Back Frames does not permit such an easy
    comparison with
    reality.[¶](#section-4-5.2){.pilcrow}]{#section-4-5.2}
3.  [Calculation of the extent of buffer time in the DUT helped to
    explain the results observed with all frame sizes. For example,
    tests with some frame sizes cannot exceed the
    frame-header-processing rate of the DUT, thus, no buffering occurs.
    Therefore, the results depended on the test equipment and not the
    DUT.[¶](#section-4-5.3){.pilcrow}]{#section-4-5.3}
4.  [It was found that a better estimate of the DUT buffer time could be
    calculated using measurements of both the longest burst in frames
    without loss and results from the Throughput tests conducted
    according to [Section
    26.1](https://www.rfc-editor.org/rfc/rfc2544#section-26.1){.relref}
    of \[[RFC2544](#RFC2544){.xref}\]. It is apparent that the DUT\'s
    frame-processing rate empties the buffer during a trial and tends to
    increase the \"implied\" buffer-size estimate (measured according to
    [Section
    26.4](https://www.rfc-editor.org/rfc/rfc2544#section-26.4){.relref}
    of \[[RFC2544](#RFC2544){.xref}\] because many frames have departed
    the buffer when the burst of frames ends). A calculation using the
    Throughput measurement can reveal a \"corrected\" buffer-size
    estimate.[¶](#section-4-5.4){.pilcrow}]{#section-4-5.4}

Further, if the Throughput tests of [Section
26.1](https://www.rfc-editor.org/rfc/rfc2544#section-26.1){.relref} of
\[[RFC2544](#RFC2544){.xref}\] are conducted as a prerequisite, the
number of frame sizes required for Back-to-Back Frame benchmarking can
be reduced to one or more of the small frame sizes, or the results for
large frame sizes can be noted as invalid in the results if tested
anyway. These are the larger frame sizes for which the Back-to-Back
Frame rate cannot exceed the frame-header-processing rate of the DUT and
little or no buffering occurs.[¶](#section-4-6){.pilcrow}

The material below provides the details of the calculation to estimate
the actual buffer storage available in the DUT, using results from the
Throughput tests for each frame size and the Max Theoretical Frame Rate
for the DUT links (which constrain the minimum frame
spacing).[¶](#section-4-7){.pilcrow}

In reality, there are many buffers and packet-header-processing steps in
a typical DUT. The simplified model used in these calculations for the
DUT includes a packet-header-processing function with limited rate of
operation, as shown in [Figure
1](#simplified-model){.xref}.[¶](#section-4-8){.pilcrow}

[]{#name-simplified-model-for-dut-te}

::: {#simplified-model}
::: {#section-4-9.1 .artwork .art-text .alignLeft}
                         |------------ DUT --------|
    Generator -> Ingress -> Buffer -> HeaderProc -> Egress -> Receiver
:::

[Figure 1](#figure-1){.selfRef}: [Simplified Model for DUT
Testing](#name-simplified-model-for-dut-te){.selfRef}
:::

So, in the Back-to-Back Frame testing:[¶](#section-4-10){.pilcrow}

1.  [The ingress burst arrives at Max Theoretical Frame Rate, and
    initially the frames are
    buffered.[¶](#section-4-11.1){.pilcrow}]{#section-4-11.1}
2.  [The packet-header-processing function (HeaderProc) operates at the
    \"Measured Throughput\" ([Section
    26.1](https://www.rfc-editor.org/rfc/rfc2544#section-26.1){.relref}
    of \[[RFC2544](#RFC2544){.xref}\]), removing frames from the buffer
    (this is the best approximation we have, another acceptable
    approximation is the received frame rate during Back-to-back Frame
    testing, if Measured Throughput is not
    available).[¶](#section-4-11.2){.pilcrow}]{#section-4-11.2}
3.  [Frames that have been processed are clearly not in the buffer, so
    the Corrected DUT Buffer Time equation ([Section
    6.4](#bench-calc){.xref}) estimates and removes the frames that the
    DUT forwarded on egress during the burst. We define buffer time as
    the number of frames occupying the buffer divided by the Max
    Theoretical Frame Rate (on ingress) for the frame size under
    test.[¶](#section-4-11.3){.pilcrow}]{#section-4-11.3}
4.  [A helpful concept is the buffer-filling rate, which is the
    difference between the Max Theoretical Frame Rate (ingress) and the
    Measured Throughput (HeaderProc on egress). If the actual buffer
    size in frames is known, the time to fill the buffer during a
    measurement can be calculated using the filling rate, as a check on
    measurements. However, the buffer in the model represents many
    buffers of different sizes in the DUT data
    path.[¶](#section-4-11.4){.pilcrow}]{#section-4-11.4}

Knowledge of approximate buffer storage size (in time or bytes) may be
useful in estimating whether frame losses will occur if DUT forwarding
is temporarily suspended in a production deployment due to an unexpected
interruption of frame processing (an interruption of duration greater
than the estimated buffer would certainly cause lost frames). In
[Section 6](#b2b){.xref}, the calculations for the correct buffer time
use the combination of offered load at Max Theoretical Frame Rate and
header-processing speed at 100% of Measured Throughput. Other
combinations are possible, such as changing the percent of Measured
Throughput to account for other processes reducing the header processing
rate.[¶](#section-4-12){.pilcrow}

The presentation of OPNFV VSPERF evaluation and development of enhanced
search algorithms \[[VSPERF-BSLV](#VSPERF-BSLV){.xref}\] was given and
discussed at IETF 102. The enhancements are intended to compensate for
transient processor interrupts that may cause loss at near-Throughput
levels of offered load. Subsequent analysis of the results indicates
that buffers within the DUT can compensate for some interrupts, and this
finding increases the importance of the Back-to-Back Frame
characterization described here.[¶](#section-4-13){.pilcrow}
:::
:::

::: {#section-5 .section}
## [5.](#section-5){.section-number .selfRef} [Prerequisites](#name-prerequisites){.section-name .selfRef} {#name-prerequisites}

The test setup [MUST]{.bcp14} be consistent with Figure 1 of
\[[RFC2544](#RFC2544){.xref}\], or Figure 2 of that document when the
tester\'s sender and receiver are different devices. Other mandatory
testing aspects described in \[[RFC2544](#RFC2544){.xref}\]
[MUST]{.bcp14} be included, unless explicitly modified in the next
section.[¶](#section-5-1){.pilcrow}

The ingress and egress link speeds and link-layer protocols
[MUST]{.bcp14} be specified and used to compute the Max Theoretical
Frame Rate when respecting the minimum interframe
gap.[¶](#section-5-2){.pilcrow}

The test results for the Throughput benchmark conducted according to
[Section
26.1](https://www.rfc-editor.org/rfc/rfc2544#section-26.1){.relref} of
\[[RFC2544](#RFC2544){.xref}\] for all frame sizes [RECOMMENDED]{.bcp14}
by \[[RFC2544](#RFC2544){.xref}\] [MUST]{.bcp14} be available to reduce
the tested-frame-size list or to note invalid results for individual
frame sizes (because the burst length may be essentially infinite for
large frame sizes).[¶](#section-5-3){.pilcrow}

Note that:[¶](#section-5-4){.pilcrow}

-   [the Throughput and the Back-to-Back Frame measurement-configuration
    traffic characteristics (unidirectional or bidirectional, and number
    of flows generated) [MUST]{.bcp14}
    match.[¶](#section-5-5.1){.pilcrow}]{#section-5-5.1}
-   [the Throughput measurement [MUST]{.bcp14} be taken under zero-loss
    conditions, according to [Section
    26.1](https://www.rfc-editor.org/rfc/rfc2544#section-26.1){.relref}
    of
    \[[RFC2544](#RFC2544){.xref}\].[¶](#section-5-5.2){.pilcrow}]{#section-5-5.2}

The Back-to-Back Benchmark described in [Section
3.1](https://www.rfc-editor.org/rfc/rfc1242#section-3.1){.relref} of
\[[RFC1242](#RFC1242){.xref}\] [MUST]{.bcp14} be measured directly by
the tester, where buffer size is inferred from Back-to-Back Frame bursts
and associated packet-loss measurements. Therefore, sources of frame
loss that are unrelated to consistent evaluation of buffer size
[SHOULD]{.bcp14} be identified and removed or mitigated. Example sources
include:[¶](#section-5-6){.pilcrow}

-   [On-path active components that are external to the
    DUT[¶](#section-5-7.1){.pilcrow}]{#section-5-7.1}
-   [Operating-system environment interrupting DUT
    operation[¶](#section-5-7.2){.pilcrow}]{#section-5-7.2}
-   [Shared-resource contention between the DUT and other off-path
    component(s) impacting DUT\'s behavior, sometimes called the \"noisy
    neighbor\" problem with virtualized network
    functions.[¶](#section-5-7.3){.pilcrow}]{#section-5-7.3}

Mitigations applicable to some of the sources above are discussed in
[Section 6.2](#frame-size){.xref}, with the other measurement
requirements described below in [Section
6](#b2b){.xref}.[¶](#section-5-8){.pilcrow}
:::

::: {#b2b}
::: {#section-6 .section}
## [6.](#section-6){.section-number .selfRef} [Back-to-Back Frames](#name-back-to-back-frames){.section-name .selfRef} {#name-back-to-back-frames}

Objective: To characterize the ability of a DUT to process Back-to-Back
Frames as defined in
\[[RFC1242](#RFC1242){.xref}\].[¶](#section-6-1){.pilcrow}

The procedure follows.[¶](#section-6-2){.pilcrow}

::: {#section-6.1 .section}
### [6.1.](#section-6.1){.section-number .selfRef} [Preparing the List of Frame Sizes](#name-preparing-the-list-of-frame){.section-name .selfRef} {#name-preparing-the-list-of-frame}

From the list of [RECOMMENDED]{.bcp14} frame sizes ([Section
9](https://www.rfc-editor.org/rfc/rfc2544#section-9){.relref} of
\[[RFC2544](#RFC2544){.xref}\]), select the subset of frame sizes whose
Measured Throughput (during prerequisite testing) was less than the Max
Theoretical Frame Rate of the DUT/test setup. These are the only frame
sizes where it is possible to produce a burst of frames that cause the
DUT buffers to fill and eventually overflow, producing one or more
discarded frames.[¶](#section-6.1-1){.pilcrow}
:::

::: {#frame-size}
::: {#section-6.2 .section}
### [6.2.](#section-6.2){.section-number .selfRef} [Test for a Single Frame Size](#name-test-for-a-single-frame-siz){.section-name .selfRef} {#name-test-for-a-single-frame-siz}

Each trial in the test requires the tester to send a burst of frames
(after idle time) with the minimum interframe gap and to count the
corresponding frames forwarded by the DUT.[¶](#section-6.2-1){.pilcrow}

The duration of the trial includes three [REQUIRED]{.bcp14}
components:[¶](#section-6.2-2){.pilcrow}

1.  [The time to send the burst of frames (at the back-to-back rate),
    determined by the search
    algorithm.[¶](#section-6.2-3.1){.pilcrow}]{#section-6.2-3.1}
2.  [The time to receive the transferred burst of frames (at the
    \[[RFC2544](#RFC2544){.xref}\] Throughput rate), possibly truncated
    by buffer overflow, and certainly including the latency of the
    DUT.[¶](#section-6.2-3.2){.pilcrow}]{#section-6.2-3.2}
3.  [At least 2 seconds not overlapping the time to receive the burst
    (Component 2, above), to ensure that DUT buffers have depleted.
    Longer times [MUST]{.bcp14} be used when conditions warrant, such as
    when buffer times >2 seconds are measured or when burst sending
    times are >2 seconds, but care is needed, since this time component
    directly increases trial duration, and many trials and tests
    comprise a complete benchmarking
    study.[¶](#section-6.2-3.3){.pilcrow}]{#section-6.2-3.3}

The upper search limit for the time to send each burst [MUST]{.bcp14} be
configurable to values as high as 30 seconds (buffer time results
reported at or near the configured upper limit are likely invalid, and
the test [MUST]{.bcp14} be repeated with a higher search
limit).[¶](#section-6.2-4){.pilcrow}

If all frames have been received, the tester increases the length of the
burst according to the search algorithm and performs another
trial.[¶](#section-6.2-5){.pilcrow}

If the received frame count is less than the number of frames in the
burst, then the limit of DUT processing and buffering may have been
exceeded, and the burst length for the next trial is determined by the
search algorithm (the burst length is typically reduced, but see
below).[¶](#section-6.2-6){.pilcrow}

Classic search algorithms have been adapted for use in benchmarking,
where the search requires discovery of a pair of outcomes, one with no
loss and another with loss, at load conditions within the acceptable
tolerance or accuracy. Conditions encountered when benchmarking the
infrastructure for network function virtualization require algorithm
enhancement. Fortunately, the adaptation of Binary Search, and an
enhanced Binary Search with Loss Verification, have been specified in
Clause 12.3 of \[[TST009](#TST009){.xref}\]. These algorithms can easily
be used for Back-to-Back Frame benchmarking by replacing the offered
load level with burst length in frames. \[[TST009](#TST009){.xref}\],
Annex B describes the theory behind the enhanced Binary Search with Loss
Verification algorithm.[¶](#section-6.2-7){.pilcrow}

There are also promising works in progress that may prove useful in
Back-to-Back Frame benchmarking.
\[[BMWG-MLRSEARCH](#I-D.ietf-bmwg-mlrsearch){.xref}\] and
\[[BMWG-PLRSEARCH](#I-D.vpolak-bmwg-plrsearch){.xref}\] are two such
examples.[¶](#section-6.2-8){.pilcrow}

Either the \[[TST009](#TST009){.xref}\] Binary Search or Binary Search
with Loss Verification algorithms [MUST]{.bcp14} be used, and input
parameters to the algorithm(s) [MUST]{.bcp14} be
reported.[¶](#section-6.2-9){.pilcrow}

The tester usually imposes a (configurable) minimum step size for burst
length, and the step size [MUST]{.bcp14} be reported with the results
(as this influences the accuracy and variation of test
results).[¶](#section-6.2-10){.pilcrow}

The original [Section
26.4](https://www.rfc-editor.org/rfc/rfc2544#section-26.4){.relref} of
\[[RFC2544](#RFC2544){.xref}\] definition is stated
below:[¶](#section-6.2-11){.pilcrow}

> The back-to-back value is the number of frames in the longest burst
> that the DUT will handle without the loss of any
> frames.[¶](#section-6.2-12){.pilcrow}
:::
:::

::: {#test-rep}
::: {#section-6.3 .section}
### [6.3.](#section-6.3){.section-number .selfRef} [Test Repetition and Benchmark](#name-test-repetition-and-benchma){.section-name .selfRef} {#name-test-repetition-and-benchma}

On this topic, [Section
26.4](https://www.rfc-editor.org/rfc/rfc2544#section-26.4){.relref} of
\[[RFC2544](#RFC2544){.xref}\] requires:[¶](#section-6.3-1){.pilcrow}

> The trial length [MUST]{.bcp14} be at least 2 seconds and
> [SHOULD]{.bcp14} be repeated at least 50 times with the average of the
> recorded values being reported.[¶](#section-6.3-2){.pilcrow}

Therefore, the Back-to-Back Frame benchmark is the average of
burst-length values over repeated tests to determine the longest burst
of frames that the DUT can successfully process and buffer without frame
loss. Each of the repeated tests completes an independent search
process.[¶](#section-6.3-3){.pilcrow}

In this update, the test [MUST]{.bcp14} be repeated N times (the number
of repetitions is now a variable that must be reported) for each frame
size in the subset list, and each Back-to-Back Frame value
[MUST]{.bcp14} be made available for further processing
(below).[¶](#section-6.3-4){.pilcrow}
:::
:::

::: {#bench-calc}
::: {#section-6.4 .section}
### [6.4.](#section-6.4){.section-number .selfRef} [Benchmark Calculations](#name-benchmark-calculations){.section-name .selfRef} {#name-benchmark-calculations}

For each frame size, calculate the following summary statistics for
longest Back-to-Back Frame values over the N
tests:[¶](#section-6.4-1){.pilcrow}

-   [Average
    (Benchmark)[¶](#section-6.4-2.1){.pilcrow}]{#section-6.4-2.1}
-   [Minimum[¶](#section-6.4-2.2){.pilcrow}]{#section-6.4-2.2}
-   [Maximum[¶](#section-6.4-2.3){.pilcrow}]{#section-6.4-2.3}
-   [Standard
    Deviation[¶](#section-6.4-2.4){.pilcrow}]{#section-6.4-2.4}

Further, calculate the Implied DUT Buffer Time and the Corrected DUT
Buffer Time in seconds, as follows:[¶](#section-6.4-3){.pilcrow}

::: {#section-6.4-4 .artwork .art-text .alignLeft}
    Implied DUT buffer time =

       Average num of Back-to-back Frames / Max Theoretical Frame Rate

[¶](#section-6.4-4){.pilcrow}
:::

The formula above is simply expressing the burst of frames in units of
time.[¶](#section-6.4-5){.pilcrow}

The next step is to apply a correction factor that accounts for the
DUT\'s frame forwarding operation during the test (assuming the simple
model of the DUT composed of a buffer and a forwarding function,
described in [Section
4](#motivation){.xref}).[¶](#section-6.4-6){.pilcrow}

::: {#section-6.4-7 .artwork .art-text .alignLeft}
    Corrected DUT Buffer Time =
                      /                                         \
       Implied DUT    |Implied DUT       Measured Throughput    |
    =  Buffer Time -  |Buffer Time * -------------------------- |
                      |              Max Theoretical Frame Rate |
                      \                                         /

[¶](#section-6.4-7){.pilcrow}
:::

where:[¶](#section-6.4-8){.pilcrow}

1.  [The \"Measured Throughput\" is the \[[RFC2544](#RFC2544){.xref}\]
    Throughput Benchmark for the frame size tested, as augmented by
    methods including the Binary Search with Loss Verification algorithm
    in \[[TST009](#TST009){.xref}\] where applicable and [MUST]{.bcp14}
    be expressed in frames per second in this
    equation.[¶](#section-6.4-9.1){.pilcrow}]{#section-6.4-9.1}
2.  [The \"Max Theoretical Frame Rate\" is a calculated value for the
    interface speed and link-layer technology used, and it
    [MUST]{.bcp14} be expressed in frames per second in this
    equation.[¶](#section-6.4-9.2){.pilcrow}]{#section-6.4-9.2}

The term on the far right in the formula for Corrected DUT Buffer Time
accounts for all the frames in the burst that were transmitted by the
DUT **while the burst of frames was sent in**.  So, these frames are not
in the buffer, and the buffer size is more accurately estimated by
excluding them. If Measured Throughput is not available, an acceptable
approximation is the received frame rate (see Forwarding Rate in
\[[RFC2889](#RFC2889){.xref}\] measured during Back-to-back Frame
testing).[¶](#section-6.4-10){.pilcrow}
:::
:::
:::
:::

::: {#section-7 .section}
## [7.](#section-7){.section-number .selfRef} [Reporting](#name-reporting){.section-name .selfRef} {#name-reporting}

The Back-to-Back Frame results [SHOULD]{.bcp14} be reported in the
format of a table with a row for each of the tested frame sizes. There
[SHOULD]{.bcp14} be columns for the frame size and the resultant average
frame count for each type of data stream
tested.[¶](#section-7-1){.pilcrow}

The number of tests averaged for the benchmark, N, [MUST]{.bcp14} be
reported.[¶](#section-7-2){.pilcrow}

The minimum, maximum, and standard deviation across all complete tests
[SHOULD]{.bcp14} also be reported (they are referred to as
\"Min,Max,StdDev\" in [Table
1](#frame-results){.xref}).[¶](#section-7-3){.pilcrow}

The Corrected DUT Buffer Time [SHOULD]{.bcp14} also be
reported.[¶](#section-7-4){.pilcrow}

If the tester operates using a limited maximum burst length in frames,
then this maximum length [SHOULD]{.bcp14} be
reported.[¶](#section-7-5){.pilcrow}

[]{#name-back-to-back-frame-results}

::: {#frame-results}
  Frame Size, octets   Ave B2B Length, frames   Min,Max,StdDev   Corrected Buff Time, Sec
  -------------------- ------------------------ ---------------- --------------------------
  64                   26000                    25500,27000,20   0.00004

  : [Table 1](#table-1){.selfRef}: [Back-to-Back Frame
  Results](#name-back-to-back-frame-results){.selfRef}
:::

Static and configuration parameters (reported with [Table
1](#frame-results){.xref}):[¶](#section-7-7){.pilcrow}

-   [Number of test repetitions,
    N[¶](#section-7-8.1){.pilcrow}]{#section-7-8.1}
-   [Minimum Step Size (during searches), in
    frames.[¶](#section-7-8.2){.pilcrow}]{#section-7-8.2}

If the tester has a specific (actual) frame rate of interest (less than
the Throughput rate), it is useful to estimate the buffer time at that
actual frame rate:[¶](#section-7-10){.pilcrow}

::: {#section-7-11 .artwork .art-text .alignLeft}
    Actual Buffer Time =
                                       Max Theoretical Frame Rate
         = Corrected DUT Buffer Time * --------------------------
                                           Actual Frame Rate

[¶](#section-7-11){.pilcrow}
:::

and report this value, properly labeled.[¶](#section-7-12){.pilcrow}
:::

::: {#section-8 .section}
## [8.](#section-8){.section-number .selfRef} [Security Considerations](#name-security-considerations){.section-name .selfRef} {#name-security-considerations}

Benchmarking activities as described in this memo are limited to
technology characterization using controlled stimuli in a laboratory
environment, with dedicated address space and the other constraints of
\[[RFC2544](#RFC2544){.xref}\].[¶](#section-8-1){.pilcrow}

The benchmarking network topology will be an independent test setup and
[MUST NOT]{.bcp14} be connected to devices that may forward the test
traffic into a production network or misroute traffic to the test
management network. See
\[[RFC6815](#RFC6815){.xref}\].[¶](#section-8-2){.pilcrow}

Further, benchmarking is performed on an \"opaque-box\" (a.k.a.
\"black-box\") basis, relying solely on measurements observable external
to the Device or System Under Test (SUT).[¶](#section-8-3){.pilcrow}

The DUT developers are commonly independent from the personnel and
institutions conducting benchmarking studies. DUT developers might have
incentives to alter the performance of the DUT if the test conditions
can be detected. Special capabilities [SHOULD NOT]{.bcp14} exist in the
DUT/SUT specifically for benchmarking purposes. Procedures described in
this document are not designed to detect such activity. Additional
testing outside of the scope of this document would be needed and has
been used successfully in the past to discover such
malpractices.[¶](#section-8-4){.pilcrow}

Any implications for network security arising from the DUT/SUT
[SHOULD]{.bcp14} be identical in the lab and in production
networks.[¶](#section-8-5){.pilcrow}
:::

::: {#IANA}
::: {#section-9 .section}
## [9.](#section-9){.section-number .selfRef} [IANA Considerations](#name-iana-considerations){.section-name .selfRef} {#name-iana-considerations}

This document has no IANA actions.[¶](#section-9-1){.pilcrow}
:::
:::

::: {#section-10 .section}
## [10.](#section-10){.section-number .selfRef} [References](#name-references){.section-name .selfRef} {#name-references}

::: {#section-10.1 .section}
### [10.1.](#section-10.1){.section-number .selfRef} [Normative References](#name-normative-references){.section-name .selfRef} {#name-normative-references}

\[RFC1242\]
:   [Bradner, S.]{.refAuthor}, [\"Benchmarking Terminology for Network
    Interconnection Devices\"]{.refTitle}, [RFC 1242]{.seriesInfo}, [DOI
    10.17487/RFC1242]{.seriesInfo}, July 1991,
    \<<https://www.rfc-editor.org/info/rfc1242>\>.
:   

\[RFC2119\]
:   [Bradner, S.]{.refAuthor}, [\"Key words for use in RFCs to Indicate
    Requirement Levels\"]{.refTitle}, [BCP 14]{.seriesInfo}, [RFC
    2119]{.seriesInfo}, [DOI 10.17487/RFC2119]{.seriesInfo}, March 1997,
    \<<https://www.rfc-editor.org/info/rfc2119>\>.
:   

\[RFC2544\]
:   [Bradner, S.]{.refAuthor} and [J. McQuaid]{.refAuthor},
    [\"Benchmarking Methodology for Network Interconnect
    Devices\"]{.refTitle}, [RFC 2544]{.seriesInfo}, [DOI
    10.17487/RFC2544]{.seriesInfo}, March 1999,
    \<<https://www.rfc-editor.org/info/rfc2544>\>.
:   

\[RFC6985\]
:   [Morton, A.]{.refAuthor}, [\"IMIX Genome: Specification of Variable
    Packet Sizes for Additional Testing\"]{.refTitle}, [RFC
    6985]{.seriesInfo}, [DOI 10.17487/RFC6985]{.seriesInfo}, July 2013,
    \<<https://www.rfc-editor.org/info/rfc6985>\>.
:   

\[RFC8174\]
:   [Leiba, B.]{.refAuthor}, [\"Ambiguity of Uppercase vs Lowercase in
    RFC 2119 Key Words\"]{.refTitle}, [BCP 14]{.seriesInfo}, [RFC
    8174]{.seriesInfo}, [DOI 10.17487/RFC8174]{.seriesInfo}, May 2017,
    \<<https://www.rfc-editor.org/info/rfc8174>\>.
:   

\[RFC8239\]
:   [Avramov, L.]{.refAuthor} and [J. Rapp]{.refAuthor}, [\"Data Center
    Benchmarking Methodology\"]{.refTitle}, [RFC 8239]{.seriesInfo},
    [DOI 10.17487/RFC8239]{.seriesInfo}, August 2017,
    \<<https://www.rfc-editor.org/info/rfc8239>\>.
:   

\[TST009\]
:   [ETSI]{.refAuthor}, [\"Network Functions Virtualisation (NFV)
    Release 3; Testing; Specification of Networking Benchmarks and
    Measurement Methods for NFVI\"]{.refTitle}, [Rapporteur: A.
    Morton]{.refContent}, [ETSI GS NFV-TST 009 v3.4.1]{.seriesInfo},
    December 2020,
    \<<https://www.etsi.org/deliver/etsi_gs/NFV-TST/001_099/009/03.04.01_60/gs_NFV-TST009v030401p.pdf>\>.
:   
:::

::: {#section-10.2 .section}
### [10.2.](#section-10.2){.section-number .selfRef} [Informative References](#name-informative-references){.section-name .selfRef} {#name-informative-references}

\[BMWG-MLRSEARCH\]
:   [Konstantynowicz, M., Ed.]{.refAuthor} and [V. Polák,
    Ed.]{.refAuthor}, [\"Multiple Loss Ratio Search for Packet
    Throughput (MLRsearch)\"]{.refTitle}, [Work in
    Progress]{.refContent}, [Internet-Draft,
    draft-ietf-bmwg-mlrsearch-00]{.seriesInfo}, 9 February 2021,
    \<<https://tools.ietf.org/html/draft-ietf-bmwg-mlrsearch-00>\>.
:   

\[BMWG-PLRSEARCH\]
:   [Konstantynowicz, M., Ed.]{.refAuthor} and [V. Polák,
    Ed.]{.refAuthor}, [\"Probabilistic Loss Ratio Search for Packet
    Throughput (PLRsearch)\"]{.refTitle}, [Work in
    Progress]{.refContent}, [Internet-Draft,
    draft-vpolak-bmwg-plrsearch-03]{.seriesInfo}, 6 March 2020,
    \<<https://tools.ietf.org/html/draft-vpolak-bmwg-plrsearch-03>\>.
:   

\[OPNFV-2017\]
:   [Cooper, T.]{.refAuthor}, [Rao, S.]{.refAuthor}, and [A.
    Morton]{.refAuthor}, [\"Dataplane Performance, Capacity, and
    Benchmarking in OPNFV\"]{.refTitle}, 15 June 2017,
    \<<https://wiki.anuket.io/download/attachments/4404001/VSPERF-Dataplane-Perf-Cap-Bench.pdf?version=1&modificationDate=1621191833500&api=v2>\>.
:   

\[RFC1944\]
:   [Bradner, S.]{.refAuthor} and [J. McQuaid]{.refAuthor},
    [\"Benchmarking Methodology for Network Interconnect
    Devices\"]{.refTitle}, [RFC 1944]{.seriesInfo}, [DOI
    10.17487/RFC1944]{.seriesInfo}, May 1996,
    \<<https://www.rfc-editor.org/info/rfc1944>\>.
:   

\[RFC2889\]
:   [Mandeville, R.]{.refAuthor} and [J. Perser]{.refAuthor},
    [\"Benchmarking Methodology for LAN Switching Devices\"]{.refTitle},
    [RFC 2889]{.seriesInfo}, [DOI 10.17487/RFC2889]{.seriesInfo}, August
    2000, \<<https://www.rfc-editor.org/info/rfc2889>\>.
:   

\[RFC5180\]
:   [Popoviciu, C.]{.refAuthor}, [Hamza, A.]{.refAuthor}, [Van de
    Velde, G.]{.refAuthor}, and [D. Dugatkin]{.refAuthor}, [\"IPv6
    Benchmarking Methodology for Network Interconnect
    Devices\"]{.refTitle}, [RFC 5180]{.seriesInfo}, [DOI
    10.17487/RFC5180]{.seriesInfo}, May 2008,
    \<<https://www.rfc-editor.org/info/rfc5180>\>.
:   

\[RFC6201\]
:   [Asati, R.]{.refAuthor}, [Pignataro, C.]{.refAuthor},
    [Calabria, F.]{.refAuthor}, and [C. Olvera]{.refAuthor}, [\"Device
    Reset Characterization\"]{.refTitle}, [RFC 6201]{.seriesInfo}, [DOI
    10.17487/RFC6201]{.seriesInfo}, March 2011,
    \<<https://www.rfc-editor.org/info/rfc6201>\>.
:   

\[RFC6815\]
:   [Bradner, S.]{.refAuthor}, [Dubray, K.]{.refAuthor},
    [McQuaid, J.]{.refAuthor}, and [A. Morton]{.refAuthor},
    [\"Applicability Statement for RFC 2544: Use on Production Networks
    Considered Harmful\"]{.refTitle}, [RFC 6815]{.seriesInfo}, [DOI
    10.17487/RFC6815]{.seriesInfo}, November 2012,
    \<<https://www.rfc-editor.org/info/rfc6815>\>.
:   

\[VSPERF-b2b\]
:   [Morton, A.]{.refAuthor}, [\"Back2Back Testing Time Series (from
    CI)\"]{.refTitle}, May 2021,
    \<<https://wiki.anuket.io/display/HOME/Traffic+Generator+Testing#TrafficGeneratorTesting-AppendixB:Back2BackTestingTimeSeries(fromCI)>\>.
:   

\[VSPERF-BSLV\]
:   [Rao, S.]{.refAuthor} and [A. Morton]{.refAuthor}, [\"Evolution of
    Repeatability in Benchmarking: Fraser Plugfest (Summary for IETF
    BMWG)\"]{.refTitle}, July 2018,
    \<<https://datatracker.ietf.org/meeting/102/materials/slides-102-bmwg-evolution-of-repeatability-in-benchmarking-fraser-plugfest-summary-for-ietf-bmwg-00>\>.
:   

\[VSPERF-CI\]
:   [Tahhan, M.]{.refAuthor}, [\"OPNFV VSPERF CI\"]{.refTitle},
    September 2019, \<<https://wiki.anuket.io/display/HOME/VSPERF+CI>\>.
:   
:::
:::

::: {#section-appendix.a .section}
## [Acknowledgments](#name-acknowledgments){.section-name .selfRef} {#name-acknowledgments}

Thanks to [Trevor Cooper]{.contact-name}, [Sridhar Rao]{.contact-name},
and [Martin Klozik]{.contact-name} of the VSPERF project for many
contributions to the early testing \[[VSPERF-b2b](#VSPERF-b2b){.xref}\].
[Yoshiaki Itou]{.contact-name} has also investigated the topic and made
useful suggestions. [Maciek Konstantyowicz]{.contact-name} and [Vratko
Polák]{.contact-name} also provided many comments and suggestions based
on extensive integration testing and resulting search-algorithm
proposals \-- the most up-to-date feedback possible. [Tim
Carlin]{.contact-name} also provided comments and support for the
document. [Warren Kumari]{.contact-name}\'s review improved readability
in several key passages. [David Black]{.contact-name}, [Martin
Duke]{.contact-name}, and [Scott Bradner]{.contact-name}\'s comments
improved the clarity and configuration advice on trial duration. [Mališa
Vučinić]{.contact-name} suggested additional text on DUT design cautions
in the Security Considerations
section.[¶](#section-appendix.a-1){.pilcrow}
:::

::: {#authors-addresses}
::: {#section-appendix.b .section}
## [Author\'s Address](#name-authors-address){.section-name .selfRef} {#name-authors-address}

::: {.left dir="auto"}
[Al Morton]{.fn .nameRole}
:::

::: {.left dir="auto"}
[AT&T Labs]{.org}
:::

::: {.left dir="auto"}
[200 Laurel Avenue South]{.street-address}
:::

::: {.left dir="auto"}
[Middletown]{.locality}, [NJ]{.region} [07748]{.postal-code}
:::

::: {.left dir="auto"}
[United States of America]{.country-name}
:::

::: tel
Phone: [+1 732 420 1571](tel:+1%20732%20420%201571){.tel}
:::

::: email
Email: <acmorton@att.com>
:::
:::
:::
