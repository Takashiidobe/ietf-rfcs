  RFC 8761           Video Codec Requirements and Evaluation   April 2020
  ------------------ ----------------------------------------- ------------
  Filippov, et al.   Informational                             \[Page\]

::: {#external-metadata .document-information}
:::

::: {#internal-metadata .document-information}

Stream:
:   Internet Engineering Task Force (IETF)

RFC:
:   [8761](https://www.rfc-editor.org/rfc/rfc8761){.eref}

Category:
:   Informational

Published:
:   April 2020

ISSN:
:   2070-1721

Authors:

:   ::: author
    ::: author-name
    A. Filippov
    :::

    ::: org
    Huawei Technologies
    :::
    :::

    ::: author
    ::: author-name
    A. Norkin
    :::

    ::: org
    Netflix
    :::
    :::

    ::: author
    ::: author-name
    J.R. Alvarez
    :::

    ::: org
    Huawei Technologies
    :::
    :::
:::

# RFC 8761 {#rfcnum}

# Video Codec Requirements and Evaluation Methodology {#title}

::: {#section-abstract .section}
## [Abstract](#abstract){.selfRef}

This document provides requirements for a video codec designed mainly
for use over the Internet. In addition, this document describes an
evaluation methodology for measuring the compression efficiency to
determine whether or not the stated requirements have been
fulfilled.[¶](#section-abstract-1){.pilcrow}
:::

::: {#status-of-memo}
::: {#section-boilerplate.1 .section}
## [Status of This Memo](#name-status-of-this-memo){.section-name .selfRef} {#name-status-of-this-memo}

This document is not an Internet Standards Track specification; it is
published for informational
purposes.[¶](#section-boilerplate.1-1){.pilcrow}

This document is a product of the Internet Engineering Task Force
(IETF). It represents the consensus of the IETF community. It has
received public review and has been approved for publication by the
Internet Engineering Steering Group (IESG). Not all documents approved
by the IESG are candidates for any level of Internet Standard; see
Section 2 of RFC 7841.[¶](#section-boilerplate.1-2){.pilcrow}

Information about the current status of this document, any errata, and
how to provide feedback on it may be obtained at
<https://www.rfc-editor.org/info/rfc8761>.[¶](#section-boilerplate.1-3){.pilcrow}
:::
:::

::: {#copyright}
::: {#section-boilerplate.2 .section}
## [Copyright Notice](#name-copyright-notice){.section-name .selfRef} {#name-copyright-notice}

Copyright (c) 2020 IETF Trust and the persons identified as the document
authors. All rights reserved.[¶](#section-boilerplate.2-1){.pilcrow}

This document is subject to BCP 78 and the IETF Trust\'s Legal
Provisions Relating to IETF Documents
(<https://trustee.ietf.org/license-info>) in effect on the date of
publication of this document. Please review these documents carefully,
as they describe your rights and restrictions with respect to this
document. Code Components extracted from this document must include
Simplified BSD License text as described in Section 4.e of the Trust
Legal Provisions and are provided without warranty as described in the
Simplified BSD License.[¶](#section-boilerplate.2-2){.pilcrow}
:::
:::

::: {#toc}
::: {#section-toc.1 .section}
[▲](#){.toplink}

## [Table of Contents](#name-table-of-contents){.section-name .selfRef} {#name-table-of-contents}

-   ::: {#section-toc.1-1.1}
    [1](#section-1){.xref}.  [Introduction](#name-introduction){.xref}[¶](#section-toc.1-1.1.1){.pilcrow}
    :::

-   ::: {#section-toc.1-1.2}
    [2](#section-2){.xref}.  [Terminology Used in This
    Document](#name-terminology-used-in-this-do){.xref}[¶](#section-toc.1-1.2.1){.pilcrow}

    -   ::: {#section-toc.1-1.2.2.1}
        [2.1](#section-2.1){.xref}.  [Definitions](#name-definitions){.xref}[¶](#section-toc.1-1.2.2.1.1){.pilcrow}
        :::

    -   ::: {#section-toc.1-1.2.2.2}
        [2.2](#section-2.2){.xref}.  [Abbreviations](#name-abbreviations){.xref}[¶](#section-toc.1-1.2.2.2.1){.pilcrow}
        :::
    :::

-   ::: {#section-toc.1-1.3}
    [3](#section-3){.xref}.  [Applications](#name-applications){.xref}[¶](#section-toc.1-1.3.1){.pilcrow}

    -   ::: {#section-toc.1-1.3.2.1}
        [3.1](#section-3.1){.xref}.  [Internet Video
        Streaming](#name-internet-video-streaming){.xref}[¶](#section-toc.1-1.3.2.1.1){.pilcrow}
        :::

    -   ::: {#section-toc.1-1.3.2.2}
        [3.2](#section-3.2){.xref}.  [Internet Protocol Television
        (IPTV)](#name-internet-protocol-televisio){.xref}[¶](#section-toc.1-1.3.2.2.1){.pilcrow}
        :::

    -   ::: {#section-toc.1-1.3.2.3}
        [3.3](#section-3.3){.xref}.  [Video
        Conferencing](#name-video-conferencing){.xref}[¶](#section-toc.1-1.3.2.3.1){.pilcrow}
        :::

    -   ::: {#section-toc.1-1.3.2.4}
        [3.4](#section-3.4){.xref}.  [Video
        Sharing](#name-video-sharing){.xref}[¶](#section-toc.1-1.3.2.4.1){.pilcrow}
        :::

    -   ::: {#section-toc.1-1.3.2.5}
        [3.5](#section-3.5){.xref}.  [Screencasting](#name-screencasting){.xref}[¶](#section-toc.1-1.3.2.5.1){.pilcrow}
        :::

    -   ::: {#section-toc.1-1.3.2.6}
        [3.6](#section-3.6){.xref}.  [Game
        Streaming](#name-game-streaming){.xref}[¶](#section-toc.1-1.3.2.6.1){.pilcrow}
        :::

    -   ::: {#section-toc.1-1.3.2.7}
        [3.7](#section-3.7){.xref}.  [Video Monitoring and
        Surveillance](#name-video-monitoring-and-survei){.xref}[¶](#section-toc.1-1.3.2.7.1){.pilcrow}
        :::
    :::

-   ::: {#section-toc.1-1.4}
    [4](#section-4){.xref}.  [Requirements](#name-requirements){.xref}[¶](#section-toc.1-1.4.1){.pilcrow}

    -   ::: {#section-toc.1-1.4.2.1}
        [4.1](#section-4.1){.xref}.  [General
        Requirements](#name-general-requirements){.xref}[¶](#section-toc.1-1.4.2.1.1){.pilcrow}

        -   ::: {#section-toc.1-1.4.2.1.2.1}
            [4.1.1](#section-4.1.1){.xref}.  [Coding
            Efficiency](#name-coding-efficiency){.xref}[¶](#section-toc.1-1.4.2.1.2.1.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.1.2.2}
            [4.1.2](#section-4.1.2){.xref}.  [Profiles and
            Levels](#name-profiles-and-levels){.xref}[¶](#section-toc.1-1.4.2.1.2.2.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.1.2.3}
            [4.1.3](#section-4.1.3){.xref}.  [Bitstream
            Syntax](#name-bitstream-syntax){.xref}[¶](#section-toc.1-1.4.2.1.2.3.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.1.2.4}
            [4.1.4](#section-4.1.4){.xref}.  [Parsing and Identification
            of Sample
            Components](#name-parsing-and-identification-){.xref}[¶](#section-toc.1-1.4.2.1.2.4.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.1.2.5}
            [4.1.5](#section-4.1.5){.xref}.  [Perceptual Quality
            Tools](#name-perceptual-quality-tools){.xref}[¶](#section-toc.1-1.4.2.1.2.5.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.1.2.6}
            [4.1.6](#section-4.1.6){.xref}.  [Buffer
            Model](#name-buffer-model){.xref}[¶](#section-toc.1-1.4.2.1.2.6.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.1.2.7}
            [4.1.7](#section-4.1.7){.xref}.  [Integration](#name-integration){.xref}[¶](#section-toc.1-1.4.2.1.2.7.1){.pilcrow}
            :::
        :::

    -   ::: {#section-toc.1-1.4.2.2}
        [4.2](#section-4.2){.xref}.  [Basic
        Requirements](#name-basic-requirements){.xref}[¶](#section-toc.1-1.4.2.2.1){.pilcrow}

        -   ::: {#section-toc.1-1.4.2.2.2.1}
            [4.2.1](#section-4.2.1){.xref}.  [Input Source
            Formats](#name-input-source-formats){.xref}[¶](#section-toc.1-1.4.2.2.2.1.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.2.2.2}
            [4.2.2](#section-4.2.2){.xref}.  [Coding
            Delay](#name-coding-delay){.xref}[¶](#section-toc.1-1.4.2.2.2.2.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.2.2.3}
            [4.2.3](#section-4.2.3){.xref}.  [Complexity](#name-complexity){.xref}[¶](#section-toc.1-1.4.2.2.2.3.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.2.2.4}
            [4.2.4](#section-4.2.4){.xref}.  [Scalability](#name-scalability){.xref}[¶](#section-toc.1-1.4.2.2.2.4.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.2.2.5}
            [4.2.5](#section-4.2.5){.xref}.  [Error
            Resilience](#name-error-resilience){.xref}[¶](#section-toc.1-1.4.2.2.2.5.1){.pilcrow}
            :::
        :::

    -   ::: {#section-toc.1-1.4.2.3}
        [4.3](#section-4.3){.xref}.  [Optional
        Requirements](#name-optional-requirements){.xref}[¶](#section-toc.1-1.4.2.3.1){.pilcrow}

        -   ::: {#section-toc.1-1.4.2.3.2.1}
            [4.3.1](#section-4.3.1){.xref}.  [Input Source
            Formats](#name-input-source-formats-2){.xref}[¶](#section-toc.1-1.4.2.3.2.1.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.3.2.2}
            [4.3.2](#section-4.3.2){.xref}.  [Scalability](#name-scalability-2){.xref}[¶](#section-toc.1-1.4.2.3.2.2.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.3.2.3}
            [4.3.3](#section-4.3.3){.xref}.  [Complexity](#name-complexity-2){.xref}[¶](#section-toc.1-1.4.2.3.2.3.1){.pilcrow}
            :::

        -   ::: {#section-toc.1-1.4.2.3.2.4}
            [4.3.4](#section-4.3.4){.xref}.  [Coding
            Efficiency](#name-coding-efficiency-2){.xref}[¶](#section-toc.1-1.4.2.3.2.4.1){.pilcrow}
            :::
        :::
    :::

-   ::: {#section-toc.1-1.5}
    [5](#section-5){.xref}.  [Evaluation
    Methodology](#name-evaluation-methodology){.xref}[¶](#section-toc.1-1.5.1){.pilcrow}
    :::

-   ::: {#section-toc.1-1.6}
    [6](#section-6){.xref}.  [Security
    Considerations](#name-security-considerations){.xref}[¶](#section-toc.1-1.6.1){.pilcrow}
    :::

-   ::: {#section-toc.1-1.7}
    [7](#section-7){.xref}.  [IANA
    Considerations](#name-iana-considerations){.xref}[¶](#section-toc.1-1.7.1){.pilcrow}
    :::

-   ::: {#section-toc.1-1.8}
    [8](#section-8){.xref}.  [References](#name-references){.xref}[¶](#section-toc.1-1.8.1){.pilcrow}

    -   ::: {#section-toc.1-1.8.2.1}
        [8.1](#section-8.1){.xref}.  [Normative
        References](#name-normative-references){.xref}[¶](#section-toc.1-1.8.2.1.1){.pilcrow}
        :::

    -   ::: {#section-toc.1-1.8.2.2}
        [8.2](#section-8.2){.xref}.  [Informative
        References](#name-informative-references){.xref}[¶](#section-toc.1-1.8.2.2.1){.pilcrow}
        :::
    :::

-   ::: {#section-toc.1-1.9}
    [](#section-appendix.a){.xref}[Acknowledgments](#name-acknowledgments){.xref}[¶](#section-toc.1-1.9.1){.pilcrow}
    :::

-   ::: {#section-toc.1-1.10}
    [](#section-appendix.b){.xref}[Authors\'
    Addresses](#name-authors-addresses){.xref}[¶](#section-toc.1-1.10.1){.pilcrow}
    :::
:::
:::

::: {#section-1 .section}
## [1.](#section-1){.section-number .selfRef} [Introduction](#name-introduction){.section-name .selfRef} {#name-introduction}

This document presents the requirements for a video codec designed
mainly for use over the Internet. The requirements encompass a wide
range of applications that use data transmission over the Internet,
including Internet video streaming, IPTV, peer-to-peer video
conferencing, video sharing, screencasting, game streaming, and video
monitoring and surveillance. For each application, typical resolutions,
frame rates, and picture-access modes are presented. Specific
requirements related to data transmission over packet-loss networks are
considered as well. In this document, when we discuss data-protection
techniques, we only refer to methods designed and implemented to protect
data inside the video codec since there are many existing techniques
that protect generic data transmitted over networks with packet losses.
From the theoretical point of view, both packet-loss and bit-error
robustness can be beneficial for video codecs. In practice, packet
losses are a more significant problem than bit corruption in IP
networks. It is worth noting that there is an evident interdependence
between the possible amount of delay and the necessity of error-robust
video streams:[¶](#section-1-1){.pilcrow}

-   [If the amount of delay is not crucial for an application, then
    reliable transport protocols such as TCP that retransmit undelivered
    packets can be used to guarantee correct decoding of transmitted
    data.[¶](#section-1-2.1){.pilcrow}]{#section-1-2.1}
-   [If the amount of delay must be kept low, then either data
    transmission should be error free (e.g., by using managed networks)
    or the compressed video stream should be error
    resilient.[¶](#section-1-2.2){.pilcrow}]{#section-1-2.2}

Thus, error resilience can be useful for delay-critical applications to
provide low delay in a packet-loss
environment.[¶](#section-1-3){.pilcrow}
:::

::: {#defs}
::: {#section-2 .section}
## [2.](#section-2){.section-number .selfRef} [Terminology Used in This Document](#name-terminology-used-in-this-do){.section-name .selfRef} {#name-terminology-used-in-this-do}

::: {#def1}
::: {#section-2.1 .section}
### [2.1.](#section-2.1){.section-number .selfRef} [Definitions](#name-definitions){.section-name .selfRef} {#name-definitions}

High dynamic range imaging
:   A set of techniques that allows a greater dynamic range of exposures
    or values (i.e., a wider range of values between light and dark
    areas) than normal digital imaging techniques. The intention is to
    accurately represent the wide range of intensity levels found in
    examples such as exterior scenes that include light-colored items
    struck by direct sunlight and areas of deep shadow
    \[[7](#HDR){.xref}\].[¶](#section-2.1-1.2){.pilcrow}
:   

Random access period
:   The period of time between the two closest independently decodable
    frames (pictures).[¶](#section-2.1-1.4){.pilcrow}
:   

RD-point
:   A point in a two-dimensional rate-distortion space where the values
    of bitrate and quality metric are used as x- and y-coordinates,
    respectively.[¶](#section-2.1-1.6){.pilcrow}
:   

Visually lossless compression
:   A form or manner of lossy compression where the data that are lost
    after the file is compressed and decompressed is not detectable to
    the eye; the compressed data appear identical to the uncompressed
    data \[[8](#COMPRESSION){.xref}\].[¶](#section-2.1-1.8){.pilcrow}
:   

Wide color gamut
:   A certain complete color subset (e.g., considered in ITU-R BT.2020
    \[[1](#BT2020-2){.xref}\]) that supports a wider range of colors
    (i.e., an extended range of colors that can be generated by a
    specific input or output device such as a video camera, monitor, or
    printer and can be interpreted by a color model) than conventional
    color gamuts (e.g., considered in ITU-R BT.601
    \[[17](#BT601){.xref}\] or BT.709
    \[[20](#BT709){.xref}\]).[¶](#section-2.1-1.10){.pilcrow}
:   
:::
:::

::: {#abbr}
::: {#section-2.2 .section}
### [2.2.](#section-2.2){.section-number .selfRef} [Abbreviations](#name-abbreviations){.section-name .selfRef} {#name-abbreviations}

AI
:   All-Intra (each picture is
    intra-coded)[¶](#section-2.2-1.2){.pilcrow}
:   

BD-Rate
:   Bjontegaard Delta Rate[¶](#section-2.2-1.4){.pilcrow}
:   

FIZD
:   just the First picture is Intra-coded, Zero structural
    Delay[¶](#section-2.2-1.6){.pilcrow}
:   

FPS
:   Frames per Second[¶](#section-2.2-1.8){.pilcrow}
:   

GOP
:   Group of Picture[¶](#section-2.2-1.10){.pilcrow}
:   

GPU
:   Graphics Processing Unit[¶](#section-2.2-1.12){.pilcrow}
:   

HBR
:   High Bitrate Range[¶](#section-2.2-1.14){.pilcrow}
:   

HDR
:   High Dynamic Range[¶](#section-2.2-1.16){.pilcrow}
:   

HRD
:   Hypothetical Reference Decoder[¶](#section-2.2-1.18){.pilcrow}
:   

HEVC
:   High Efficiency Video Coding[¶](#section-2.2-1.20){.pilcrow}
:   

IPTV
:   Internet Protocol Television[¶](#section-2.2-1.22){.pilcrow}
:   

LBR
:   Low Bitrate Range[¶](#section-2.2-1.24){.pilcrow}
:   

MBR
:   Medium Bitrate Range[¶](#section-2.2-1.26){.pilcrow}
:   

MOS
:   Mean Opinion Score[¶](#section-2.2-1.28){.pilcrow}
:   

MS-SSIM
:   Multi-Scale Structural Similarity quality
    index[¶](#section-2.2-1.30){.pilcrow}
:   

PAM
:   Picture Access Mode[¶](#section-2.2-1.32){.pilcrow}
:   

PSNR
:   Peak Signal-to-Noise Ratio[¶](#section-2.2-1.34){.pilcrow}
:   

QoS
:   Quality of Service[¶](#section-2.2-1.36){.pilcrow}
:   

QP
:   Quantization Parameter[¶](#section-2.2-1.38){.pilcrow}
:   

RA
:   Random Access[¶](#section-2.2-1.40){.pilcrow}
:   

RAP
:   Random Access Period[¶](#section-2.2-1.42){.pilcrow}
:   

RD
:   Rate-Distortion[¶](#section-2.2-1.44){.pilcrow}
:   

SEI
:   Supplemental Enhancement Information[¶](#section-2.2-1.46){.pilcrow}
:   

SIMD
:   Single Instruction, Multiple Data[¶](#section-2.2-1.48){.pilcrow}
:   

SNR
:   Signal-to-Noise Ratio[¶](#section-2.2-1.50){.pilcrow}
:   

UGC
:   User-Generated Content[¶](#section-2.2-1.52){.pilcrow}
:   

VDI
:   Virtual Desktop Infrastructure[¶](#section-2.2-1.54){.pilcrow}
:   

VUI
:   Video Usability Information[¶](#section-2.2-1.56){.pilcrow}
:   

WCG
:   Wide Color Gamut[¶](#section-2.2-1.58){.pilcrow}
:   
:::
:::
:::
:::

::: {#apps}
::: {#section-3 .section}
## [3.](#section-3){.section-number .selfRef} [Applications](#name-applications){.section-name .selfRef} {#name-applications}

In this section, an overview of video codec applications that are
currently available on the Internet market is presented. It is worth
noting that there are different use cases for each application that
define a target platform; hence, there are different types of
communication channels involved (e.g., wired or wireless channels) that
are characterized by different QoS as well as bandwidth; for instance,
wired channels are considerably more free from error than wireless
channels and therefore require different QoS approaches. The target
platform, the channel bandwidth, and the channel quality determine
resolutions, frame rates, and either quality or bitrates for video
streams to be encoded or decoded. By default, color format YCbCr 4:2:0
is assumed for the application scenarios listed
below.[¶](#section-3-1){.pilcrow}

::: {#section-3.1 .section}
### [3.1.](#section-3.1){.section-number .selfRef} [Internet Video Streaming](#name-internet-video-streaming){.section-name .selfRef} {#name-internet-video-streaming}

Typical content for this application is movies, TV series and shows, and
animation. Internet video streaming uses a variety of client devices and
has to operate under changing network conditions. For this reason, an
adaptive streaming model has been widely adopted. Video material is
encoded at different quality levels and different resolutions, which are
then chosen by a client depending on its capabilities and current
network bandwidth. An example combination of resolutions and bitrates is
shown in [Table 1](#vid-stream){.xref}.[¶](#section-3.1-1){.pilcrow}

A video encoding pipeline in on-demand Internet video streaming
typically operates as follows:[¶](#section-3.1-2){.pilcrow}

-   [Video is encoded in the cloud by software
    encoders.[¶](#section-3.1-3.1){.pilcrow}]{#section-3.1-3.1}
-   [Source video is split into chunks, each of which is encoded
    separately, in
    parallel.[¶](#section-3.1-3.2){.pilcrow}]{#section-3.1-3.2}
-   [Closed-GOP encoding with intrapicture intervals of 2-5 seconds (or
    longer) is used.[¶](#section-3.1-3.3){.pilcrow}]{#section-3.1-3.3}
-   [Encoding is perceptually optimized. Perceptual quality is important
    and should be considered during the codec
    development.[¶](#section-3.1-3.4){.pilcrow}]{#section-3.1-3.4}

[]{#name-internet-video-streaming-ty}

::: {#vid-stream}
+-----------------------+-----------------------+-----------------------+
| Resolution \*         | PAM                   | Frame Rate, FPS \*\*  |
+=======================+=======================+=======================+
| 4K, 3840x2160         | RA                    | \                     |
|                       |                       | \                     |
|                       |                       | \                     |
|                       |                       | 24/1.001, 24, 25,\    |
|                       |                       | 30/1.001, 30, 50,\    |
|                       |                       | 60/1.001, 60, 100,\   |
|                       |                       | 120/1.001,            |
|                       |                       | 120[¶](#section-3.1   |
|                       |                       | -4.2.1.3.1){.pilcrow} |
+-----------------------+-----------------------+-----------------------+
| 2K (1080p), 1920x1080 |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 1080i, 1920x1080\*    |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 720p, 1280x720        |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 576p (EDTV), 720x576  |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 576i (SDTV),          |                       | RA                    |
| 720x576\*             |                       |                       |
+-----------------------+-----------------------+-----------------------+
| 480p (EDTV), 720x480  |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 480i (SDTV),          |                       | RA                    |
| 720x480\*             |                       |                       |
+-----------------------+-----------------------+-----------------------+
| 512x384               |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| QVGA, 320x240         |                       | RA                    |
+-----------------------+-----------------------+-----------------------+

: [Table 1](#table-1){.selfRef}: [Internet Video Streaming: Typical
Values of Resolutions, Frame Rates, and
PAMs](#name-internet-video-streaming-ty){.selfRef}
:::

\*Note: Interlaced content can be handled at the higher system level and
not necessarily by using specialized video coding tools. It is included
in this table only for the sake of completeness, as most video content
today is in the progressive format.[¶](#section-3.1-5){.pilcrow}

\*\*Note: The set of frame rates presented in this table is taken from
Table 2 in \[[1](#BT2020-2){.xref}\].[¶](#section-3.1-6){.pilcrow}

The characteristics and requirements of this application scenario are as
follows:[¶](#section-3.1-7){.pilcrow}

-   [High encoder complexity (up to 10x and more) can be tolerated since
    encoding happens once and in parallel for different
    segments.[¶](#section-3.1-8.1){.pilcrow}]{#section-3.1-8.1}

-   [Decoding complexity should be kept at reasonable levels to enable
    efficient decoder
    implementation.[¶](#section-3.1-8.2){.pilcrow}]{#section-3.1-8.2}

-   ::: {#section-3.1-8.3}
    Support and efficient encoding of a wide range of content types and
    formats is required:[¶](#section-3.1-8.3.1){.pilcrow}

    -   [High Dynamic Range (HDR), Wide Color Gamut (WCG),
        high-resolution (currently, up to 4K), and high-frame-rate
        content are important use cases; the codec should be able to
        encode such content
        efficiently.[¶](#section-3.1-8.3.2.1){.pilcrow}]{#section-3.1-8.3.2.1}
    -   [Improvement of coding efficiency at both lower and higher
        resolutions is important since low resolutions are used when
        streaming in low-bandwidth
        conditions.[¶](#section-3.1-8.3.2.2){.pilcrow}]{#section-3.1-8.3.2.2}
    -   [Improvement on both \"easy\" and \"difficult\" content in terms
        of compression efficiency at the same quality level contributes
        to the overall bitrate/storage
        savings.[¶](#section-3.1-8.3.2.3){.pilcrow}]{#section-3.1-8.3.2.3}
    -   [Film grain (and sometimes other types of noise) is often
        present in movies and similar content; this is usually part of
        the creative
        intent.[¶](#section-3.1-8.3.2.4){.pilcrow}]{#section-3.1-8.3.2.4}
    :::

-   [Significant improvements in compression efficiency between
    generations of video standards are desirable since this scenario
    typically assumes long-term support of legacy video
    codecs.[¶](#section-3.1-8.4){.pilcrow}]{#section-3.1-8.4}

-   [Random access points are inserted frequently (one per 2-5 seconds)
    to enable switching between resolutions and fast-forward
    playback.[¶](#section-3.1-8.5){.pilcrow}]{#section-3.1-8.5}

-   [The elementary stream should have a model that allows easy parsing
    and identification of the sample
    components.[¶](#section-3.1-8.6){.pilcrow}]{#section-3.1-8.6}

-   [Middle QP values are normally used in streaming; this is also the
    range where compression efficiency is important for this
    scenario.[¶](#section-3.1-8.7){.pilcrow}]{#section-3.1-8.7}

-   [Scalability or other forms of supporting multiple quality
    representations are beneficial if they do not incur significant
    bitrate overhead and if mandated in the first
    version.[¶](#section-3.1-8.8){.pilcrow}]{#section-3.1-8.8}
:::

::: {#section-3.2 .section}
### [3.2.](#section-3.2){.section-number .selfRef} [Internet Protocol Television (IPTV)](#name-internet-protocol-televisio){.section-name .selfRef} {#name-internet-protocol-televisio}

This is a service for delivering television content over IP-based
networks. IPTV may be classified into two main groups based on the type
of delivery, as follows:[¶](#section-3.2-1){.pilcrow}

-   [unicast (e.g., for video on demand), where delay is not crucial;
    and[¶](#section-3.2-2.1){.pilcrow}]{#section-3.2-2.1}
-   [multicast/broadcast (e.g., for transmitting news) where zapping
    (i.e., stream changing) delay is
    important.[¶](#section-3.2-2.2){.pilcrow}]{#section-3.2-2.2}

In the IPTV scenario, traffic is transmitted over managed (QoS-based)
networks. Typical content used in this application is news, movies,
cartoons, series, TV shows, etc. One important requirement for both
groups is that random access to pictures (i.e., the random access period
(RAP)) should be kept small enough (approximately 1-5 seconds). Optional
requirements are as follows:[¶](#section-3.2-3){.pilcrow}

-   [Temporal (frame-rate) scalability;
    and[¶](#section-3.2-4.1){.pilcrow}]{#section-3.2-4.1}
-   [Resolution and quality (SNR)
    scalability.[¶](#section-3.2-4.2){.pilcrow}]{#section-3.2-4.2}

For this application, typical values of resolutions, frame rates, and
PAMs are presented in [Table
2](#IPTV){.xref}.[¶](#section-3.2-5){.pilcrow}

[]{#name-iptv-typical-values-of-reso}

::: {#IPTV}
+-----------------------+-----------------------+-----------------------+
| Resolution \*         | PAM                   | Frame Rate, FPS \*\*  |
+=======================+=======================+=======================+
| 2160p (4K), 3840x2160 | RA                    | \                     |
|                       |                       | \                     |
|                       |                       | \                     |
|                       |                       | 24/1.001, 24, 25,\    |
|                       |                       | 30/1.001, 30, 50,\    |
|                       |                       | 60/1.001, 60, 100,\   |
|                       |                       | 120/1.001,            |
|                       |                       | 120[¶](#section-3.2   |
|                       |                       | -6.2.1.3.1){.pilcrow} |
+-----------------------+-----------------------+-----------------------+
| 1080p, 1920x1080      |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 1080i, 1920x1080\*    |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 720p, 1280x720        |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 576p (EDTV), 720x576  |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 576i (SDTV),          |                       | RA                    |
| 720x576\*             |                       |                       |
+-----------------------+-----------------------+-----------------------+
| 480p (EDTV), 720x480  |                       | RA                    |
+-----------------------+-----------------------+-----------------------+
| 480i (SDTV),          |                       | RA                    |
| 720x480\*             |                       |                       |
+-----------------------+-----------------------+-----------------------+

: [Table 2](#table-2){.selfRef}: [IPTV: Typical Values of Resolutions,
Frame Rates, and PAMs](#name-iptv-typical-values-of-reso){.selfRef}
:::

\*Note: Interlaced content can be handled at the higher system level and
not necessarily by using specialized video coding tools. It is included
in this table only for the sake of completeness, as most video content
today is in a progressive format.[¶](#section-3.2-7){.pilcrow}

\*\*Note: The set of frame rates presented in this table is taken from
Table 2 in \[[1](#BT2020-2){.xref}\].[¶](#section-3.2-8){.pilcrow}
:::

::: {#section-3.3 .section}
### [3.3.](#section-3.3){.section-number .selfRef} [Video Conferencing](#name-video-conferencing){.section-name .selfRef} {#name-video-conferencing}

This is a form of video connection over the Internet. This form allows
users to establish connections to two or more people by two- way video
and audio transmission for communication in real time. For this
application, both stationary and mobile devices can be used. The main
requirements are as follows:[¶](#section-3.3-1){.pilcrow}

-   [Delay should be kept as low as possible (the preferable and maximum
    end-to-end delay values should be less than 100 ms
    \[[9](#SG-16){.xref}\] and 320 ms \[[2](#G1091){.xref}\],
    respectively);[¶](#section-3.3-2.1){.pilcrow}]{#section-3.3-2.1}
-   [Temporal (frame-rate) scalability;
    and[¶](#section-3.3-2.2){.pilcrow}]{#section-3.3-2.2}
-   [Error robustness.[¶](#section-3.3-2.3){.pilcrow}]{#section-3.3-2.3}

Support of resolution and quality (SNR) scalability is highly desirable.
For this application, typical values of resolutions, frame rates, and
PAMs are presented in [Table
3](#vid-conf){.xref}.[¶](#section-3.3-3){.pilcrow}

[]{#name-video-conferencing-typical-}

::: {#vid-conf}
  Resolution         Frame Rate, FPS   PAM
  ------------------ ----------------- ------
  1080p, 1920x1080   15, 30            FIZD
  720p, 1280x720     30, 60            FIZD
  4CIF, 704x576      30, 60            FIZD
  4SIF, 704x480      30, 60            FIZD
  VGA, 640x480       30, 60            FIZD
  360p, 640x360      30, 60            FIZD

  : [Table 3](#table-3){.selfRef}: [Video Conferencing: Typical Values
  of Resolutions, Frame Rates, and
  PAMs](#name-video-conferencing-typical-){.selfRef}
:::
:::

::: {#section-3.4 .section}
### [3.4.](#section-3.4){.section-number .selfRef} [Video Sharing](#name-video-sharing){.section-name .selfRef} {#name-video-sharing}

This is a service that allows people to upload and share video data
(using live streaming or not) and watch those videos. It is also known
as video hosting. A typical User-Generated Content (UGC) scenario for
this application is to capture video using mobile cameras such as GoPros
or cameras integrated into smartphones (amateur video). The main
requirements are as follows:[¶](#section-3.4-1){.pilcrow}

-   [Random access to pictures for downloaded video
    data;[¶](#section-3.4-2.1){.pilcrow}]{#section-3.4-2.1}
-   [Temporal (frame-rate) scalability;
    and[¶](#section-3.4-2.2){.pilcrow}]{#section-3.4-2.2}
-   [Error robustness.[¶](#section-3.4-2.3){.pilcrow}]{#section-3.4-2.3}

Support of resolution and quality (SNR) scalability is highly desirable.
For this application, typical values of resolutions, frame rates, and
PAMs are presented in [Table
4](#vid-share){.xref}.[¶](#section-3.4-3){.pilcrow}

Typical values of resolutions and frame rates in [Table
4](#vid-share){.xref} are taken from
\[[10](#YOUTUBE){.xref}\].[¶](#section-3.4-4){.pilcrow}

[]{#name-video-sharing-typical-value}

::: {#vid-share}
  Resolution              Frame Rate, FPS          PAM
  ----------------------- ------------------------ -----
  2160p (4K), 3840x2160   24, 25, 30, 48, 50, 60   RA
  1440p (2K), 2560x1440   24, 25, 30, 48, 50, 60   RA
  1080p, 1920x1080        24, 25, 30, 48, 50, 60   RA
  720p, 1280x720          24, 25, 30, 48, 50, 60   RA
  480p, 854x480           24, 25, 30, 48, 50, 60   RA
  360p, 640x360           24, 25, 30, 48, 50, 60   RA

  : [Table 4](#table-4){.selfRef}: [Video Sharing: Typical Values of
  Resolutions, Frame Rates, and
  PAMs](#name-video-sharing-typical-value){.selfRef}
:::
:::

::: {#section-3.5 .section}
### [3.5.](#section-3.5){.section-number .selfRef} [Screencasting](#name-screencasting){.section-name .selfRef} {#name-screencasting}

This is a service that allows users to record and distribute video data
from a computer screen. This service requires efficient compression of
computer-generated content with high visual quality up to visually and
mathematically (numerically) lossless \[[11](#HEVC-EXT){.xref}\].
Currently, this application includes business presentations (PowerPoint,
Word documents, email messages, etc.), animation (cartoons), gaming
content, and data visualization. This type of content is characterized
by fast motion, rotation, smooth shade, 3D effect, highly saturated
colors with full resolution, clear textures and sharp edges with
distinct colors \[[11](#HEVC-EXT){.xref}\], virtual desktop
infrastructure (VDI), screen/desktop sharing and collaboration,
supervisory control and data acquisition (SCADA) display,
automotive/navigation display, cloud gaming, factory automation display,
wireless display, display wall, digital operating room (DiOR), etc. For
this application, an important requirement is the support of low-delay
configurations with zero structural delay for a wide range of video
formats (e.g., RGB) in addition to YCbCr 4:2:0 and YCbCr 4:4:4
\[[11](#HEVC-EXT){.xref}\]. For this application, typical values of
resolutions, frame rates, and PAMs are presented in [Table
5](#screencast){.xref}.[¶](#section-3.5-1){.pilcrow}

[]{#name-screencasting-for-rgb-and-y}

::: {#screencast}
  Resolution                        Frame Rate, FPS   PAM
  --------------------------------- ----------------- --------------
  Input color format: RGB 4:4:4                       
  5k, 5120x2880                     15, 30, 60        AI, RA, FIZD
  4k, 3840x2160                     15, 30, 60        AI, RA, FIZD
  WQXGA, 2560x1600                  15, 30, 60        AI, RA, FIZD
  WUXGA, 1920x1200                  15, 30, 60        AI, RA, FIZD
  WSXGA+, 1680x1050                 15, 30, 60        AI, RA, FIZD
  WXGA, 1280x800                    15, 30, 60        AI, RA, FIZD
  XGA, 1024x768                     15, 30, 60        AI, RA, FIZD
  SVGA, 800x600                     15, 30, 60        AI, RA, FIZD
  VGA, 640x480                      15, 30, 60        AI, RA, FIZD
  Input color format: YCbCr 4:4:4                     
  5k, 5120x2880                     15, 30, 60        AI, RA, FIZD
  4k, 3840x2160                     15, 30, 60        AI, RA, FIZD
  1440p (2K), 2560x1440             15, 30, 60        AI, RA, FIZD
  1080p, 1920x1080                  15, 30, 60        AI, RA, FIZD
  720p, 1280x720                    15, 30, 60        AI, RA, FIZD

  : [Table 5](#table-5){.selfRef}: [Screencasting for RGB and YCbCr
  4:4:4 Format: Typical Values of Resolutions, Frame Rates, and
  PAMs](#name-screencasting-for-rgb-and-y){.selfRef}
:::
:::

::: {#section-3.6 .section}
### [3.6.](#section-3.6){.section-number .selfRef} [Game Streaming](#name-game-streaming){.section-name .selfRef} {#name-game-streaming}

This is a service that provides game content over the Internet to
different local devices such as notebooks and gaming tablets. In this
category of applications, the server renders 3D games in a cloud server
and streams the game to any device with a wired or wireless broadband
connection \[[12](#GAME){.xref}\]. There are low-latency requirements
for transmitting user interactions and receiving game data with a
turnaround delay of less than 100 ms. This allows anyone to play (or
resume) full-featured games from anywhere on the Internet
\[[12](#GAME){.xref}\]. An example of this application is Nvidia Grid
\[[12](#GAME){.xref}\]. Another application scenario of this category is
broadcast of video games played by people over the Internet in real time
or for later viewing \[[12](#GAME){.xref}\]. There are many companies,
such as Twitch and YY in China, that enable game broadcasting
\[[12](#GAME){.xref}\]. Games typically contain a lot of sharp edges and
large motion \[[12](#GAME){.xref}\]. The main requirements are as
follows:[¶](#section-3.6-1){.pilcrow}

-   [Random access to pictures for game
    broadcasting;[¶](#section-3.6-2.1){.pilcrow}]{#section-3.6-2.1}
-   [Temporal (frame-rate) scalability;
    and[¶](#section-3.6-2.2){.pilcrow}]{#section-3.6-2.2}
-   [Error robustness.[¶](#section-3.6-2.3){.pilcrow}]{#section-3.6-2.3}

Support of resolution and quality (SNR) scalability is highly desirable.
For this application, typical values of resolutions, frame rates, and
PAMs are similar to ones presented in [Table
3](#vid-conf){.xref}.[¶](#section-3.6-3){.pilcrow}
:::

::: {#section-3.7 .section}
### [3.7.](#section-3.7){.section-number .selfRef} [Video Monitoring and Surveillance](#name-video-monitoring-and-survei){.section-name .selfRef} {#name-video-monitoring-and-survei}

This is a type of live broadcasting over IP-based networks. Video
streams are sent to many receivers at the same time. A new receiver may
connect to the stream at an arbitrary moment, so the random access
period should be kept small enough (approximately, 1-5 seconds). Data
are transmitted publicly in the case of video monitoring and privately
in the case of video surveillance. For IP cameras that have to capture,
process, and encode video data, complexity \-- including computational
and hardware complexity, as well as memory bandwidth \-- should be kept
low to allow real-time processing. In addition, support of a high
dynamic range and a monochrome mode (e.g., for infrared cameras) as well
as resolution and quality (SNR) scalability is an essential requirement
for video surveillance. In some use cases, high video signal fidelity is
required even after lossy compression. Typical values of resolutions,
frame rates, and PAMs for video monitoring and surveillance applications
are presented in [Table
6](#monitoring){.xref}.[¶](#section-3.7-1){.pilcrow}

[]{#name-video-monitoring-and-surveil}

::: {#monitoring}
  Resolution              Frame Rate, FPS   PAM
  ----------------------- ----------------- ----------
  2160p (4K), 3840x2160   12, 25, 30        RA, FIZD
  5Mpixels, 2560x1920     12, 25, 30        RA, FIZD
  1080p, 1920x1080        25, 30            RA, FIZD
  1.23Mpixels, 1280x960   25, 30            RA, FIZD
  720p, 1280x720          25, 30            RA, FIZD
  SVGA, 800x600           25, 30            RA, FIZD

  : [Table 6](#table-6){.selfRef}: [Video Monitoring and Surveillance:
  Typical Values of Resolutions, Frame Rates, and
  PAMs](#name-video-monitoring-and-surveil){.selfRef}
:::
:::
:::
:::

::: {#section-4 .section}
## [4.](#section-4){.section-number .selfRef} [Requirements](#name-requirements){.section-name .selfRef} {#name-requirements}

Taking the requirements discussed above for specific video applications,
this section proposes requirements for an Internet video
codec.[¶](#section-4-1){.pilcrow}

::: {#gen-reqs}
::: {#section-4.1 .section}
### [4.1.](#section-4.1){.section-number .selfRef} [General Requirements](#name-general-requirements){.section-name .selfRef} {#name-general-requirements}

::: {#efficiency}
::: {#section-4.1.1 .section}
#### [4.1.1.](#section-4.1.1){.section-number .selfRef} [Coding Efficiency](#name-coding-efficiency){.section-name .selfRef} {#name-coding-efficiency}

The most fundamental requirement is coding efficiency, i.e., compression
performance on both \"easy\" and \"difficult\" content for applications
and use cases in [Section 3](#apps){.xref}. The codec should provide
higher coding efficiency over state-of-the-art video codecs such as
HEVC/H.265 and VP9, at least 25%, in accordance with the methodology
described in [Section 5](#eval-method){.xref} of this document. For
higher resolutions, the improvements in coding efficiency are expected
to be higher than for lower resolutions.[¶](#section-4.1.1-1){.pilcrow}
:::
:::

::: {#profiles}
::: {#section-4.1.2 .section}
#### [4.1.2.](#section-4.1.2){.section-number .selfRef} [Profiles and Levels](#name-profiles-and-levels){.section-name .selfRef} {#name-profiles-and-levels}

Good-quality specification and well-defined profiles and levels are
required to enable device interoperability and facilitate decoder
implementations. A profile consists of a subset of entire bitstream
syntax elements; consequently, it also defines the necessary tools for
decoding a conforming bitstream of that profile. A level imposes a set
of numerical limits to the values of some syntax elements. An example of
codec levels to be supported is presented in [Table
7](#codec-levels){.xref}. An actual level definition should include
constraints on features that impact the decoder complexity. For example,
these features might be as follows: maximum bitrate, line buffer size,
memory usage, etc.[¶](#section-4.1.2-1){.pilcrow}

[]{#name-codec-levels}

::: {#codec-levels}
+-----------------------------------+-----------------------------------+
| Level                             | Example picture resolution at     |
|                                   | highest frame rate                |
+===================================+===================================+
| 1                                 | 128x96(12,288\*)\@30.0\           |
|                                   | 176x144(25,344\*)\@15.0[¶](#s     |
|                                   | ection-4.1.2-2.2.1.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 2                                 | 352x288(101,376\*)\@30.0          |
+-----------------------------------+-----------------------------------+
| 3                                 | 352x288(101,376\*)\@60.0\         |
|                                   | 640x360(230,400\*)\@30.0[¶](#s    |
|                                   | ection-4.1.2-2.2.3.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 4                                 | 640x360(230,400\*)\@60.0\         |
|                                   | 960x540(518,400\*)\@30.0[¶](#s    |
|                                   | ection-4.1.2-2.2.4.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 5                                 | 720x576(414,720\*)\@75.0\         |
|                                   | 960x540(518,400\*)\@60.0\         |
|                                   | 1280x720(921,600\*)\@30.0[¶](#s   |
|                                   | ection-4.1.2-2.2.5.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 6                                 | 1,280x720(921,600\*)\@68.0\       |
|                                   | 2,0                               |
|                                   | 48x1,080(2,211,840\*)\@30.0[¶](#s |
|                                   | ection-4.1.2-2.2.6.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 7                                 | 1,280x720(921,600\*)\@120.0       |
+-----------------------------------+-----------------------------------+
| 8                                 | 1,920x1,080(2,073,600\*)\@120.0\  |
|                                   | 3,840x2,160(8,294,400\*)\@30.0\   |
|                                   | 4,0                               |
|                                   | 96x2,160(8,847,360\*)\@30.0[¶](#s |
|                                   | ection-4.1.2-2.2.8.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 9                                 | 1,920x1,080(2,073,600\*)\@250.0\  |
|                                   | 4,0                               |
|                                   | 96x2,160(8,847,360\*)\@60.0[¶](#s |
|                                   | ection-4.1.2-2.2.9.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 10                                | 1,920x1,080(2,073,600\*)\@300.0\  |
|                                   | 4,096                             |
|                                   | x2,160(8,847,360\*)\@120.0[¶](#se |
|                                   | ction-4.1.2-2.2.10.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 11                                | 3,840x2,160(8,294,400\*)\@120.0\  |
|                                   | 8,192                             |
|                                   | x4,320(35,389,440\*)\@30.0[¶](#se |
|                                   | ction-4.1.2-2.2.11.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 12                                | 3,840x2,160(8,294,400\*)\@250.0\  |
|                                   | 8,192                             |
|                                   | x4,320(35,389,440\*)\@60.0[¶](#se |
|                                   | ction-4.1.2-2.2.12.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| 13                                | 3,840x2,160(8,294,400\*)\@300.0\  |
|                                   | 8,192x                            |
|                                   | 4,320(35,389,440\*)\@120.0[¶](#se |
|                                   | ction-4.1.2-2.2.13.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+

: [Table 7](#table-7){.selfRef}: [Codec
Levels](#name-codec-levels){.selfRef}
:::

\*Note: The quantities of pixels are presented for applications in which
a picture can have an arbitrary size (e.g.,
screencasting).[¶](#section-4.1.2-3){.pilcrow}
:::
:::

::: {#syntax}
::: {#section-4.1.3 .section}
#### [4.1.3.](#section-4.1.3){.section-number .selfRef} [Bitstream Syntax](#name-bitstream-syntax){.section-name .selfRef} {#name-bitstream-syntax}

Bitstream syntax should allow extensibility and backward compatibility.
New features can be supported easily by using metadata (such as SEI
messages, VUI, and headers) without affecting the bitstream
compatibility with legacy decoders. A newer version of the decoder shall
be able to play bitstreams of an older version of the same or lower
profile and level.[¶](#section-4.1.3-1){.pilcrow}
:::
:::

::: {#model}
::: {#section-4.1.4 .section}
#### [4.1.4.](#section-4.1.4){.section-number .selfRef} [Parsing and Identification of Sample Components](#name-parsing-and-identification-){.section-name .selfRef} {#name-parsing-and-identification-}

A bitstream should have a model that allows easy parsing and
identification of the sample components (such as Annex B of ISO/IEC
14496-10 \[[18](#ISO14496-10){.xref}\] or ISO/IEC 14496-15
\[[19](#ISO14496-15){.xref}\]). In particular, information needed for
packet handling (e.g., frame type) should not require parsing anything
below the header level.[¶](#section-4.1.4-1){.pilcrow}
:::
:::

::: {#tools}
::: {#section-4.1.5 .section}
#### [4.1.5.](#section-4.1.5){.section-number .selfRef} [Perceptual Quality Tools](#name-perceptual-quality-tools){.section-name .selfRef} {#name-perceptual-quality-tools}

Perceptual quality tools (such as adaptive QP and quantization matrices)
should be supported by the codec
bitstream.[¶](#section-4.1.5-1){.pilcrow}
:::
:::

::: {#buffer}
::: {#section-4.1.6 .section}
#### [4.1.6.](#section-4.1.6){.section-number .selfRef} [Buffer Model](#name-buffer-model){.section-name .selfRef} {#name-buffer-model}

The codec specification shall define a buffer model such as hypothetical
reference decoder (HRD).[¶](#section-4.1.6-1){.pilcrow}
:::
:::

::: {#integration}
::: {#section-4.1.7 .section}
#### [4.1.7.](#section-4.1.7){.section-number .selfRef} [Integration](#name-integration){.section-name .selfRef} {#name-integration}

Specifications providing integration with system and delivery layers
should be developed.[¶](#section-4.1.7-1){.pilcrow}
:::
:::
:::
:::

::: {#section-4.2 .section}
### [4.2.](#section-4.2){.section-number .selfRef} [Basic Requirements](#name-basic-requirements){.section-name .selfRef} {#name-basic-requirements}

::: {#section-4.2.1 .section}
#### [4.2.1.](#section-4.2.1){.section-number .selfRef} [Input Source Formats](#name-input-source-formats){.section-name .selfRef} {#name-input-source-formats}

Input pictures coded by a video codec should have one of the following
formats:[¶](#section-4.2.1-1){.pilcrow}

-   [Bit depth: 8 and 10 bits (up to 12 bits for a high profile) per
    color
    component.[¶](#section-4.2.1-2.1){.pilcrow}]{#section-4.2.1-2.1}

-   ::: {#section-4.2.1-2.2}
    Color sampling formats:[¶](#section-4.2.1-2.2.1){.pilcrow}

    -   [YCbCr
        4:2:0[¶](#section-4.2.1-2.2.2.1){.pilcrow}]{#section-4.2.1-2.2.2.1}
    -   [YCbCr 4:4:4, YCbCr 4:2:2, and YCbCr 4:0:0 (preferably in
        different
        profile(s))[¶](#section-4.2.1-2.2.2.2){.pilcrow}]{#section-4.2.1-2.2.2.2}
    :::

-   [For profiles with bit depth of 10 bits per sample or higher,
    support of high dynamic range and wide color
    gamut.[¶](#section-4.2.1-2.3){.pilcrow}]{#section-4.2.1-2.3}

-   [Support of arbitrary resolution according to the level constraints
    for applications in which a picture can have an arbitrary size
    (e.g., in
    screencasting).[¶](#section-4.2.1-2.4){.pilcrow}]{#section-4.2.1-2.4}

Exemplary input source formats for codec profiles are shown in [Table
8](#exemplary){.xref}.[¶](#section-4.2.1-3){.pilcrow}

[]{#name-exemplary-input-source-form}

::: {#exemplary}
  Profile   Bit depths per color component   Color sampling formats
  --------- -------------------------------- --------------------------------
  1         8 and 10                         4:0:0 and 4:2:0
  2         8 and 10                         4:0:0, 4:2:0, and 4:4:4
  3         8, 10, and 12                    4:0:0, 4:2:0, 4:2:2, and 4:4:4

  : [Table 8](#table-8){.selfRef}: [Exemplary Input Source Formats for
  Codec Profiles](#name-exemplary-input-source-form){.selfRef}
:::
:::

::: {#section-4.2.2 .section}
#### [4.2.2.](#section-4.2.2){.section-number .selfRef} [Coding Delay](#name-coding-delay){.section-name .selfRef} {#name-coding-delay}

In order to meet coding delay requirements, a video codec should support
all of the following:[¶](#section-4.2.2-1){.pilcrow}

-   ::: {#section-4.2.2-2.1}
    Support of configurations with zero structural delay, also referred
    to as \"low-delay\"
    configurations.[¶](#section-4.2.2-2.1.1){.pilcrow}

    -   [Note: End-to-end delay should be no more than 320 ms
        \[[2](#G1091){.xref}\], but it is preferable for its value to be
        less than 100 ms
        \[[9](#SG-16){.xref}\].[¶](#section-4.2.2-2.1.2.1){.pilcrow}]{#section-4.2.2-2.1.2.1}
    :::

-   [Support of efficient random access point encoding (such as
    intracoding and resetting of context variables), as well as
    efficient switching between multiple quality
    representations.[¶](#section-4.2.2-2.2){.pilcrow}]{#section-4.2.2-2.2}

-   [Support of configurations with nonzero structural delay (such as
    out-of-order or multipass encoding) for applications without
    low-delay requirements, if such configurations provide additional
    compression efficiency
    improvements.[¶](#section-4.2.2-2.3){.pilcrow}]{#section-4.2.2-2.3}
:::

::: {#section-4.2.3 .section}
#### [4.2.3.](#section-4.2.3){.section-number .selfRef} [Complexity](#name-complexity){.section-name .selfRef} {#name-complexity}

Encoding and decoding complexity considerations are as
follows:[¶](#section-4.2.3-1){.pilcrow}

-   [Feasible real-time implementation of both an encoder and a decoder
    supporting a chosen subset of tools for hardware and software
    implementation on a wide range of state-of-the-art platforms. The
    subset of real-time encoder tools should provide meaningful
    improvement in compression efficiency at reasonable complexity of
    hardware and software encoder implementations as compared to
    real-time implementations of state-of-the-art video compression
    technologies such as HEVC/H.265 and
    VP9.[¶](#section-4.2.3-2.1){.pilcrow}]{#section-4.2.3-2.1}
-   [High-complexity software encoder implementations used by offline
    encoding applications can have a 10x or more complexity increase
    compared to state-of-the-art video compression technologies such as
    HEVC/H.265 and
    VP9.[¶](#section-4.2.3-2.2){.pilcrow}]{#section-4.2.3-2.2}
:::

::: {#section-4.2.4 .section}
#### [4.2.4.](#section-4.2.4){.section-number .selfRef} [Scalability](#name-scalability){.section-name .selfRef} {#name-scalability}

The mandatory scalability requirement is as
follows:[¶](#section-4.2.4-1){.pilcrow}

-   [Temporal (frame-rate) scalability should be
    supported.[¶](#section-4.2.4-2.1){.pilcrow}]{#section-4.2.4-2.1}
:::

::: {#section-4.2.5 .section}
#### [4.2.5.](#section-4.2.5){.section-number .selfRef} [Error Resilience](#name-error-resilience){.section-name .selfRef} {#name-error-resilience}

In order to meet the error resilience requirement, a video codec should
satisfy all of the following conditions:[¶](#section-4.2.5-1){.pilcrow}

-   [Tools that are complementary to the error-protection mechanisms
    implemented on the transport level should be
    supported.[¶](#section-4.2.5-2.1){.pilcrow}]{#section-4.2.5-2.1}
-   [The codec should support mechanisms that facilitate packetization
    of a bitstream for common network
    protocols.[¶](#section-4.2.5-2.2){.pilcrow}]{#section-4.2.5-2.2}
-   [Packetization mechanisms should enable frame-level error recovery
    by means of retransmission or error
    concealment.[¶](#section-4.2.5-2.3){.pilcrow}]{#section-4.2.5-2.3}
-   [The codec should support effective mechanisms for allowing decoding
    and reconstruction of significant parts of pictures in the event
    that parts of the picture data are lost in
    transmission.[¶](#section-4.2.5-2.4){.pilcrow}]{#section-4.2.5-2.4}
-   [The bitstream specification shall support independently decodable
    subframe units similar to slices or independent tiles. It shall be
    possible for the encoder to restrict the bitstream to allow parsing
    of the bitstream after a packet loss and to communicate it to the
    decoder.[¶](#section-4.2.5-2.5){.pilcrow}]{#section-4.2.5-2.5}
:::
:::

::: {#section-4.3 .section}
### [4.3.](#section-4.3){.section-number .selfRef} [Optional Requirements](#name-optional-requirements){.section-name .selfRef} {#name-optional-requirements}

::: {#section-4.3.1 .section}
#### [4.3.1.](#section-4.3.1){.section-number .selfRef} [Input Source Formats](#name-input-source-formats-2){.section-name .selfRef} {#name-input-source-formats-2}

It is a desired but not mandatory requirement for a video codec to
support some of the following features:[¶](#section-4.3.1-1){.pilcrow}

-   [Bit depth: up to 16 bits per color
    component.[¶](#section-4.3.1-2.1){.pilcrow}]{#section-4.3.1-2.1}
-   [Color sampling formats: RGB
    4:4:4.[¶](#section-4.3.1-2.2){.pilcrow}]{#section-4.3.1-2.2}
-   [Auxiliary channel (e.g., alpha channel)
    support.[¶](#section-4.3.1-2.3){.pilcrow}]{#section-4.3.1-2.3}
:::

::: {#section-4.3.2 .section}
#### [4.3.2.](#section-4.3.2){.section-number .selfRef} [Scalability](#name-scalability-2){.section-name .selfRef} {#name-scalability-2}

Desirable scalability requirements are as
follows:[¶](#section-4.3.2-1){.pilcrow}

-   [Resolution and quality (SNR) scalability that provides a
    low-compression efficiency penalty (increase of up to 5% of BD-rate
    \[[13](#PSNR){.xref}\] per layer with reasonable increase of both
    computational and hardware complexity) can be supported in the main
    profile of the codec being developed by the NETVC Working Group.
    Otherwise, a separate profile is needed to support these types of
    scalability.[¶](#section-4.3.2-2.1){.pilcrow}]{#section-4.3.2-2.1}
-   [Computational complexity scalability (i.e., computational
    complexity is decreasing along with degrading picture quality) is
    desirable.[¶](#section-4.3.2-2.2){.pilcrow}]{#section-4.3.2-2.2}
:::

::: {#section-4.3.3 .section}
#### [4.3.3.](#section-4.3.3){.section-number .selfRef} [Complexity](#name-complexity-2){.section-name .selfRef} {#name-complexity-2}

Tools that enable parallel processing (e.g., slices, tiles, and
wave-front propagation processing) at both encoder and decoder sides are
highly desirable for many applications.[¶](#section-4.3.3-1){.pilcrow}

-   [High-level multicore parallelism: encoder and decoder operation,
    especially entropy encoding and decoding, should allow multiple
    frames or subframe regions (e.g., 1D slices, 2D tiles, or
    partitions) to be processed concurrently, either independently or
    with deterministic dependencies that can be efficiently
    pipelined.[¶](#section-4.3.3-2.1){.pilcrow}]{#section-4.3.3-2.1}
-   [Low-level instruction-set parallelism: favor algorithms that are
    SIMD/GPU friendly over inherently serial
    algorithms[¶](#section-4.3.3-2.2){.pilcrow}]{#section-4.3.3-2.2}
:::

::: {#section-4.3.4 .section}
#### [4.3.4.](#section-4.3.4){.section-number .selfRef} [Coding Efficiency](#name-coding-efficiency-2){.section-name .selfRef} {#name-coding-efficiency-2}

Compression efficiency on noisy content, content with film grain,
computer generated content, and low resolution materials is
desirable.[¶](#section-4.3.4-1){.pilcrow}
:::
:::
:::

::: {#eval-method}
::: {#section-5 .section}
## [5.](#section-5){.section-number .selfRef} [Evaluation Methodology](#name-evaluation-methodology){.section-name .selfRef} {#name-evaluation-methodology}

As shown in [Figure 1](#QP){.xref}, compression performance testing is
performed in three overlapped ranges that encompass ten different
bitrate values:[¶](#section-5-1){.pilcrow}

-   [Low bitrate range (LBR) is the range that contains the four lowest
    bitrates of the ten specified bitrates (one of the four bitrate
    values is shared with the neighboring
    range).[¶](#section-5-2.1){.pilcrow}]{#section-5-2.1}
-   [Medium bitrate range (MBR) is the range that contains the four
    medium bitrates of the ten specified bitrates (two of the four
    bitrate values are shared with the neighboring
    ranges).[¶](#section-5-2.2){.pilcrow}]{#section-5-2.2}
-   [High bitrate range (HBR) is the range that contains the four
    highest bitrates of the ten specified bitrates (one of the four
    bitrate values is shared with the neighboring
    range).[¶](#section-5-2.3){.pilcrow}]{#section-5-2.3}

Initially, for the codec selected as a reference one (e.g., HEVC or
VP9), a set of ten QP (quantization parameter) values should be
specified as in \[[14](#I-D.ietf-netvc-testing){.xref}\], and
corresponding quality values should be calculated. In [Figure
1](#QP){.xref}, QP and quality values are denoted as \"QP0\"-\"QP9\" and
\"Q0\"-\"Q9\", respectively. To guarantee the overlaps of quality levels
between the bitrate ranges of the reference and tested codecs, a quality
alignment procedure should be performed for each range\'s outermost
(left- and rightmost) quality levels Qk of the reference codec (i.e.,
for Q0, Q3, Q6, and Q9) and the quality levels Q\'k (i.e., Q\'0, Q\'3,
Q\'6, and Q\'9) of the tested codec. Thus, these quality levels Q\'k,
and hence the corresponding QP value QP\'k (i.e., QP\'0, QP\'3, QP\'6,
and QP\'9), of the tested codec should be selected using the following
formulas:[¶](#section-5-3){.pilcrow}

::: {#section-5-4 .artwork .art-text .alignLeft}
    Q'k =   min { abs(Q'i - Qk) },
          i in R

    QP'k = argmin { abs(Q'i(QP'i) - Qk(QPk)) },
           i in R

[¶](#section-5-4){.pilcrow}
:::

where R is the range of the QP indexes of the tested codec, i.e., the
candidate Internet video codec. The inner quality levels (i.e., Q\'1,
Q\'2, Q\'4, Q\'5, Q\'7, and Q\'8), as well as their corresponding QP
values of each range (i.e., QP\'1, QP\'2, QP\'4, QP\'5, QP\'7, and
QP\'8), should be as equidistantly spaced as possible between the left-
and rightmost quality levels without explicitly mapping their values
using the procedure described above.[¶](#section-5-5){.pilcrow}

[]{#name-quality-qp-alignment-for-co}

::: {#QP}
::: {#section-5-6.1 .artwork .art-text .alignLeft}
    QP'9 QP'8  QP'7 QP'6 QP'5 QP'4 QP'3 QP'2 QP'1 QP'0 <+-----
     ^     ^    ^    ^    ^    ^    ^    ^    ^    ^    | Tested
     |     |    |    |    |    |    |    |    |    |    | codec
    Q'0   Q'1  Q'2  Q'3  Q'4  Q'5  Q'6  Q'7  Q'8  Q'9  <+-----
     ^               ^              ^              ^
     |               |              |              |
    Q0    Q1    Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  <+-----
     ^    ^     ^    ^    ^    ^    ^    ^    ^    ^    | Reference
     |    |     |    |    |    |    |    |    |    |    | codec
    QP9  QP8   QP7  QP6  QP5  QP4  QP3  QP2  QP1  QP0  <+-----
    +----------------+--------------+--------------+--------->
    ^                ^              ^              ^     Bitrate
    |-------LBR------|              |-----HBR------|
                     ^              ^
                     |------MBR-----|
:::

[Figure 1](#figure-1){.selfRef}: [Quality/QP Alignment for Compression
Performance Evaluation](#name-quality-qp-alignment-for-co){.selfRef}
:::

Since the QP mapping results may vary for different sequences, this
quality alignment procedure eventually needs to be performed separately
for each quality assessment index and each sequence used for codec
performance evaluation to fulfill the requirements described
above.[¶](#section-5-7){.pilcrow}

To assess the quality of output (decoded) sequences, two indexes (PSNR
\[[3](#ISO29170-1){.xref}\] and MS-SSIM \[[3](#ISO29170-1){.xref}\]
\[[15](#MULTI-SCALE){.xref}\]) are separately computed. In the case of
the YCbCr color format, PSNR should be calculated for each color plane,
whereas MS-SSIM is calculated for the luma channel only. In the case of
the RGB color format, both metrics are computed for R, G, and B
channels. Thus, for each sequence, 30 RD-points for PSNR (i.e., three
RD-curves, one for each channel) and 10 RD-points for MS-SSIM (i.e., one
RD-curve, for luma channel only) should be calculated in the case of
YCbCr. If content is encoded as RGB, 60 RD-points (30 for PSNR and 30
for MS-SSIM) should be calculated (i.e., three RD-curves, one for each
channel) are computed for PSNR as well as three RD-curves (one for each
channel) for MS-SSIM.[¶](#section-5-8){.pilcrow}

Finally, to obtain an integral estimation, BD-rate savings
\[[13](#PSNR){.xref}\] should be computed for each range and each
quality index. In addition, average values over all three ranges should
be provided for both PSNR and MS-SSIM. A list of video sequences that
should be used for testing, as well as the ten QP values for the
reference codec, are defined in
\[[14](#I-D.ietf-netvc-testing){.xref}\]. Testing processes should use
the information on the codec applications presented in this document. As
the reference for evaluation, state-of-the-art video codecs such as
HEVC/H.265 \[[4](#ISO23008-2){.xref}\]\[[5](#H265){.xref}\] or VP9 must
be used. The reference source code of the HEVC/H.265 codec can be found
at \[[6](#HEVC){.xref}\]. The HEVC/H.265 codec must be configured
according to \[[16](#CONDITIONS){.xref}\] and [Table
9](#intra-period){.xref}.[¶](#section-5-9){.pilcrow}

[]{#name-intraperiods-for-different-}

::: {#intra-period}
+-----------------------------------+-----------------------------------+
| Intra-period, second              | HEVC/H.265 encoding mode          |
|                                   | according to                      |
|                                   | \[[16](#CONDITIONS){.xref}\]      |
+===================================+===================================+
| AI                                | Intra Main or Intra Main10        |
+-----------------------------------+-----------------------------------+
| RA                                | Random access Main or\            |
|                                   | Random access                     |
|                                   | Main10[¶]                         |
|                                   | (#section-5-10.2.2.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+
| FIZD                              | Low delay Main or\                |
|                                   | Low delay                         |
|                                   | Main10[¶]                         |
|                                   | (#section-5-10.2.3.2.1){.pilcrow} |
+-----------------------------------+-----------------------------------+

: [Table 9](#table-9){.selfRef}: [Intraperiods for Different HEVC/H.265
Encoding Modes According to
\[16\]](#name-intraperiods-for-different-){.selfRef}
:::

According to the coding efficiency requirement described in [Section
4.1.1](#efficiency){.xref}, BD-rate savings calculated for each color
plane and averaged for all the video sequences used to test the NETVC
codec should be, at least,[¶](#section-5-11){.pilcrow}

-   [25% if calculated over the whole bitrate range;
    and[¶](#section-5-12.1){.pilcrow}]{#section-5-12.1}
-   [15% if calculated for each bitrate subrange (LBR, MBR,
    HBR).[¶](#section-5-12.2){.pilcrow}]{#section-5-12.2}

Since values of the two objective metrics (PSNR and MS-SSIM) are
available for some color planes, each value should meet these coding
efficiency requirements. That is, the final BD-rate saving denoted as S
is calculated for a given color plane as
follows:[¶](#section-5-13){.pilcrow}

::: {#section-5-14 .artwork .art-text .alignLeft}
    S = min { S_psnr, S_ms-ssim }

[¶](#section-5-14){.pilcrow}
:::

where S_psnr and S_ms-ssim are BD-rate savings calculated for the given
color plane using PSNR and MS-SSIM metrics,
respectively.[¶](#section-5-15){.pilcrow}

In addition to the objective quality measures defined above, subjective
evaluation must also be performed for the final NETVC codec adoption.
For subjective tests, the MOS-based evaluation procedure must be used as
described in Section 2.1 of \[[3](#ISO29170-1){.xref}\]. For
perception-oriented tools that primarily impact subjective quality,
additional tests may also be individually assigned even for intermediate
evaluation, subject to a decision of the NETVC
WG.[¶](#section-5-16){.pilcrow}
:::
:::

::: {#section-6 .section}
## [6.](#section-6){.section-number .selfRef} [Security Considerations](#name-security-considerations){.section-name .selfRef} {#name-security-considerations}

This document itself does not address any security considerations.
However, it is worth noting that a codec implementation (for both an
encoder and a decoder) should take into consideration the worst-case
computational complexity, memory bandwidth, and physical memory size
needed to process the potentially untrusted input (e.g., the decoded
pictures used as references).[¶](#section-6-1){.pilcrow}
:::

::: {#section-7 .section}
## [7.](#section-7){.section-number .selfRef} [IANA Considerations](#name-iana-considerations){.section-name .selfRef} {#name-iana-considerations}

This document has no IANA actions.[¶](#section-7-1){.pilcrow}
:::

::: {#section-8 .section}
## [8.](#section-8){.section-number .selfRef} [References](#name-references){.section-name .selfRef} {#name-references}

::: {#section-8.1 .section}
### [8.1.](#section-8.1){.section-number .selfRef} [Normative References](#name-normative-references){.section-name .selfRef} {#name-normative-references}

\[1\]
:   [ITU-R]{.refAuthor}, [\"Parameter values for ultra-high definition
    television systems for production and international programme
    exchange\"]{.refTitle}, [ITU-R Recommendation
    BT.2020-2]{.seriesInfo}, October 2015,
    \<<https://www.itu.int/rec/R-REC-BT.2020-2-201510-I/en>\>.
:   

\[2\]
:   [ITU-T]{.refAuthor}, [\"Quality of Experience requirements for
    telepresence services\"]{.refTitle}, [ITU-T Recommendation
    G.1091]{.seriesInfo}, October 2014,
    \<<https://www.itu.int/rec/T-REC-G.1091/en>\>.
:   

\[3\]
:   [ISO]{.refAuthor}, [\"Information technology \-- Advanced image
    coding and evaluation \-- Part 1: Guidelines for image coding system
    evaluation\"]{.refTitle}, [ISO/IEC TR 29170-1:2017]{.seriesInfo},
    October 2017, \<<https://www.iso.org/standard/63637.html>\>.
:   

\[4\]
:   [ISO]{.refAuthor}, [\"Information technology \-- High efficiency
    coding and media delivery in heterogeneous environments \-- Part 2:
    High efficiency video coding\"]{.refTitle}, [ISO/IEC
    23008-2:2015]{.seriesInfo}, May 2018,
    \<<https://www.iso.org/standard/67660.html>\>.
:   

\[5\]
:   [ITU-T]{.refAuthor}, [\"High efficiency video coding\"]{.refTitle},
    [ITU-T Recommendation H.265]{.seriesInfo}, November 2019,
    \<<https://www.itu.int/rec/T-REC-H.265>\>.
:   

\[6\]
:   [Fraunhofer Institute for Telecommunications]{.refAuthor}, [\"High
    Efficiency Video Coding (HEVC) reference software (HEVC Test Model
    also known as HM)\"]{.refTitle},
    \<<https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/>\>.
:   
:::

::: {#section-8.2 .section}
### [8.2.](#section-8.2){.section-number .selfRef} [Informative References](#name-informative-references){.section-name .selfRef} {#name-informative-references}

\[7\]
:   [Federal Agencies Digital Guidelines Initiative]{.refAuthor},
    [\"Term: High dynamic range imaging\"]{.refTitle},
    \<<http://www.digitizationguidelines.gov/term.php?term=highdynamicrangeimaging>\>.
:   

\[8\]
:   [Federal Agencies Digital Guidelines Initiative]{.refAuthor},
    [\"Term: Compression, visually lossless\"]{.refTitle},
    \<<http://www.digitizationguidelines.gov/term.php?term=compressionvisuallylossless>\>.
:   

\[9\]
:   [Wenger, S.]{.refAuthor}, [\"The case for scalability support in
    version 1 of Future Video Coding\"]{.refTitle}, [SG 16 (Study
    Period 2013) Contribution 988]{.seriesInfo}, September 2015,
    \<<https://www.itu.int/md/T13-SG16-C-0988/en>\>.
:   

\[10\]
:   [YouTube]{.refAuthor}, [\"Recommended upload encoding
    settings\"]{.refTitle},
    \<<https://support.google.com/youtube/answer/1722171?hl=en>\>.
:   

\[11\]
:   [Yu, H., Ed.]{.refAuthor}[, McCann, K., Ed.]{.refAuthor}[, Cohen,
    R., Ed.]{.refAuthor}[, and P. Amon, Ed.]{.refAuthor},
    [\"Requirements for an extension of HEVC for coding of screen
    content\"]{.refTitle}, [ISO/IEC JTC 1/SC 29/WG 11 Moving Picture
    Experts Group MPEG2013/N14174]{.seriesInfo}, [San Jose,
    USA]{.seriesInfo}, January 2014,
    \<<https://mpeg.chiariglione.org/standards/mpeg-h/high-efficiency-video-coding/requirements-extension-hevc-coding-screen-content>\>.
:   

\[12\]
:   [Parhy, M.]{.refAuthor}, [\"Game streaming requirement for Future
    Video Coding\"]{.refTitle}, [ISO/IEC JTC 1/SC 29/WG 11 Moving
    Picture Experts Group N36771]{.seriesInfo}, [Warsaw,
    Poland]{.seriesInfo}, June 2015.
:   

\[13\]
:   [Bjontegaard, G.]{.refAuthor}, [\"Calculation of average PSNR
    differences between RD-curves\"]{.refTitle}, [SG 16
    VCEG-M33]{.seriesInfo}, April 2001,
    \<<https://www.itu.int/wftp3/av-arch/video-site/0104_Aus/>\>.
:   

\[14\]
:   [Daede, T.]{.refAuthor}[, Norkin, A.]{.refAuthor}[, and I.
    Brailovskiy]{.refAuthor}, [\"Video Codec Testing and Quality
    Measurement\"]{.refTitle}, [Work in Progress]{.refContent},
    [Internet-Draft, draft-ietf-netvc-testing-09]{.seriesInfo}, 31
    January 2020,
    \<<https://tools.ietf.org/html/draft-ietf-netvc-testing-09>\>.
:   

\[15\]
:   [Wang, Z.]{.refAuthor}[, Simoncelli, E.P.]{.refAuthor}[, and A.C.
    Bovik]{.refAuthor}, [\"Multiscale structural similarity for image
    quality assessment\"]{.refTitle}, [IEEE Thirty-Seventh Asilomar
    Conference on Signals, Systems and Computers]{.seriesInfo}, [DOI
    10.1109/ACSSC.2003.1292216]{.seriesInfo}, November 2003,
    \<<https://ieeexplore.ieee.org/document/1292216>\>.
:   

\[16\]
:   [Bossen, F.]{.refAuthor}, [\"Common HM test conditions and software
    reference configurations\"]{.refTitle}, [Joint Collaborative Team on
    Video Coding (JCT-VC) of the ITU-T Video Coding Experts Group (ITU-T
    Q.6/SG 16) and ISO/IEC Moving Picture Experts Group (ISO/IEC JTC
    1/SC 29/WG 11) ]{.seriesInfo}, [Document JCTVC-L1100]{.seriesInfo},
    April 2013,
    \<<http://phenix.it-sudparis.eu/jct/doc_end_user/current_document.php?id=7281>\>.
:   

\[17\]
:   [ITU-R]{.refAuthor}, [\"Studio encoding parameters of digital
    television for standard 4:3 and wide screen 16:9 aspect
    ratios\"]{.refTitle}, [ITU-R Recommendation BT.601]{.seriesInfo},
    March 2011, \<<https://www.itu.int/rec/R-REC-BT.601/>\>.
:   

\[18\]
:   [ISO/IEC]{.refAuthor}, [\"Information technology \-- Coding of
    audio-visual objects \-- Part 10: Advanced video
    coding\"]{.refTitle}, [ISO/IEC DIS 14496-10]{.seriesInfo},
    \<<https://www.iso.org/standard/75400.html>\>.
:   

\[19\]
:   [ISO/IEC]{.refAuthor}, [\"Information technology \-- Coding of
    audio-visual objects \-- Part 15: Carriage of network abstraction
    layer (NAL) unit structured video in the ISO base media file
    format\"]{.refTitle}, [ISO/IEC 14496-15]{.seriesInfo},
    \<<https://www.iso.org/standard/74429.html>\>.
:   

\[20\]
:   [ITU-R]{.refAuthor}, [\"Parameter values for the HDTV standards for
    production and international programme exchange\"]{.refTitle},
    [ITU-R Recommendation BT.709]{.seriesInfo}, June 2015,
    \<<https://www.itu.int/rec/R-REC-BT.709>\>.
:   
:::
:::

::: {#sect-8}
::: {#section-appendix.a .section}
## [Acknowledgments](#name-acknowledgments){.section-name .selfRef} {#name-acknowledgments}

The authors would like to thank [Mr. Paul Coverdale]{.contact-name},
[Mr. Vasily Rufitskiy]{.contact-name}, and [Dr. Jianle
Chen]{.contact-name} for many useful discussions on this document and
their help while preparing it, as well as [Mr. Mo
Zanaty]{.contact-name}, [Dr. Minhua Zhou]{.contact-name}, [Dr. Ali
Begen]{.contact-name}, [Mr. Thomas Daede]{.contact-name}, [Mr. Adam
Roach]{.contact-name}, [Dr. Thomas Davies]{.contact-name}, [Mr. Jonathan
Lennox]{.contact-name}, [Dr. Timothy Terriberry]{.contact-name}, [Mr.
Peter Thatcher]{.contact-name}, [Dr. Jean-Marc Valin]{.contact-name},
[Mr. Roman Danyliw]{.contact-name}, [Mr. Jack Moffitt]{.contact-name},
[Mr. Greg Coppa]{.contact-name}, and [Mr. Andrew
Krupiczka]{.contact-name} for their valuable comments on different
revisions of this document.[¶](#section-appendix.a-1){.pilcrow}
:::
:::

::: {#authors-addresses}
::: {#section-appendix.b .section}
## [Authors\' Addresses](#name-authors-addresses){.section-name .selfRef} {#name-authors-addresses}

::: {.left dir="auto"}
[Alexey Filippov]{.fn .nameRole}
:::

::: {.left dir="auto"}
[Huawei Technologies]{.org}
:::

::: email
Email: <alexey.filippov@huawei.com>
:::

::: {.left dir="auto"}
[Andrey Norkin]{.fn .nameRole}
:::

::: {.left dir="auto"}
[Netflix]{.org}
:::

::: email
Email: <anorkin@netflix.com>
:::

::: {.left dir="auto"}
[Jose Roberto Alvarez]{.fn .nameRole}
:::

::: {.left dir="auto"}
[Huawei Technologies]{.org}
:::

::: email
Email: <j.alvarez@ieee.org>
:::
:::
:::
